journal,year,title,authors,abstract,url
Journal of Econometrics,2022,Conditional rotation between forecasting models,Yinchu Zhu and Allan Timmermann,"We establish conditions under which forecasting performance can be improved by rotating between a set of underlying forecasts whose predictive accuracy is tracked using a set of time-varying monitoring instruments. We characterize the properties that the monitoring instruments must possess to be useful for identifying, at each point in time, the best forecast and show that these reflect both the accuracy of the predictors used by the underlying forecasting models and the strength of the monitoring instruments. Finite-sample bounds on forecasting performance that account for estimation error are used to compute the expected loss of the competing forecasts as well as for the dynamic rotation strategy. Finally, using Monte Carlo simulations and empirical applications to forecasting inflation and stock returns, we demonstrate the potential gains from using conditioning information to rotate between forecasts.",http://www.sciencedirect.com/science/article/pii/S0304407621002505
Journal of Econometrics,2022,From zero to hero: Realized partial (co)variances,"Tim Bollerslev, Marcelo Medeiros, Andrew Patton and Rogier Quaedvlieg","This paper proposes a generalization of the class of realized semivariance and semicovariance measures introduced by Barndorff-Nielsen et al. (2010) and Bollerslev et al. (2020a) to allow for a finer decomposition of realized (co)variances. The new “realized partial (co)variances” allow for multiple thresholds with various locations, rather than the single fixed threshold of zero used in semi (co)variances. We adopt methods from machine learning to choose the thresholds to maximize the out-of-sample forecast performance of time series models based on realized partial (co)variances. We find that in low dimensional settings it is hard, but not impossible, to improve upon the simple fixed threshold of zero. In large dimensions, however, the zero threshold embedded in realized semi covariances emerges as a robust choice.",http://www.sciencedirect.com/science/article/pii/S0304407621002517
Journal of Econometrics,2022,Testing for parameter instability and structural change in persistent predictive regressions,Torben Andersen and Rasmus T. Varneskov,"This paper develops parameter instability and structural change tests within predictive regressions for economic systems governed by persistent vector autoregressive dynamics. Specifically, in a setting where all – or a subset – of the variables may be fractionally integrated and the predictive relation may feature cointegration, we provide sup-Wald break tests that are constructed using the Local speCtruM (LCM) approach. The new tests cover both parameter variation and multiple structural changes with unknown break dates, and the number of breaks being known or unknown. We establish asymptotic limit theory for the tests, showing that it coincides with standard testing procedures. As a consequence, existing critical values for tied-down Bessel processes may be applied, without modification. We implement the new structural change tests to explore the stability of the fractionally cointegrating relation between implied- and realized volatility (IV and RV). Moreover, we assess the relative efficiency of IV forecasts against a challenging time-series benchmark constructed from high-frequency data. Unlike existing studies, we find evidence that the IV–RV cointegrating relation is unstable, and that carefully constructed time-series forecasts are more efficient than IV in capturing low-frequency movements in RV.",http://www.sciencedirect.com/science/article/pii/S0304407621002529
Journal of Econometrics,2022,Words speak as loudly as actions: Central bank communication and the response of equity prices to macroeconomic announcements,"Ben Gardner, Chiara Scotti and Clara Vega","While the literature has already widely documented the effects of macroeconomic news announcements on asset prices, as well as their asymmetric impact during good and bad times, we focus on the reaction to news based on the description of the state of the economy as painted by the Federal Open Market Committee (FOMC) statements. We develop a novel FOMC sentiment index using textual analysis techniques, and find that news has a bigger (smaller) effect on equity prices during bad (good) times as described by the FOMC sentiment index. Our analysis suggests that the FOMC sentiment index offers a reading on current and future macroeconomic conditions that will affect the probability of a change in interest rates, and the reaction of equity prices to news depends on the FOMC sentiment index which is one of the best predictors of this probability.",http://www.sciencedirect.com/science/article/pii/S0304407621002530
Journal of Econometrics,2022,Monetary reforms and inflation expectations in Japan: Evidence from inflation-indexed bonds,Jens H.E. Christensen and Mark Spiegel,"We assess the impact of news concerning recent Japanese monetary reforms on long-term inflation expectations using an arbitrage-free term structure model of nominal and real yields. Our model accounts for the value of deflation protection embedded in Japanese inflation-indexed bonds issued since 2013, which is sizable and time-varying. Our results suggest that Japanese long-term inflation expectations have remained positive despite extensive spells of deflation, leaving inflation risk premia mostly negative during this period. Moreover, adjusting for deflation protection demonstrates that market responses to policy changes were not as inflationary as they appear under standard modeling procedures. Consequently, the reforms were less “disappointing” than is widely perceived.",http://www.sciencedirect.com/science/article/pii/S0304407621002542
Journal of Econometrics,2022,Approximate maximum likelihood for complex structural models,"Veronika Czellar, David T. Frazier and Eric Renault","Indirect Inference (I-I) is a popular technique for estimating complex parametric models whose likelihood function is intractable, however, the statistical efficiency of I-I estimation is questionable. While the efficient method of moments, Gallant and Tauchen (1996), promises efficiency, the price to pay for this efficiency is a loss of parsimony and thereby a potential lack of robustness to model misspecification. This stands in contrast to simpler I-I estimation strategies, which are known to display less sensitivity to model misspecification due in large part to their focus on specific elements of the underlying structural model. In this research, we propose a new simulation-based approach that maintains the parsimony of I-I estimation, which is often critical in empirical applications, but can also deliver estimators that are nearly as efficient as maximum likelihood. This new approach is based on using a constrained approximation to the structural model, which ensures identification and can deliver estimators that are consistent and nearly efficient. We demonstrate this approach through several examples, and show that this approach can deliver estimators that are nearly as efficient as maximum likelihood, when feasible, but can be employed in many situations where maximum likelihood is infeasible.",http://www.sciencedirect.com/science/article/pii/S0304407621002463
Journal of Econometrics,2022,Joint Bayesian inference about impulse responses in VAR models,Atsushi Inoue and Lutz Kilian,"We derive the Bayes estimator of vectors of structural VAR impulse responses under a range of alternative loss functions. We also discuss the construction of joint credible regions for vectors of impulse responses as the lowest posterior risk region under the same loss functions. We show that conventional impulse response estimators such as the posterior median response function or the posterior mean response function are not in general the Bayes estimator of the impulse response vector obtained by stacking the impulse responses of interest. We illustrate that such pointwise estimators may imply response function shapes that are incompatible with any possible parameterization of the underlying model. Moreover, conventional pointwise quantile error bands are not a valid measure of the estimation uncertainty about the impulse response vector because they ignore the mutual dependence of the responses. In practice, they tend to understate substantially the estimation uncertainty about the impulse response vector.",http://www.sciencedirect.com/science/article/pii/S0304407621002475
Journal of Econometrics,2022,SVARs with occasionally-binding constraints,"S. Boragan Aruoba, Marko Mlikota, Frank Schorfheide and Sergio Villalvazo","We develop a structural VAR in which an occasionally-binding constraint generates censoring of one of the dependent variables. Once the censoring mechanism is triggered, we allow some of the coefficients for the remaining variables to change. We show that a necessary condition for a unique reduced form is that regression functions for the non-censored variables are continuous at the censoring point and that parameters satisfy some mild restrictions. In our application the censored variable is a nominal interest rate constrained by an effective lower bound (ELB). According to our estimates based on U.S. data, once the ELB becomes binding, the coefficients in the inflation equation change significantly, which translates into a change of the inflation responses to (unconventional) monetary policy and demand shocks. Our results suggest that the presence of the ELB is indeed empirically relevant for the propagation of shocks. We also obtain a shadow interest rate that shows a significant accommodation in the early phase of the Great Recession, followed by a mild and steady accommodation until liftoff in 2016.",http://www.sciencedirect.com/science/article/pii/S0304407621002487
Journal of Econometrics,2022,Nowcasting with large Bayesian vector autoregressions,"Jacopo Cimadomo, Domenico Giannone, Michele Lenza, Francesca Monti and Andrej Sokol","Monitoring economic conditions in real time, or nowcasting, and Big Data analytics share some challenges, sometimes called the three “Vs”. Indeed, nowcasting is characterized by the use of a large number of time series (Volume), the complexity of the data covering various sectors of the economy, with different frequencies and precision and asynchronous release dates (Variety), and the need to incorporate new information continuously and in a timely manner (Velocity). In this paper, we explore three alternative routes to nowcasting with Bayesian Vector Autoregressive (BVAR) models and find that they can effectively handle the three Vs by producing, in real time, accurate probabilistic predictions of US economic activity and a meaningful narrative by means of scenario analysis.",http://www.sciencedirect.com/science/article/pii/S0304407621002499
Journal of Econometrics,2022,Probability assessments of an ice-free Arctic: Comparing statistical and climate model projections,Francis Diebold and Glenn Rudebusch,"The downward trend in the amount of Arctic sea ice has a wide range of environmental and economic consequences including important effects on the pace and intensity of global climate change. Based on several decades of satellite data, we provide statistical forecasts of Arctic sea ice extent during the rest of this century. The best fitting statistical model indicates that overall sea ice coverage is declining at an increasing rate. By contrast, average projections from the CMIP5 global climate models foresee a gradual slowing of Arctic sea ice loss even in scenarios with high carbon emissions. Our long-range statistical projections also deliver probability assessments of the timing of an ice-free Arctic. These results indicate almost a 60 percent chance of an effectively ice-free Arctic Ocean sometime during the 2030s — much earlier than the average projection from the global climate models.",http://www.sciencedirect.com/science/article/pii/S0304407620304012
Journal of Econometrics,2022,Maternal subjective expectations about the technology of skill formation predict investments in children one year later,"Flávio Cunha, Irma Elo and Jennifer Culhane","A growing literature reports significant socio-economic gaps in investments in the human capital of young children. Because the returns to these investments may be huge, parenting programs attempt to improve children’s environments by increasing parental expectations about the importance of investments for their children’s human capital formation. We contribute to this literature by investigating the relevance of maternal subjective expectations (MSE) about the technology of skill formation in predicting investments in the human capital of children. We develop and implement a framework to elicit and analyze MSE data. We launch a longitudinal study with 822 participants, all of whom were women in the second trimester of their first pregnancy at the date of enrollment. In the first wave of the study, during pregnancy, we elicited the woman’s MSE. In the second wave, approximately one year later, we measured maternal investments using the Home Observation for the Measurement of the Environment (HOME) Inventory. The vast majority of study participants believe that the Cobb–Douglas technology of skill formation describes the process of child development accurately. We observed substantial heterogeneity in MSE about the impact of human capital at birth and investments in child development at age two. Family income explains part of this heterogeneity in MSE. The higher the family income, the higher the MSE about the impact of investment in child development. We find that a one-standard-deviation of MSE measured at pregnancy is associated with 11% of a standard deviation in investments measured when the child is approximately nine months old.",http://www.sciencedirect.com/science/article/pii/S0304407620302700
Journal of Econometrics,2022,Parental beliefs about returns to child health investments,"Pietro Biroli, Teodora Boneva, Akash Raja and Christopher Rauh","Childhood obesity has adverse health and productivity consequences and it poses negative externalities to health services. To shed light on the role of parents, we elicit parental beliefs about the returns and the persistence of a healthy diet and exercise routine in childhood. Parents believe both types of investments to improve child and adult health outcomes. Consistent with a model of taste formation, parents believe that childhood health behaviors persist into adulthood. We show that perceived returns are predictive of health investments and outcomes, and that less educated parents view the returns to health investments to be lower. Our descriptive evidence suggests that beliefs contribute to the socioeconomic inequality in health outcomes and the intergenerational transmission of obesity.",http://www.sciencedirect.com/science/article/pii/S0304407620302712
Journal of Econometrics,2022,Self-perceptions about academic achievement: Evidence from Mexico City,Matteo Bobba and Veronica Frisancho,"A growing body of evidence suggests that people exhibit large biases when processing information about themselves, but less is known about the underlying inference process. This paper studies belief updating patterns regarding academic ability in a large sample of students transitioning from middle to high school in Mexico City. The analysis takes advantage of rich and longitudinal data on subjective beliefs together with randomized feedback about individual performance on an achievement test. On average, the performance feedback reduces the relative role of priors on posteriors and shifts substantial probability mass toward the signal. Further evidence reveals that males and high-socioeconomic status students tend to process new information on their own ability more effectively.",http://www.sciencedirect.com/science/article/pii/S0304407620302724
Journal of Econometrics,2022,"Academic and non-academic investments at university: The role of expectations, preferences and constraints","Adeline Delavande, Emilia Del Bono and Angus Holford","This paper estimates a discrete choice model of time allocation decisions made by university students. We consider investments in academic and non-academic activities, such as job placements or volunteering. Identification is achieved using data collected through a recent survey of UK university students on subjective expectations about the returns to these activities, and the enjoyment students derive from them. Unobserved heterogeneity in the choice set is addressed using a sufficient set logit method. The analysis reveals significant ethnic differences in the level of investments, expected academic and labour market returns, and enjoyment of academic and non-academic activities. Simulations suggest that existing constraints play an important role in explaining ethnic gaps in investments.",http://www.sciencedirect.com/science/article/pii/S030440762030275X
Journal of Econometrics,2022,"The role of heterogeneous risk preferences, discount rates, and earnings expectations in college major choice","Arpita Patnaik, Joanna Venator, Matthew Wiswall and Basit Zafar","We estimate a rich model of college major choice using a panel of experimentally-derived data. Our estimation strategy combines two types of data: data on self-reported beliefs about future earnings from potential human capital decisions and survey-based measures of risk and time preferences. We show how to use these data to identify a general life-cycle model, allowing for rich patterns of heterogeneous beliefs and preferences. Our data allow us to separate perceptions about the degree of risk or about the current versus future payoffs for a choice from the individual’s preference for risk and patience. Comparing our estimates of the general model to estimates of models which ignore heterogeneity in risk and time preferences, we find that these restricted models overstate the importance of earnings to major choice. Additionally, we show that while men are less risk averse and patient than women, gender differences in expectations about own-earnings, risk aversion, and patience cannot explain gender gaps in major choice.",http://www.sciencedirect.com/science/article/pii/S0304407620302773
Journal of Econometrics,2022,Understanding migration aversion using elicited counterfactual choice probabilities,"Gizem Kosar, Tyler Ransom and Wilbert van der Klaauw","This paper investigates how migration and location choice decisions depend on a large set of location characteristics, with particular focus on measuring the importance and nature of non-monetary costs of moving. We employ a stated-preference approach to elicit respondents’ choice probabilities for a set of hypothetical choice scenarios, using two waves from the NY Fed’s Survey of Consumer Expectations. Our stated probabilistic choice approach allows us to recover the distribution of individual-level preferences for location and mobility attributes without concerns about omitted variables and selection biases that hamper analyses based on observed mobility choices alone. We estimate substantial heterogeneity in the willingness-to-pay (WTP) for location characteristics and in moving costs, both across and within demographic groups. We find moving costs to be strongly associated with attachment to the current neighborhood and dwelling and to social networks. Our results indicate evidence of sorting into current locations based on preferences for location attributes as well as a strong negative association between respondents’ non-monetary moving costs and their moving expectations and actual mobility decisions.",http://www.sciencedirect.com/science/article/pii/S0304407621000415
Journal of Econometrics,2022,"Marriage, children, and labor supply: Beliefs and outcomes","Yifan Gong, Ralph Stinebrickner and Todd Stinebrickner","While a large literature is interested in the relationship between family and labor supply outcomes, little is known about the expectations of these objects at earlier stages. We examine these expectations, taking advantage of unique data from the Berea Panel Study. In addition to characterizing expectations, starting during college, the data details outcomes for ten years after graduation. Methodological contributions come from approaches to validate quality of survey expectations data and the recognition that expectations data, along with longitudinal data, can potentially help address endogeneity issues arising in the estimation of the causal effect of family on labor supply.",http://www.sciencedirect.com/science/article/pii/S0304407620302803
Journal of Econometrics,2022,Beliefs about public debt and the demand for government spending,"Christopher Roth, Sonja Settele and Johannes Wohlfart","We examine how beliefs about the debt-to-GDP ratio affect people’s attitudes towards government spending and taxation. Using representative samples of the US population, we run a series of experiments in which we provide half of our respondents with information about the debt-to-GDP ratio in the US. Based on a total of more than 4,000 respondents, we find that most people underestimate the debt-to-GDP ratio and reduce their support for government spending once they learn about the actual amount of debt, but do not substantially alter their attitudes towards taxation. The treatment effects seem to operate through changes in expectations about fiscal sustainability and persist in a four-week follow-up.",http://www.sciencedirect.com/science/article/pii/S0304407621000397
Journal of Econometrics,2022,Incentive-driven inattention,"Wagner Gaglianone, Raffaella Giacomini, João Issler and Vasiliki Skreta","“Rational inattention” is becoming increasingly prominent in economic modeling, but there is little empirical evidence for its central premise-that the choice of attention results from a cost-benefit optimization. Observational data typically do not allow researchers to infer attention choices from observables. We fill this gap in the literature by exploiting a unique dataset of professional forecasters who update their inflation forecasts at days of their choice. In the data we observe how many forecasters update (extensive margin of updating), the magnitude of the update (intensive margin), and the objective of optimization (forecast accuracy). There are also “shifters” in incentives: A contest that increases the benefit of accurate forecasting, and the release of official data that reduces the cost of processing information. These features allow us to link observables to attention and incentive parameters. We structurally estimate a model where the decision to update and the magnitude of the update are endogenous and the latter is the outcome of a rational inattention optimization. The empirical findings provide support for the key implication of rational inattention that information-processing efforts react to changing incentives. Counterfactuals reveal that accuracy is maximized if the contest date coincides with the release of information, aligning higher benefits with lower costs of attention.",http://www.sciencedirect.com/science/article/pii/S0304407620302736
Journal of Econometrics,2022,Dynamics and heterogeneity of subjective stock market expectations,"Florian Heiss, Michael Hurd, Maarten van Rooij, Tobias Rossmann and Joachim Winter","Between 2004 and 2016, we elicited individuals’ subjective expectations of stock market returns in a Dutch internet panel at bi-annual intervals. In this paper, we develop a panel data model with a finite mixture of expectation types who differ in how they use past stock market returns to form current stock market expectations. The model allows for rounding in the probabilistic responses and for observed and unobserved heterogeneity at several levels. We estimate the type distribution in the population and find evidence for considerable heterogeneity in expectation types and meaningful variation over time, in particular during the financial crisis of 2008/09.",http://www.sciencedirect.com/science/article/pii/S0304407621002232
Journal of Econometrics,2022,Heterogeneity in households’ stock market beliefs,Hans-Martin von Gaudecker and Axel Wogrolly,"We analyse a long panel of households’ stock market beliefs to gain insights into the nature of the levels, dynamics, and informativeness of these expectations. In a first step, we classify respondents into one of five groups based on their beliefs data alone. In a second step, we estimate models of expectations at the group level so that belief levels, volatility, and response to information can vary freely across groups. At opposite extremes in terms of optimism we identify pessimists who expect substantially negative returns and financially sophisticated individuals whose expectations are close to the historical average. Two groups expect average returns around zero and differ only in how they respond to information: Extrapolators who become more optimistic following positive information and mean-reverters for whom the opposite is the case. The final group is characterised by its members being unable or unwilling to quantify their beliefs about future returns.",http://www.sciencedirect.com/science/article/pii/S0304407621000403
Journal of Econometrics,2022,Optimal frequency of portfolio evaluation in a choice experiment with ambiguity and loss aversion,"Charles Bellemare, Sabine Kröger and Kouamé Marius Sossou","We estimate a structural model using data from a novel experiment investigating how investors’ preferred frequency of portfolio evaluations balance the opposing effects of ambiguity and loss aversion. Investors in the experiment face initial ambiguity concerning return distributions for an asset. They observe draws from the true return distribution of the asset, allowing them to reduce their ambiguity through time. We exploit portfolio choices and stated beliefs over possible return distributions to estimate preferences and ambiguity updating rules. We find that 70% of investors would opt for a high frequency of portfolio evaluations, reflecting the dominating effect of ambiguity aversion over loss aversion.",http://www.sciencedirect.com/science/article/pii/S0304407620303900
Journal of Econometrics,2022,Tail and center rounding of probabilistic expectations in the Health and Retirement Study,"Pamela Giustinelli, Charles Manski and Francesca Molinari","We study rounding of numerical expectations in the Health and Retirement Study (HRS) between 2002 and 2014. We document that respondent-specific rounding patterns across questions in individual waves are quite stable across waves. We discover a tendency by about half of the respondents to provide more refined responses in the tails of the 0–100 scale than the center. In contrast, only about five percent of the respondents give more refined responses in the center than the tails. We find that respondents tend to report the values 25 and 75 more frequently than other values ending in 5. We also find that rounding practices vary somewhat across question domains and respondent characteristics. We propose an inferential approach that assumes stability of response tendencies across questions and waves to infer person-specific rounding in each question domain and scale segment and that replaces each point-response with an interval representing the range of possible values of the true latent belief. Using expectations from the 2016 wave of the HRS, we validate our approach. To demonstrate the consequences of rounding on inference, we compare best-predictor estimates from face-value expectations with those implied by our intervals.",http://www.sciencedirect.com/science/article/pii/S0304407620302761
Journal of Econometrics,2022,Surveying business uncertainty,"David Altig, Jose Maria Barrero, Nicholas Bloom, Steven Davis, Brent Meyer and Nicholas Parker","We elicit subjective probability distributions from business executives about their own-firm outcomes at a one-year look-ahead horizon. In terms of question design, our key innovation is to let survey respondents freely select support points and probabilities in five-point distributions over future sales growth, employment, and investment. In terms of data collection, we develop and field a new monthly panel Survey of Business Uncertainty. The SBU began in 2014 and now covers about 1,750 firms drawn from all 50 states, every major nonfarm industry, and a range of firm sizes. We find three key results. First, firm-level growth expectations are highly predictive of realized growth rates. Second, firm-level subjective uncertainty predicts the magnitudes of future forecast errors and future forecast revisions. Third, subjective uncertainty rises with the firm’s absolute growth rate in the previous year and with the magnitude of recent revisions to its expected growth rate. We aggregate over firm-level forecast distributions to construct monthly indices of business expectations (first moment) and uncertainty (second moment) for the U.S. private sector.",http://www.sciencedirect.com/science/article/pii/S0304407620302785
Journal of Econometrics,2022,"Incentives, search engines, and the elicitation of subjective beliefs: Evidence from representative online survey experiments","Elisabeth Grewenig, Philipp Lergetporer, Katharina Werner and Ludger Woessmann","A large literature studies subjective beliefs about economic facts using unincentivized survey questions. We devise randomized experiments in a representative online survey to investigate whether incentivizing belief accuracy affects stated beliefs about average earnings by professional degree and average public school spending. Incentive provision does not impact earnings beliefs, but improves school-spending beliefs. Response spikes suggest that the latter effect likely reflects increased online-search activity. Consistently, an experiment that just encourages search-engine usage produces very similar results. Another experiment provides no evidence of experimenter-demand effects. Overall, results suggest a trade-off between increased respondent effort and the risk of inducing online-search activity when incentivizing beliefs in online surveys.",http://www.sciencedirect.com/science/article/pii/S0304407620302797
Journal of Econometrics,2022,Predictive functional linear models with diverging number of semiparametric single-index interactions,"Yanghui Liu, Yehua Li, Raymond J. Carroll and Naisyin Wang","When predicting crop yield using both functional and multivariate predictors, the prediction performances benefit from the inclusion of the interactions between the two sets of predictors. We assume the interaction depends on a nonparametric, single-index structure of the multivariate predictor and reduce each functional predictor’s dimension using functional principal component analysis (FPCA). Allowing the number of FPCA scores to diverge to infinity, we consider a sequence of semiparametric working models with a diverging number of predictors, which are FPCA scores with estimation errors. We show that the parametric component of the model is root-n consistent and asymptotically normal, the overall prediction error is dominated by the estimation of the nonparametric interaction function, and justify a CV-based procedure to select the tuning parameters.",http://www.sciencedirect.com/science/article/pii/S0304407621001020
Journal of Econometrics,2022,Global temperatures and greenhouse gases: A common features approach,"Li Chen, Jiti Gao and Farshid Vahid","We propose a common features approach for testing for common trends and estimating long-run relationships between variables with complex trends. Using this approach, we establish that global temperatures and the concentration of greenhouse gases share a common trend and we estimate their long-run relationship without conditioning on the exact nature of this trend.",http://www.sciencedirect.com/science/article/pii/S0304407621001159
Journal of Econometrics,2022,Nonparametric jump variation measures from options,Viktor Todorov,"This paper proposes a novel nonparametric method for estimating tail jump variation measures from short-dated options, which can achieve rate-efficiency and works in a general infinite jump activity setting, avoiding parametric or semiparametric assumptions for the jump measure. The method is based on expressing the measures of interest as integrals of the Laplace transforms of the jump compensator and developing methods for recovering nonparametrically the latter from the available option data. The separation of volatility from jumps is done in a novel way by making use of the second derivative of the Laplace transform of the returns, de-biased using either the value of the Laplace transform or of its second derivative evaluated at high frequencies. A Monte Carlo study shows the superiority of the newly-developed method over existing ones in empirically realistic settings. In an empirical application to S&P 500 index options, we find risk-neutral negative market tail jump variation that is on average smaller than previous estimates of it, is generated by smaller-sized jumps, and has less dependence on the level of diffusive volatility.",http://www.sciencedirect.com/science/article/pii/S0304407621001263
Journal of Econometrics,2022,Markov switching panel with endogenous synchronization effects,"Komla M. Agudze, Monica Billio, Roberto Casarin and Francesco Ravazzolo","This paper introduces a new dynamic panel model with multi-layer network effects. Series-specific latent Markov chain processes drive the dynamics of the observable processes, and several types of interaction effects among the hidden chains allow for various degrees of endogenous synchronization of both latent and observable processes. The interaction is driven by a multi-layer network with exogenous and endogenous connectivity layers. We provide some theoretical properties of the model, develop a Bayesian inference framework and an efficient Markov Chain Monte Carlo algorithm for estimating parameters, latent states, and endogenous network layers. An application to the US-state coincident indicators shows that the synchronization in the US economy is generated by network effects among the states. The inclusion of a multi-layer network provides a new tool for measuring the effects of the public policies that impact the connectivity between the US states, such as mobility restrictions or job support schemes. The proposed new model and the related inference are general and may find application in a wide spectrum of datasets where the extraction of endogenous interaction effects is relevant and of interest.",http://www.sciencedirect.com/science/article/pii/S0304407621001251
Journal of Econometrics,2022,Sampling properties of the Bayesian posterior mean with an application to WALS estimation,"Giuseppe De Luca, Jan R. Magnus and Franco Peracchi","Many statistical and econometric learning methods rely on Bayesian ideas. When applied in a frequentist setting, their precision is often assessed using the posterior variance. This is permissible asymptotically, but not necessarily in finite samples. We explore this issue focusing on weighted-average least squares (WALS), a Bayesian-frequentist ‘fusion’. Exploiting the sampling properties of the posterior mean in the normal location model, we derive estimators of the finite-sample bias and variance of WALS. We study the performance of the proposed estimators in an empirical application and a closely related Monte Carlo experiment which analyze the impact of legalized abortion on crime.",http://www.sciencedirect.com/science/article/pii/S0304407621001482
Journal of Econometrics,2022,Inference on covariance-mean regression,"Tao Zou, Wei Lan, Runze Li and Chih-Ling Tsai","In this article, we introduce a covariance-mean regression model with heterogeneous similarity matrices. It not only links the covariance of responses to heterogeneous similarity matrices induced by auxiliary information, but also establishes the relationship between the mean of responses and covariates. Under this new model setting, however, two statistical inference challenges are encountered. The first challenge is that the consistency of the covariance estimator based on the standard profile likelihood approach breaks down. Hence, we propose an adjustment and develop the Z-estimation and unconstrained/constrained ordinary least squares estimation methods. We demonstrate that the resulting estimators are consistent and asymptotically normal. The second challenge is testing the adequacy of the covariance-mean regression model comprising both the multivariate mean regression and the heterogeneous covariance matrices. Correspondingly, we introduce two diagnostic test statistics and then obtain their theoretical properties. The proposed estimators and tests are illustrated via extensive simulations and an empirical example study of the stock return comovement in the US stock market.",http://www.sciencedirect.com/science/article/pii/S0304407621001585
Journal of Econometrics,2022,Fast and accurate variational inference for models with many latent variables,"Rubén Loaiza-Maya, Michael Stanley Smith, David J. Nott and Peter Danaher","Models with a large number of latent variables are often used to utilize the information in big or complex data, but can be difficult to estimate. Variational inference methods provide an attractive solution. These methods use an approximation to the posterior density, yet for large latent variable models existing choices can be inaccurate or slow to calibrate. Here, we propose a family of tractable variational approximations that are more accurate and faster to calibrate for this case. It combines a parsimonious approximation for the parameter posterior with the exact conditional posterior of the latent variables. We derive a simplified expression for the re-parameterization gradient of the variational lower bound, which is the main ingredient of optimization algorithms used for calibration. Implementation only requires exact or approximate generation from the conditional posterior of the latent variables, rather than computation of their density. In effect, our method provides a new way to employ Markov chain Monte Carlo (MCMC) within variational inference. We illustrate using two complex contemporary econometric examples. The first is a nonlinear multivariate state space model for U.S. macroeconomic variables. The second is a random coefficients tobit model applied to two million sales by 20,000 individuals in a consumer panel. In both cases, our approximating family is considerably more accurate than mean field or structured Gaussian approximations, and faster than MCMC. Last, we show how to implement data sub-sampling in variational inference for our approximation, further reducing computation time. MATLAB code implementing the method is provided.",http://www.sciencedirect.com/science/article/pii/S0304407621001330
Journal of Econometrics,2022,Estimation and inference about tail features with tail censored data,Yulong Wang and Zhijie Xiao,"This paper considers estimation and inference about tail features such as tail index and extreme quantile when the observations beyond some threshold are censored. Ignoring such tail censoring could lead to substantial bias and size distortion, even if the censored probability is tiny. We first propose a new maximum likelihood estimator (MLE) based on the Pareto tail approximation and derive its asymptotic properties. Then, we propose an alternative method of constructing confidence intervals by resorting to extreme value theory. The MLE and the confidence intervals deliver excellent small sample performance, as shown by Monte Carlo simulations. Finally, we apply the proposed methods to estimate and construct confidence intervals for the tail index of the distribution of macroeconomic disasters and the coefficient of risk aversion using the dataset collected by Barro and Ursúa (2008). Our empirical findings are substantially different from those obtained from the existing methods.",http://www.sciencedirect.com/science/article/pii/S0304407621001548
Journal of Econometrics,2022,Estimation of varying coefficient models with measurement error,"Hao Dong, Taisuke Otsu and Luke Taylor","We propose a semiparametric estimator for varying coefficient models when the regressors in the nonparametric components are measured with error. Varying coefficient models are an extension of other popular semiparametric models, including partially linear and nonparametric additive models, and deliver an attractive solution to the curse-of-dimensionality. We use deconvolution kernel estimation in a two-step procedure and show that the estimator is consistent and asymptotically normally distributed. We do not assume that we know the distribution of the measurement error a priori. Instead, we suppose we have access to a repeated measurement of the noisy regressor and present results using the approach of Delaigle, Hall and Meister (2008) and, for cases when the measurement error may be asymmetric, the approach of Li and Vuong (1998) based on Kotlarski’s (1967) identity. We show that the convergence rate of the estimator is significantly reduced when the distribution of the measurement error is assumed unknown and possibly asymmetric. We study the small sample behaviour of our estimator in a simulation study and apply it to a real dataset. In particular, we consider the role of cognitive ability in augmenting the effect of risk preferences on earnings.",http://www.sciencedirect.com/science/article/pii/S0304407621001615
Journal of Econometrics,2022,Robust post-selection inference of high-dimensional mean regression with heavy-tailed asymmetric or heteroskedastic errors,"Dongxiao Han, Jian Huang, Yuanyuan Lin and Guohao Shen","We propose a robust post-selection inference method based on the Huber loss for the regression coefficients, when the error distribution is heavy-tailed and asymmetric in a high-dimensional linear model with an intercept term. The asymptotic properties of the resulting estimators are established under mild conditions. We also extend the proposed method to accommodate heteroscedasticity assuming the error terms are symmetric and other suitable conditions. Statistical tests for low-dimensional parameters or individual coefficient in the high-dimensional linear model are also studied. Simulation studies demonstrate desirable properties of the proposed method. An application to a genomic dataset about riboflavin production rate is provided.",http://www.sciencedirect.com/science/article/pii/S0304407621001639
Journal of Econometrics,2022,GMM quantile regression,"Sergio Firpo, Antonio Galvao, Cristine Pinto, Alexandre Poirier and Graciela Sanroman","This paper develops generalized method of moments (GMM) estimation and inference procedures for quantile regression models. We propose a GMM estimator for simultaneous estimation across multiple quantiles. This estimator allows us to model quantile regression coefficients using flexible parametric restrictions across quantiles. The restrictions and simultaneous estimation lead to efficiency gains compared to standard methods. We establish the asymptotic properties of the GMM estimators when the number of quantiles used is fixed and when it diverges to infinity jointly with the sample size. As an alternative to GMM, we also propose a minimum distance estimator over a given subset of quantiles. Moreover, we provide specification tests for the imposed restrictions. The estimators and tests we propose are simple to implement in practice. Monte Carlo simulations provide numerical evidence of the finite sample properties of the methods. Finally, we apply the proposed methods to estimate the effects of smoking on birthweight of live infants at the extreme bottom of the conditional distribution.",http://www.sciencedirect.com/science/article/pii/S0304407621001299
Journal of Econometrics,2022,Nonparametric inference for quantile cointegrations with stationary covariates,"Yundong Tu, Han-Ying Liang and Qiying Wang","This paper considers the inference problems in nonlinear quantile regressions with both stationary and nonstationary covariates. The nonparametric local constant quantile estimator is proposed to estimate the unknown quantile regression function, whose asymptotic properties are established under quite general conditions. Specification testing of the quantile regression function is further considered through a statistic constructed based on the integrated squared distance between the parametric and the nonparametric estimators for the regression function. The test statistic is shown to converge to a random variable related to the local time of an Ornstein–Uhlenbeck process under the parametric null. The power of the test against local alternatives is also investigated. Additional asymptotic results on the null parametric quantile estimators and a bootstrap test are developed as well. Numerical results demonstrate that the proposed nonparametric estimator and the specification test enjoy attractive finite sample performance.",http://www.sciencedirect.com/science/article/pii/S0304407621001731
Journal of Econometrics,2022,Testing for the presence of jump components in jump diffusion models,Bin Wang and Xu Zheng,"In this paper we propose a nonparametric test to determine whether an underlying jump diffusion process indeed contains jump component, or equivalently, is indeed a diffusion. Our test is based upon a robust threshold estimation of diffusive volatility and the kernel estimation of the conditional moment function of the squared instantaneous increments of the underlying process. We show that our test statistic has asymptotic standard normal distribution under the null hypothesis of no jumps, is consistent against fixed alternatives, and may detect local alternatives that shrink to diffusions at certain convergence rates, when sampling interval shrinks to zero and time span is either fixed or expands. We only assume that the jump diffusion process is recurrent, thus allowing for both stationary and nonstationary cases. In addition, we provide a regression bootstrap test and establish its validity. A Monte Carlo simulation is conducted to examine the finite sample performances of our test, and an empirical illustration is also provided.",http://www.sciencedirect.com/science/article/pii/S0304407621001779
Journal of Econometrics,2022,Local mispricing and microstructural noise: A parametric perspective,"Torben Andersen, Ilya Archakov, Gökhan Cebiroglu and Nikolaus Hautsch","We extend the classic ”martingale-plus-noise” model for high-frequency returns to accommodate an error correction mechanism and endogenous pricing errors. It is motivated by (i) novel empirical evidence documenting that microstructure noise exhibits frequently changing patterns of serial dependence which are interwoven with innovations to the efficient price; (ii) building a bridge between high-frequency econometrics and market microstructure models. We identify temporal pricing error correction and noise endogeneity as complementary components driving high-frequency dynamics and inducing two separate regimes, characterized by the sign of the return serial correlation and an implied bias in realized variance estimates. We document frequent fluctuations between these regimes, which can be associated with price discovery in a setting with incomplete information and learning. The model links critical concepts from high-frequency statistics and market microstructure theory, suggesting new avenues for volatility estimation.",http://www.sciencedirect.com/science/article/pii/S0304407621001780
Journal of Econometrics,2022,How should parameter estimation be tailored to the objective?,Peter Hansen and Elena-Ivona Dumitrescu,"We study parameter estimation from the sample X, when the objective is to maximize the expected value of a criterion function, Q, for a distinct sample, Y. This is the situation that arises when a model is estimated for the purpose of describing other data than those used for estimation, such as in forecasting problems. A natural candidate for solving maxT∈σ(X)EQ(Y,T) is the innate estimator, θˆ=argmaxθQ(X,θ). While the innate estimator has certain advantages, we show that the asymptotically efficient estimator takes the form θ̃=argmaxθQ̃(X,θ), where Q̃ is defined from a likelihood function in conjunction with Q. The likelihood-based estimator is, however, fragile, as misspecification is harmful in two ways. First, the likelihood-based estimator may be inefficient under misspecification. Second, and more importantly, the likelihood approach requires a parameter transformation that depends on the true model, causing an improper mapping to be used under misspecification.",http://www.sciencedirect.com/science/article/pii/S0304407621001822
Journal of Econometrics,2022,Bayesian factor-adjusted sparse regression,"Jianqing Fan, Bai Jiang and Qiang Sun","Many sparse regression methods rely on an assumption that the covariates are weakly correlated, which hardly holds in many economic and financial datasets. To relax this assumption, we model the strongly correlated covariates by a factor structure: strong correlations among covariates are modeled by common factors, while the remaining variations of covariates are modeled as idiosyncratic components. We then propose a factor-adjusted sparse regression model and develop a semi-Bayesian estimation method for it. Posterior contraction rate and model selection consistency are established by a non-asymptotic analysis. Experimental studies show that the proposed method outperforms its Lasso analogue, manifests insensitivity to overestimates of the number of common factors, pays a negligible price when covariates are uncorrelated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the posterior distribution. An application to the U.S. bond risk premia lends further support to the proposed model and method.",http://www.sciencedirect.com/science/article/pii/S0304407621000828
Journal of Econometrics,2022,Bayesian and maximum likelihood analysis of large-scale panel choice models with unobserved heterogeneity,"Tomohiro Ando, Jushan Bai and Kunpeng Li","This paper considers the estimation and inference procedures for the case of a logistic panel regression model with interactive fixed effects, where multiple individual effects are allowed and the model is capable of capturing high-dimensional cross-section dependence. The proposed model also allows for heterogeneous regression coefficients. New Bayesian and non-Bayesian approaches are introduced to estimate the model parameters. We investigate the asymptotic behaviors of the estimated parameters. We show the consistency and asymptotic normality of the estimated regression coefficients and the estimated interactive fixed effects when both the cross-section and time-series dimensions of the panel go to infinity. We prove that the dimensionality of the interactive effects can be consistently estimated by the proposed information criterion. Monte Carlo simulations demonstrate the satisfactory performance of the proposed method. Finally, the method is applied to study the performance of New York City medallion drivers in terms of efficiency.",http://www.sciencedirect.com/science/article/pii/S030440762100083X
Journal of Econometrics,2022,Parsimony inducing priors for large scale state–space models,"Hedibert F. Lopes, Robert E. McCulloch and Ruey S. Tsay","State–space models are commonly used in the engineering, economic, and statistical literature. They are flexible and encompass many well-known statistical models, including random coefficient autoregressive models and dynamic factor models. Bayesian analysis of state–space models has attracted much interest in recent years. However, for large scale models, prior specification becomes a challenging issue in Bayesian inference. In this paper, we propose a flexible prior for state–space models. The proposed prior is a mixture of four commonly entertained models, yet achieving parsimony in high-dimensional systems. Here “parsimony” is represented by the idea that, in a large system, some states may not be time-varying. Our prior for the state–space component’s standard deviation is capable to accommodate different scenarios. Simulation and simple examples are used throughout this paper to demonstrate the performance of the proposed prior. As an application, we consider the time-varying conditional covariance matrices of daily log returns of the components of the S&P 100 index, leading to a state–space model with roughly five thousand time-varying states. Our model for this large system enables us to use parallel computing.",http://www.sciencedirect.com/science/article/pii/S0304407621002621
Journal of Econometrics,2022,Adaptive Bayesian estimation of conditional discrete-continuous distributions with an application to stock market trading activity,Andriy Norets and Justinas Pelenis,"We consider Bayesian nonparametric estimation of conditional discrete-continuous distributions. Our model is based on a mixture of normal distributions with covariate dependent mixing probabilities. We use continuous latent variables for modeling the discrete part of the distribution. The marginal distribution of covariates is not modeled. Under anisotropic smoothness conditions on the data generating conditional distribution and a possibly increasing number of the support points for the discrete part of the distribution, we show that the posterior in our model contracts at frequentist adaptive optimal rates up to a log factor. Our results also imply an upper bound on the posterior contraction rate for predictive distributions when the data follow an ergodic Markov process and our model is used for modeling the Markov transition distribution. The proposed model performs well in an application to stock market trading activity.",http://www.sciencedirect.com/science/article/pii/S030440762100261X
Journal of Econometrics,2022,Posterior-based Wald-type statistics for hypothesis testing,"Xiaobin Liu, Yong Li, Jun Yu and Tao Zeng","A new Wald-type statistic is proposed for hypothesis testing based on Bayesian posterior distributions under the correct model specification. The new statistic can be explained as a posterior version of the Wald statistic and has several nice properties. First, it is well-defined under improper prior distributions. Second, it avoids Jeffreys–Lindley–Bartlett’s paradox. Third, under the null hypothesis and repeated sampling, it follows a χ2 distribution asymptotically, offering an asymptotically pivotal test. Fourth, it only requires inverting the posterior covariance for parameters of interest. Fifth and perhaps most importantly, when a random sample from the posterior distribution (such as MCMC output) is available, the proposed statistic can be easily obtained as a by-product of posterior simulation. In addition, the numerical standard error of the estimated proposed statistic can be computed based on random samples. A robust version of the test statistic is developed under model misspecification and inherits many nice properties of the new posterior statistic. The finite sample performance of the statistics is examined in Monte Carlo studies. The method is applied to two latent variable models used in microeconometrics and financial econometrics.",http://www.sciencedirect.com/science/article/pii/S0304407621002608
Journal of Econometrics,2022,Real-time Bayesian learning and bond return predictability,"Runqing Wan, Andras Fulop and Junye Li","The paper examines statistical and economic evidence of out-of-sample bond return predictability for a real-time Bayesian investor who learns about parameters, hidden states, and predictive models over time. We find some statistical evidence using information contained in forward rates. However, such statistical predictability can hardly generate any economic value for investors. Furthermore, we find that strong statistical and economic evidence of bond return predictability from fully-revised macroeconomic data vanishes when real-time macroeconomic information is used. We also show that highly levered investments in bonds can improve short-run bond return predictability.",http://www.sciencedirect.com/science/article/pii/S0304407621000877
Journal of Econometrics,2022,Bayesian nonparametric learning of how skill is distributed across the mutual fund industry,Mark Fisher and Mark Jensen,"In this paper, we use Bayesian nonparametric learning to estimate the skill of actively managed mutual funds and also to estimate the population distribution of skill. A nonparametric hierarchical prior, where the hyperprior distribution is unknown and modeled with a Dirichlet Process prior, is used to model the skill parameter, with its posterior predictive distribution being an estimate of the population distribution. Our nonparametric approach is equivalent to an infinitely ordered mixture of normals where we resolve the uncertainty in the number of mixture components by learning how to partition the funds into groups according to the average ability and the variability in the skill of a group. By resolving the mixture’s uncertainty, our nonparametric prior avoids having to sequentially estimate and test an array of pre-specified, finite ordered, mixture priors. Applying our Bayesian nonparametric learning approach to a panel of actively managed, domestic equity funds, we find the population distribution of skill to be fat-tailed, skewed towards higher levels of performance, with two distinct modes – a primary mode where the average ability covers the average fees charged by funds, and a secondary mode at a performance level where a fund loses money for its investors.",http://www.sciencedirect.com/science/article/pii/S0304407621001147
Journal of Econometrics,2022,Asymptotically valid Bayesian inference in the presence of distributional misspecification in VAR models,Katerina Petrova,"Inaccurately imposing Gaussian distributional assumptions in standard multivariate time series models does not affect inference on the autoregressive coefficients but distorts both classical and Bayesian inference on the volatility matrix whenever the true error distribution has excess kurtosis relative to the multivariate normal density. Inference on the intercept is also affected whenever the innovations are generated from a non-symmetric distribution. As a result of distributional misspecification, Bayesian methods lead to asymptotically invalid posterior inference for the intercept and the volatility matrix and, consequently, invalid posterior credible sets for quantities such as impulse responses, variance decompositions and density forecasts. We propose a robust and computationally fast Bayesian procedure which delivers asymptotically correct posterior credible sets without the need for distributional assumptions. The proposed corrected Bayesian posteriors for the volatility matrix and the intercept vector are based on the asymptotic covariance of the QML estimators and admit a closed form. Implementation of the procedure requires consistent estimation of the multivariate skewness and kurtosis of the innovations, and we propose novel shrinkage estimators designed to shrink these large dimensional objects towards the skewness and kurtosis of a Gaussian vector. We extend our robust Bayesian analysis to accommodate non-Gaussian disturbances in the presence of parameter instability, by combining the estimators of the current paper with semi-parametric kernel-type methods. We demonstrate that our estimators deliver correct posterior coverage rates in an extensive Monte Carlo exercise under a variety of distributional specifications. Finally, we present empirical evidence that imposing Gaussianity or homoskedasticity assumptions on financial and uncertainty shocks is not justified and may lead to misleading empirical conclusions.",http://www.sciencedirect.com/science/article/pii/S0304407621000865
Journal of Econometrics,2022,Factor investing: A Bayesian hierarchical approach,Guanhao Feng and Jingyu He,"This paper investigates the asset allocation problem when returns are predictable. We introduce a market-timing Bayesian hierarchical (BH) approach that adopts heterogeneous time-varying coefficients driven by lagged fundamental characteristics. Our approach estimates the conditional expected returns and residual covariance matrix jointly enables evaluating the estimation risk in the portfolio analysis. The hierarchical prior allows the modeling of different assets separately while sharing information across assets. We demonstrate the performance of the U.S. equity market, and our BH approach outperforms most alternative methods in terms of point prediction and interval coverage. In addition, the BH efficient portfolio achieves monthly returns of 0.92% and a significant Jensen’s alpha of 0.32% in sector investment over the past twenty years. We detect that technology, energy, and manufacturing are the most critical sectors in the past decade, and size, investment, and short-term reversal factors are heavily weighted in our portfolio. Furthermore, the stochastic discount factor constructed by our BH approach can explain many risk anomalies.",http://www.sciencedirect.com/science/article/pii/S030440762100258X
Journal of Econometrics,2022,Affine arbitrage-free yield net models with application to the euro debt crisis,"Zhiwu Hong, Linlin Niu and Chen Zhang","We develop a parsimonious class of affine arbitrage-free yield net models for consistent bond pricing across maturities and issuers of different risk levels. Containing a core curve and multiple peripheral curves, the yield net is spanned by three layers of factors: base factors spanning all curves, and common and individual spread factors. Under the arbitrage-free assumption, we prove a parsimonious solution to the risk-neutral process that guarantees joint identification of parameters and latent states. By using a Bayesian estimation method with a marginal Metropolis–Hastings algorithm and specification tests based on MCMC output, we apply the model to weekly treasury yields of Germany, Italy, Spain, and Greece from 2009 to 2016. The results show that the extracted common credit risk is a level factor in spread, and market liquidity risk is a slope factor. Further, the net structure helps reconstruct the Greek yield curve even with only its 10-year yield available throughout the sample.",http://www.sciencedirect.com/science/article/pii/S0304407621002591
Journal of Econometrics,2022,Semiparametric model averaging prediction for dichotomous response,"Fang Fang, Jialiang Li and Xiaochao Xia","Model averaging has attracted abundant attentions in the past decades as it emerges as an impressive forecasting device in econometrics, social sciences and medicine. So far most developed model averaging methods focus only on either parametric models or nonparametric models with a continuous response. In this paper, we propose a semiparametric model averaging prediction (SMAP) method for a dichotomous response. The idea is to approximate the unknown score function by a linear combination of one-dimensional marginal score functions. The weight parameters involved in the approximation are obtained by first smoothing the nonparametric marginal scores and then applying the parametric model averaging via a maximum likelihood estimation. The proposed SMAP provides greater flexibility than parametric models while being more stable than a fully nonparametric approach. Theoretical properties are investigated in two practical scenarios: (i) covariates are conditionally independent given the response; and (ii) the conditional independence assumption does not hold. In the first scenario, we show that SMAP puts weight one to the true model and hence the model averaging estimators are consistent. In the second scenario in which a “true” model may not exist, SMAP is shown to be asymptotically optimal in the sense that its Kullback–Leibler loss is asymptotically identical to that of the best – but infeasible – model averaging estimator. Empirical evidences from simulation studies and a real data analysis are presented to support and illustrate our methods.",http://www.sciencedirect.com/science/article/pii/S0304407620303882
Journal of Econometrics,2022,On improvability of model selection by model averaging,Jingfu Peng and Yuhong Yang,"In regression, model averaging (MA) provides an alternative to model selection (MS), and asymptotic efficiency theories have been derived for both MS and MA. Basically, under sensible conditions, MS asymptotically achieves the smallest estimation loss/risk among the candidate models, and MA does so among averaged estimators from the models with convex weights. Clearly, MA can beat MS by any extent in rate of convergence when all the candidate models have large biases that can be canceled out by a MA scheme. To our knowledge, however, a foundational issue has not been addressed in the literature. That is, when there is no advantage of reducing approximation error, does MA offer any significant improvement over MS in regression estimation? In this paper, we answer this question in a nested model setting that has been often used in the frequentist MA research area. A remarkable implication is that the much celebrated asymptotic efficiency of MS (e.g., by AIC) does not necessarily justify MS as commonly interpreted as achieving the best possible performance. In a nutshell, the oracle model (i.e., the unknowable best model among all the candidates) can be significantly improved by MA under certain conditions. A simulation study supports the theoretical findings.",http://www.sciencedirect.com/science/article/pii/S0304407620303973
Journal of Econometrics,2022,Sieve IV estimation of cross-sectional interaction models with nonparametric endogenous effect,Tadao Hoshino,"In this study, we consider cross-sectional interaction models including spatial autoregressive models and peer effects models as special cases. Our model allows the endogenous effect – the effect of others’ outcomes on one’s own outcome – to be nonlinear and nonparametric. For the model estimation, we propose a sieve instrumental variable estimator and establish both its consistency and asymptotic normality. Furthermore, we propose a nonparametric specification test for the linearity of the endogenous effect. Under the null hypothesis of linearity, we show that the test statistic is asymptotically distributed as normal. As an empirical illustration, we focus on the data on regional economic performance investigated by Gennaioli et al. (2013). This empirical analysis highlights the usefulness of the proposed model and method.",http://www.sciencedirect.com/science/article/pii/S0304407620304036
Journal of Econometrics,2022,A doubly corrected robust variance estimator for linear GMM,"Jungbin Hwang, Byunghoon Kang and Seojeong Lee","We propose a new finite sample corrected variance estimator for the linear generalized method of moments (GMM) including the one-step, two-step, and iterated estimators. Our formula also corrects the over-identification bias in variance estimation on top of the commonly used finite sample correction of Windmeijer (2005), which corrects the bias from estimating the efficient weight matrix, so is doubly corrected. An important feature of the proposed double correction is that it automatically provides robustness to misspecification of the moment condition. In contrast, the conventional variance estimator and the Windmeijer correction are inconsistent under misspecification. That is, the double correction formula proposed in this paper provides a convenient way to obtain improved inference under correct specification and robustness against misspecification at the same time.",http://www.sciencedirect.com/science/article/pii/S0304407621000166
Journal of Econometrics,2022,Nonparametric estimation of the random coefficients model: An elastic net approach,"Florian Heiss, Stephan Hetzenecker and Maximilian Osterhaus","This paper investigates and extends the computationally attractive nonparametric random coefficients estimator of Fox et al. (2011). We show that their estimator is a special case of the nonnegative LASSO, explaining its sparse nature observed in many applications. Recognizing this link, we extend the estimator, transforming it into a special case of the nonnegative elastic net. The extension improves the estimator’s recovery of the true support and allows for more accurate estimates of the random coefficients’ distribution. Our estimator is a generalization of the original estimator and therefore, is guaranteed to have a model fit at least as good as the original one. A theoretical analysis of both estimators’ properties shows that, under conditions, our generalized estimator approximates the true distribution more accurately. Two Monte Carlo experiments and an application to a travel mode data set illustrate the improved performance of the generalized estimator.",http://www.sciencedirect.com/science/article/pii/S0304407621000178
Journal of Econometrics,2022,On LASSO for predictive regression,"Ji Hyung Lee, Zhentao Shi and Zhan Gao","Explanatory variables in a predictive regression typically exhibit low signal strength and various degrees of persistence. Variable selection in such a context is of great importance. In this paper, we explore the pitfalls and possibilities of the LASSO methods in this predictive regression framework. In the presence of stationary, local unit root, and cointegrated predictors, we show that the adaptive LASSO cannot asymptotically eliminate all cointegrating variables with zero regression coefficients. This new finding motivates a novel post-selection adaptive LASSO, which we call the twin adaptive LASSO (TAlasso), to restore variable selection consistency. Accommodating the system of heterogeneous regressors, TAlasso achieves the well-known oracle property. In contrast, conventional LASSO fails to attain coefficient estimation consistency and variable screening in all components simultaneously. We apply these LASSO methods to evaluate the short- and long-horizon predictability of S&P 500 excess returns.",http://www.sciencedirect.com/science/article/pii/S030440762100049X
Journal of Econometrics,2022,Transformations and moment conditions for dynamic fixed effects logit models,Yoshitsugu Kitazawa,"This study proposes transformations for dynamic fixed effects logit models. First, these transformations construct valid moment conditions for the case with neither explanatory variables nor time dummies. Using valid moment conditions, we can obtain the first-order condition of the conditional maximum likelihood estimator proposed by Chamberlain (1985). Next, we derive valid moment conditions based on the transformations for the cases with strictly exogenous continuous explanatory variables and/or time dummies when the number of time periods is four or more. Transformations of these moment conditions exactly coincide with a subset of those obtained by Honoré and Weidner (2020) using the functional differencing approach proposed by Bonhomme (2012).",http://www.sciencedirect.com/science/article/pii/S0304407621000464
Journal of Econometrics,2022,Testing the eigenvalue structure of spot and integrated covariance,"Prosper Dovonon, Abderrahim Taamouti and Julian Williams","For vector Itô semimartingale dynamics, we derive the asymptotic distributions of likelihood-ratio-type test statistics for the purpose of identifying the eigenvalue structure of both integrated and spot covariance matrices estimated using high-frequency data. Unlike the existing approaches where the cross-section dimension grows to infinity, our tests do not necessarily require large cross-section and thus allow for a wide range of applications. The tests, however, are based on non-standard asymptotic distributions with many nuisance parameters. Another contribution of this paper consists in proposing a bootstrap method to approximate these asymptotic distributions. While standard bootstrap methods focus on sampling point-wise returns, the proposed method replicates features of the asymptotic approximation of the statistics of interest that guarantee its validity. A Monte Carlo simulation study shows that the bootstrap-based test controls size and has power for even moderate size samples.",http://www.sciencedirect.com/science/article/pii/S0304407621000579
Journal of Econometrics,2022,Spurious functional-coefficient regression models and robust inference with marginal integration,Yundong Tu and Ying Wang,"Functional-coefficient cointegrating models have become popular to model nonlinear nonstationarity in econometrics (Cai et al., 2009; Xiao, 2009). However, there is rare study on testing the existence of functional-coefficient cointegration. Consequently, functional-coefficient regressions involving nonstationary regressors may be spurious. This paper investigates the effect that spurious functional-coefficient regression has on the model diagnostics. We find that common characteristics of spurious regressions are manifest, including divergent local significance tests, random local goodness-of-fit, and local Durbin–Watson ratio converging to zero, complementing those discovered in spurious linear and nonparametric regressions (Phillips, 1986, 2009). In addition, spuriousness causes the divergences of the global significance tests proposed by Xiao (2009) and Sun et al. (2016), which are likely to produce misleading conclusions for practitioners when cointegration tests fail to reject a spurious regression. To resolve the problems, we propose a simple-to-implement inference procedure based on a semiparametric balanced regression, by augmenting regressors of the original spurious regression with lagged dependent variable and independent variables, with the aid of the marginal integration. This procedure achieves spurious regression detection via standard nonparametric inferential asymptotics, and is found robust to the true relationship between the integrated processes. The theoretical results are also corroborated by simulations.",http://www.sciencedirect.com/science/article/pii/S0304407621000713
Journal of Econometrics,2022,Volatility of volatility: Estimation and tests based on noisy high frequency data with jumps,"Yingying Li, Guangying Liu and Zhiyuan Zhang","We establish a feasible central limit theorem with convergence rate n1/8 for the estimation of the integrated volatility of volatility (VoV) based on noisy high-frequency data with jumps. This is the first inference theory ever built for VoV estimation under such a general setup. The central limit theorem is applied to provide interval estimates of the VoV and conduct hypothesis tests. Furthermore, when one is interested in the null hypothesis that the VoV is zero, we show that a more powerful test can be established based on a VoV estimator with a convergence rate n1/5 under the null. Empirical results on the S&P 500 and individual stocks show strong evidence of non-zero VoV.",http://www.sciencedirect.com/science/article/pii/S0304407621000701
Journal of Econometrics,2022,Asymptotic properties of correlation-based principal component analysis,Jungjun Choi and Xiye Yang,"It is a common practice to conduct principal component analysis (PCA) using standardized data, which is equivalent to applying PCA to the correlation matrix rather than the covariance matrix. Yet little research has been done about such differences in the context of high frequency data. This paper bridges this gap. We derive the analytical forms of the asymptotic biases and variances for the estimators of the integrated eigenvalues and eigenvectors. Furthermore, we propose a novel jackknife-type estimator of the asymptotic variance of the integrated volatility functional estimator. This new variance estimator shows much better finite sample performances compared to other existing ones. This paper also proposes several statistical tests for some commonly tested hypotheses in the literature. Simulation results show that one will get misleading results if one uses the analytical results of the covariance case when applying PCA on the correlation matrix.",http://www.sciencedirect.com/science/article/pii/S0304407621002050
Journal of Econometrics,2022,An incidental parameters free inference approach for panels with common shocks,Artūras Juodis and Vasilis Sarafidis,"This paper develops a novel Method of Moments approach for panel data models with endogenous regressors and unobserved common factors. The proposed approach does not require estimating explicitly a large number of parameters in either time-series or cross-sectional dimension, T and N respectively. Hence, it is free from the incidental parameter problem. In particular, the proposed approach does not suffer from “Nickell bias” of order O(T−1), nor from bias terms that are of order O(N−1). Therefore, it can operate under substantially weaker restrictions compared to existing large T procedures. Two alternative GMM estimators are analyzed; one makes use of a fixed number of “averaged estimating equations” à la Anderson and Hsiao (1982), whereas the other one makes use of “stacked estimating equations”, the total number of which increases at the rate of O(T). It is demonstrated that both estimators are consistent and asymptotically mixed-normal as N→∞ for any value of T. Low-level conditions that ensure local and global identification in this setup are examined using several examples.",http://www.sciencedirect.com/science/article/pii/S0304407621001135
Journal of Econometrics,2022,Estimation and inference in heterogeneous spatial panels with a multifactor error structure,"Jia Chen, Yongcheol Shin and Chaowen Zheng","We develop a unifying econometric framework for the analysis of heterogeneous panel data models that can account for both spatial dependence and common factors. To tackle the challenging issues of endogeneity due to the spatial lagged term and the correlation between the regressors and factors, we propose the CCEX-IV estimation procedure that approximates factors by the cross-section averages of regressors and deals with the spatial endogeneity using the internal instrumental variables. We develop the individual and Mean Group estimators, and establish their consistency and asymptotic normality. By contrast, the Pooled estimator is shown to be inconsistent in the presence of parameter heterogeneity. Monte Carlo simulations confirm that the finite sample performance of the proposed estimators is quite satisfactory. We demonstrate the usefulness of our approach with an application to the house price growth for Local Authority Districts in the UK over 1997Q1–2016Q4.",http://www.sciencedirect.com/science/article/pii/S0304407621001433
Journal of Econometrics,2022,Factor models with local factors — Determining the number of relevant factors,Simon Freyaldenhoven,"We extend the theory on factor models by incorporating “local” factors into the model. Local factors affect only an unknown subset of the observed variables. This implies a continuum of eigenvalues of the covariance matrix, as is commonly observed in applications. We derive which factors are pervasive enough to be economically important and which factors are pervasive enough to be estimable using the common principal component estimator. We then introduce a new class of estimators to determine the number of those relevant factors. Unlike existing estimators, our estimators use not only the eigenvalues of the covariance matrix, but also its eigenvectors. We find that incorporating partial sums of the eigenvectors into our estimators leads to significant gains in performance in simulations.",http://www.sciencedirect.com/science/article/pii/S0304407621001275
Journal of Econometrics,2022,"Factor models with many assets: Strong factors, weak factors, and the two-pass procedure",Stanislav Anatolyev and Anna Mikusheva,"This paper re-examines the problem of estimating risk premia in unconditional linear factor pricing models. Typically, the data used in the empirical literature are characterized by weakness of some pricing factors, strong cross-sectional dependence in the errors, and (moderately) high cross-sectional dimensionality. Using an asymptotic framework where the number of assets/portfolios grows with the time span of the data while the risk exposures of weak factors are local-to-zero, we show that the conventional two-pass estimation procedure delivers inconsistent estimates of the risk premia. We propose a new estimation procedure based on sample-splitting instrumental variables regression. The proposed estimator of risk premia is robust to weak included factors and to the presence of strong unaccounted cross-sectional error dependence. We prove the consistency of the new estimator, establish asymptotically valid inferences using Wald statistics, verify performance of the new procedure in simulations, and revisit some empirical studies.",http://www.sciencedirect.com/science/article/pii/S0304407621000130
Journal of Econometrics,2022,Functional time series approach to analyzing asset returns co-movements,Patrick W. Saart and Yingcun Xia,"We introduce a new approach for modeling the time varying behavior and time series evolution of asset returns co-movements. Here, the co-movement in each period is captured by a trajectory of returns correlation, then a sequence of this over time and the time series evolution are studied. We rely on functional principal components to achieve dimension reduction and to construct the dynamic space of interest, while introducing a new class of information criteria in order to identify the finite dimensionality of the curve time series. Our method is able to combine two of the most applied ideas in the literature, namely economics (or finance) based and time-series based time-varying correlation models. This offers a general specification that is able to model processes of time-varying time-series correlations generated under many existing models that have dominated the financial literature for several decades. To illustrate its empirical relevance, we apply our method to model the time varying co-movement of exchange rate returns for a group of small open economies with large financial sectors. Our empirical results indicate that concepts of time varying correlation enabled by existing methods are too restrictive to accommodate fully the time varying behavior and time series evolution of the returns correlation. On the other hand, our method gives a more complete picture and is able to provide more accurate correlation forecasts.",http://www.sciencedirect.com/science/article/pii/S0304407621000804
Journal of Econometrics,2022,High-dimensional test for alpha in linear factor pricing models with sparse alternatives,"Long Feng, Wei Lan, Binghui Liu and Yanyuan Ma","We consider the problem of testing for the presence of alpha in Linear Factor Pricing Models. We propose a novel test of the max-of-squares type, which is designed to deal with the high dimensionality of the securities and the sparse alternatives. We rigorously show that the proposed test has attractive theoretical properties and demonstrate its superior performance via Monte Carlo experiments. These results are established when the number of securities is larger than the time dimension of the return series, and the alternative hypothesis is sparse, i.e. the alpha vector is sparse. As a general alternative, we suggest to combine the max-of-squares type test and a sum-of-squares type test, to benefit from the power advantages of both tests. We apply the two proposed tests to the monthly returns on securities in the Chinese and the U.S. stock markets, respectively under the Fama–French three-factor model, and confirm the usefulness of the proposed tests in detecting the presence of alpha.",http://www.sciencedirect.com/science/article/pii/S0304407621001962
Journal of Econometrics,2022,Kotlarski with a factor loading,Arthur Lewbel,"This note extends the Kotlarski (1967) Lemma to show exactly what is identified when we allow for an unknown factor loading on the common unobserved factor. That is, this note completely characterizes identification of the model Y = cV + U and X = V + W, where the joint distribution of Y and X is known, while the constant c and the mutually independent random variables V, U, and W are unobserved. Potential applications include measurement error models and panel data factor models.",http://www.sciencedirect.com/science/article/pii/S0304407621001603
Journal of Econometrics,2022,Maximum likelihood estimation and inference for high dimensional generalized factor models with application to factor-augmented regressions,Fa Wang,"This paper reestablishes the main results in Bai (2003) and Bai and Ng (2006) for generalized factor models, with slightly stronger conditions on the relative magnitude of N (number of subjects) and T (number of time periods). Convergence rates of the estimated factor space and loading space and asymptotic normality of the estimated factors and loadings are established under mild conditions that allow for linear, Logit, Probit, Tobit, Poisson and some other single-index nonlinear models. The probability density/mass function is allowed to vary across subjects and time, thus mixed models are also allowed for. For factor-augmented regressions, this paper establishes the limit distributions of the parameter estimates, the conditional mean, and the forecast when factors estimated from nonlinear/mixed data are used as proxies for the true factors.",http://www.sciencedirect.com/science/article/pii/S0304407620303894
Journal of Econometrics,2022,Projected estimation for large-dimensional matrix factor models,"Long Yu, Yong He, Xinbing Kong and Xinsheng Zhang","In this study, we propose a projection estimation method for large-dimensional matrix factor models with cross-sectionally spiked eigenvalues. By projecting the observation matrix onto the row or column factor space, we simplify factor analysis for matrix series to that of a lower-dimensional tensor. This method also reduces the magnitudes of the idiosyncratic error components, thereby increasing the signal-to-noise ratio, because the projection matrix linearly filters the idiosyncratic error matrix. We theoretically prove that the projected estimators of the factor loading matrices achieve faster convergence rates than existing estimators under similar conditions. Asymptotic distributions of the projected estimators are also presented. A novel iterative procedure is given to specify the pair of row and column factor numbers. Extensive numerical studies verify the empirical performance of the projection method. Two real examples in finance and macroeconomics reveal factor patterns across rows and columns, which coincide with financial, economic, or geographical interpretations.",http://www.sciencedirect.com/science/article/pii/S0304407621001123
Journal of Econometrics,2022,SONIC: SOcial Network analysis with Influencers and Communities,"Cathy Yi-Hsuan Chen, Wolfgang Härdle and Yegor Klochkov","The integration of social media characteristics into an econometric framework requires modeling a high dimensional dynamic network with dimensions of parameter typically much larger than the number of observations. To cope with this problem, we introduce SONIC, a new high-dimensional network model that assumes that (1) only few influencers drive the network dynamics; (2) the community structure of the network is characterized by homogeneity of response to specific influencers, implying their underlying similarity. An estimation procedure is proposed based on a greedy algorithm and LASSO regularization. Through theoretical study and simulations, we show that the matrix parameter can be estimated even when sample size is smaller than the size of the network. Using a novel dataset retrieved from one of leading social media platforms — StockTwits and quantifying their opinions via natural language processing, we model the opinions network dynamics among a select group of users and further detect the latent communities. With a sparsity regularization, we can identify important nodes in the network.",http://www.sciencedirect.com/science/article/pii/S0304407621000816
Journal of Econometrics,2022,Measuring news sentiment,"Adam Hale Shapiro, Moritz Sudhof and Daniel Wilson","This paper demonstrates state-of-the-art text sentiment analysis tools while developing a new time-series measure of economic sentiment derived from economic and financial newspaper articles from January 1980 to April 2015. We compare the predictive accuracy of a large set of sentiment analysis models using a sample of articles that have been rated by humans on a positivity/negativity scale. The results highlight the gains from combining existing lexicons and from accounting for negation. We also generate our own sentiment-scoring model, which includes a new lexicon built specifically to capture the sentiment in economic news articles. This model is shown to have better predictive accuracy than existing “off-the-shelf” models. Lastly, we provide two applications to the economic research on sentiment. First, we show that daily news sentiment is predictive of movements of survey-based measures of consumer sentiment. Second, motivated by Barsky and Sims (2012), we estimate the impulse responses of macroeconomic variables to sentiment shocks, finding that positive sentiment shocks increase consumption, output, and interest rates and dampen inflation.",http://www.sciencedirect.com/science/article/pii/S0304407620303535
Journal of Econometrics,2022,An explainable attention network for fraud detection in claims management,"Helmut Farbmacher, Leander Löw and Martin Spindler","Insurance companies must manage millions of claims per year. While most of these are not fraudulent, those that are nevertheless cost insurance companies and those they insure vast amounts of money. The ultimate goal is to develop a predictive model that can single out fraudulent claims and pay out non-fraudulent ones automatically. Health care claims have a peculiar data structure, comprising inputs of varying length and variables with a large number of categories. Both issues are challenging for traditional econometric methods. We develop a deep learning model that can handle these challenges by adapting methods from text classification. Using a large dataset from a private health insurer in Germany, we show that the model we propose outperforms a conventional machine learning model. With the rise of digitalization, unstructured data with characteristics similar to ours will become increasingly common in applied research, and methods to deal with such data will be needed.",http://www.sciencedirect.com/science/article/pii/S0304407620302852
Journal of Econometrics,2022,Can we measure inflation expectations using Twitter?,"Cristina Angelico, Juri Marcucci, Marcello Miccoli and Filippo Quarta","Drawing on Italian tweets, we employ textual data and machine learning techniques to build new real-time measures of consumers’ inflation expectations. First, we select keywords to identify tweets related to prices and expectations thereof. Second, we build a set of daily measures of inflation expectations around the selected tweets, combining the Latent Dirichlet Allocation (LDA) with a dictionary-based approach, using manually labeled bi-grams and tri-grams. Finally, we show that Twitter-based indicators are highly correlated with both monthly survey-based and daily market-based inflation expectations. Our new indicators anticipate consumers’ expectations, proving to be a good real-time proxy, and provide additional information beyond market-based expectations, professional forecasts, and realized inflation. The results suggest that Twitter can be a new timely source for eliciting beliefs.",http://www.sciencedirect.com/science/article/pii/S0304407622000227
Journal of Econometrics,2022,Instrument-free identification and estimation of differentiated products models using cost data,"David P. Byrne, Susumu Imai, Neelam Jain and Vasilis Sarafidis","We propose a new methodology for identifying and estimating demand in differentiated products models when demand and cost data are available. The method deals with the endogeneity of prices to demand shocks and the endogeneity of outputs to cost shocks by using cost data rather than instruments. Further, we allow for unobserved market size. Using Monte Carlo experiments, we show that our method works well in contexts where commonly used instruments are invalid. We also apply our method to the estimation of deposit demand in the US banking industry.",http://www.sciencedirect.com/science/article/pii/S0304407622000021
Journal of Econometrics,2022,Infinite Markov pooling of predictive distributions,"Xin Jin, John Maheu and Qiao Yang","This paper introduces novel approaches to forecast pooling methods based on a nonparametric prior for a weight vector combining predictive densities. The first approach places a Dirichlet process prior on the weight vector and generalizes the static linear pool. The second approach uses a hierarchical Dirichlet process prior to allow the weight vector to follow an infinite hidden Markov chain. This generalizes dynamic prediction pools to the nonparametric setting. Efficient posterior simulation based on MCMC methods is also examined. Detailed applications to short-term interest rates, realized covariance matrices and asset pricing models demonstrate that the nonparametric pool forecasts well. The paper concludes with extensions and an application for calibrating and combining predictive densities.",http://www.sciencedirect.com/science/article/pii/S0304407621002578
Journal of Econometrics,2022,Latent complementarity in bundles models,Roy Allen and John Rehbeck,"This paper studies partial identification of latent complementarity in an optimizing model with two goods and binary quantities of each good (buy/do not buy). We provide bounds on the fraction of individuals for whom goods are complements, or substitutes. When utility indices are unknown, we present simple bounds that require only the average structural function (“mean demands”). We show these simple bounds are sharp with only a binary demand shifter. Next, we characterize sharp bounds with richer variation in covariates when utility indices are known, using either the average structural function or structural choice probabilities. In simulations with binary variation in regressors for both goods, we find that the latter bounds coincide. Together, these results indicate that mean demands contain rich information for measuring complementarity without observing whether goods are chosen together.",http://www.sciencedirect.com/science/article/pii/S0304407621002438
Journal of Econometrics,2022,A stochastic dominance test under survey nonresponse with an application to comparing trust levels in Lebanese public institutions,"Ali Fakih, Paul Makdissi, Walid Marrouch, Rami V. Tabri and Myra Yazbeck","Stochastic dominance comparisons of distributions based on ordinal data arise in many areas of economics. This paper develops a testing procedure for such comparisons under survey sampling from large finite populations with nonresponse using the worst-case bounds of the distributions. The advantage of using these bounds in distributional comparisons is that conclusions are robust to the nature of the nonresponse-generating mechanism. While these bounds on the distributions are often too wide in practice, we show that they can be informative for distributional comparisons in an empirical analysis. This paper examines the dynamics of trust in Lebanese public institutions using the 2013 wave of the World Values Survey as well as the 2016 and 2018 waves of the Arab Barometer, and finds convincing evidence of a decrease in confidence in most public institutions between 2013 and 2016.",http://www.sciencedirect.com/science/article/pii/S0304407621002311
Journal of Econometrics,2022,Illuminating economic growth,Yingyao Hu and Jiaxiong Yao,"This paper seeks to illuminate national accounts GDP growth using satellite-recorded nighttime lights in a measurement error model framework. Using recently developed results in conjunction with reasonable assumptions about the exogeneity of the lights data generating process, we identify and estimate the relationship between nighttime light growth and GDP growth, as well as the nonparametric distribution of errors in both measures. We obtain three key results: (i) the elasticity of nighttime lights to GDP is about 1.3; (ii) national accounts GDP growth measures are less precise for low and middle income countries, and nighttime lights can play a big role in improving such measures; and (iii) our new measure of GDP growth, based on the optimal combination of nighttime lights and national accounts data under our identification assumptions, implies that China and India had considerably lower growth rates than official data suggested between 1993 and 2013. We expect our statistical framework and methodology to have a broad impact on measuring GDP using additional information.",http://www.sciencedirect.com/science/article/pii/S0304407621001767
Journal of Econometrics,2022,An integrated panel data approach to modelling economic growth,"Guohua Feng, Jiti Gao and Bin Peng","Empirical growth analysis is plagued with three problems – variable selection, parameter heterogeneity and cross-sectional dependence – which are addressed independently from each other in most studies. This study is to propose an integrated framework that allows for parameter heterogeneity and cross-sectional error dependence, while simultaneously performing variable selection. We derive the asymptotic properties of the estimator, and apply the framework to a dataset of 89 countries over the period from 1960 to 2014. Our results support the “optimistic” conclusion of Sala-I-Martin (1997), and also reveal some cross-country patterns not found previously.",http://www.sciencedirect.com/science/article/pii/S0304407621000014
Journal of Econometrics,2022,High-dimensional linear models with many endogenous variables,"Alexandre Belloni, Christian Hansen and Whitney Newey","High-dimensional linear models with endogenous variables play an increasingly important role in the recent econometric literature. In this work, we allow for models with many endogenous variables and make use of many instrumental variables to achieve identification. Because of the high-dimensionality in the structural equation, constructing honest confidence regions with asymptotically correct coverage is non-trivial. Our main contribution is to propose estimators and confidence regions that achieve this goal.",http://www.sciencedirect.com/science/article/pii/S0304407621002220
Journal of Econometrics,2022,Nonparametric Bayes subject to overidentified moment conditions,A. Ronald Gallant,Nonparametric Bayesian estimation subject to overidentified moment equations is a challenge because the support of the posterior is a manifold of lower dimension than the number of model parameters. The manifold therefore has Lebesgue measure zero thus inhibiting the use of the most commonly used Bayesian estimation method: MCMC (Markov Chain Monte Carlo). This study proposes an effective MCMC algorithm and algorithms for estimating scale and the normalizing constant. The algorithms are illustrated with two illustrative applications.,http://www.sciencedirect.com/science/article/pii/S0304407621000555
Journal of Econometrics,2022,Estimation and inference for the counterfactual distribution and quantile functions in continuous treatment models,"Chunrong Ai, Oliver Linton and Zheng Zhang","Donald and Hsu (2014) studied the estimation and inference for the counterfactual distribution and quantile functions in a binary treatment model. We extend their work to the continuous treatment model. Specifically, we propose a weighted regression estimator for the counterfactual distribution but we estimate the weighting function from a covariate balancing equation by maximizing a globally concave criterion function. We estimate the quantile function by inverting the estimated counterfactual distribution. To test the distributional effect, we consider the (uniform) confidence bands, the sup and L2 distance, and the Mann–Whitney test. We also consider the stochastic dominance test for the distributional effect and the L2 test for constant quantiles. A simulation study reveals that our tests exhibit a satisfactory finite-sample performance, and an application shows their practical value.",http://www.sciencedirect.com/science/article/pii/S0304407621000543
Journal of Econometrics,2022,Bayesian estimation of long-run risk models using sequential Monte Carlo,"Andras Fulop, Jeremy Heng, Junye Li and Hening Liu","We propose a likelihood-based Bayesian method that exploits up-to-date sequential Monte Carlo methods to efficiently estimate long-run risk models in which the conditional variance of consumption growth follows either an autoregressive (AR) process or an autoregressive gamma (ARG) process. We use the U.S. quarterly consumption and asset returns data from the postwar period to implement estimation. Our findings are: (1) informative priors on the preference parameters can help to improve model performance; (2) expected consumption growth has a very persistent component, whereas consumption volatility is less persistent; (3) while the ARG-based model performs better than the AR-based one statistically, the latter could fit asset returns better; and (4) the solution method matters more for estimation in the AR-based model than in the ARG-based model.",http://www.sciencedirect.com/science/article/pii/S0304407621000531
Journal of Econometrics,2022,Constrained estimation using penalization and MCMC,"A. Ronald Gallant, Han Hong, Michael Leung and Jessie Li","We study inference for parameters defined by either classical extremum estimators or Laplace-type estimators subject to general nonlinear constraints on the parameters. We show that running MCMC on the penalized version of the problem offers a computationally attractive alternative to solving the original constrained optimization problem. Bayesian credible intervals are asymptotically valid confidence intervals in a pointwise sense, providing exact asymptotic coverage for general functions of the parameters. We allow for nonadaptive and adaptive penalizations using the ℓp for p⩾1 penalty functions. These methods are motivated by and include as special cases model selection and shrinkage methods such as the LASSO and its Bayesian and adaptive versions. A simulation study validates the theoretical results. We also provide an empirical application on estimating the joint density of U.S. real consumption and asset returns subject to Euler equation constraints in a CRRA asset pricing model.",http://www.sciencedirect.com/science/article/pii/S030440762100052X
Journal of Econometrics,2022,Robust Bayesian inference in proxy SVARs,"Raffaella Giacomini, Toru Kitagawa and Matthew Read","We develop methods for robust Bayesian inference in structural vector autoregressions (SVARs) where the parameters of interest are set-identified using external instruments, or ‘proxy SVARs’. Set-identification in these models typically occurs when there are multiple instruments for multiple structural shocks. Existing Bayesian approaches to inference in proxy SVARs require researchers to specify a single prior over the model’s parameters, but, under set-identification, a component of the prior is never revised. We extend the robust Bayesian approach to inference in set-identified models proposed by Giacomini and Kitagawain press[a] – which allows researchers to relax potentially controversial point-identifying restrictions without having to specify an unrevisable prior – to proxy SVARs. We provide new results on the frequentist validity of the approach in proxy SVARs. We also explore the effect of instrument strength on inference about the identified set. We illustrate our approach by revisiting Mertens and Ravn (2013) and relaxing the assumption that they impose to obtain point identification.",http://www.sciencedirect.com/science/article/pii/S0304407621000518
Journal of Econometrics,2022,Copula-based time series with filtered nonstationarity,"Xiaohong Chen, Zhijie Xiao and Bo Wang","Economic and financial time series data can exhibit nonstationary and nonlinear patterns simultaneously. This paper studies copula-based time series models that capture both patterns. We introduce a procedure where nonstationarity is removed via a filtration, and then the nonlinear temporal dependence in the filtered data is captured via a flexible Markov copula. We propose two estimators of the copula dependence parameters: the parametric (two-step) copula estimator where the marginal distribution of the filtered series is estimated parametrically; and the semiparametric (two-step) copula estimator where the marginal distribution is estimated via a rescaled empirical distribution of the filtered series. We show that the limiting distribution of the parametric copula estimator depends on the nonstationary filtration and the parametric marginal distribution estimation, and may be non-normal. Surprisingly, the limiting distribution of the semiparametric copula estimator using the filtered data is shown to be the same as that without nonstationary filtration, which is normal and free of marginal distribution specification. The simple and robust properties of the semiparametric copula estimators extend to models with misspecified copulas, and facilitate statistical inferences, such as hypothesis testing and model selection tests, on semiparametric copula-based dynamic models in the presence of nonstationarity. Monte Carlo studies and real data applications are presented.",http://www.sciencedirect.com/science/article/pii/S0304407620303808
Journal of Econometrics,2022,Variation and efficiency of high-frequency betas,"Congshan Zhang, Jia Li, Viktor Todorov and George Tauchen","This paper studies the efficient estimation of betas from high-frequency return data on a fixed time interval. Under an assumption of equal diffusive and jump betas, we derive the semiparametric efficiency bound for estimating the common beta and develop an adaptive estimator that attains the efficiency bound. We further propose a Hausman type test for deciding whether the common beta assumption is true from the high-frequency data. In our empirical analysis we provide examples of stocks and time periods for which a common market beta assumption appears true and ones for which this is not the case. We further quantify empirically the gains from the efficient common beta estimation developed in the paper.",http://www.sciencedirect.com/science/article/pii/S0304407620303778
Journal of Econometrics,2022,Stationary vine copula models for multivariate time series,"Thomas Nagler, Daniel Krüger and Aleksey Min","Multivariate time series exhibit two types of dependence: across variables and across time points. Vine copulas are graphical models for the dependence and can conveniently capture both types of dependence in the same model. We derive the maximal class of graph structures that guarantee stationarity under a natural and verifiable condition called translation invariance. We propose computationally efficient methods for estimation, simulation, prediction, and uncertainty quantification and show their validity by asymptotic results and simulations. The theoretical results allow for misspecified models and, even when specialized to the iid case, go beyond what is available in the literature. The new model class is illustrated by an application to forecasting returns of a portfolio of 20 stocks, where they show excellent forecast performance. The paper is accompanied by an open source software implementation.",http://www.sciencedirect.com/science/article/pii/S0304407621003043
Journal of Econometrics,2022,Maximum likelihood estimation for score-driven models,"Francisco Blasques, Janneke van Brummelen, Siem Jan Koopman and Andre Lucas","We establish strong consistency and asymptotic normality of the maximum likelihood estimator for stochastic time-varying parameter models driven by the score of the predictive conditional likelihood function. For this purpose, we formulate primitive conditions for global identification, invertibility, strong consistency, and asymptotic normality both under correct specification and misspecification of the model. A detailed illustration is provided for a conditional volatility model with disturbances from the Student’s t distribution.",http://www.sciencedirect.com/science/article/pii/S0304407621001743
Journal of Econometrics,2022,Semiparametric testing with highly persistent predictors,Bas J.M. Werker and Bo Zhou,"We address the issue of semiparametric efficiency in the bivariate regression problem with a highly persistent predictor, where the joint distribution of the innovations is regarded an infinite-dimensional nuisance parameter. Using a structural representation of the limit experiment and exploiting invariance relationships therein, we construct invariant point-optimal tests for the regression coefficient of interest. This approach naturally leads to a family of feasible tests based on the component-wise ranks of the innovations that can gain considerable power relative to existing tests under non-Gaussian innovation distributions, while behaving equivalently under Gaussianity. When an i.i.d. assumption on the innovations is appropriate for the data at hand, our tests exploit the efficiency gains possible. Moreover, we show by simulation that our test remains well behaved under some forms of conditional heteroskedasticity.",http://www.sciencedirect.com/science/article/pii/S0304407621001573
Journal of Econometrics,2022,Functional coefficient panel modeling with communal smoothing covariates,Peter Phillips and Ying Wang,"Behavior at the individual level in panels is often influenced by aspects of the system in aggregate. In particular, the interaction between individual-specific explanatory variables and an individual dependent variable may be affected by ‘global’ variables that are relevant in decision making and shared communally by all individuals in the sample. To capture such behavioral features, we employ a functional coefficient panel model in which certain communal covariates may jointly influence panel interactions by means of their impact on the model coefficients. Two classes of estimation procedures are proposed, one based on cross-section averaged data, the other on the full panel. The asymptotic properties of these methods are obtained and compared, allowing for sequential and joint expansion of the cross-section and time series sample sizes. Limit theory for the associated fixed effects estimators is derived and inferential procedures are developed to test hypotheses concerning the functional coefficients. The finite sample performance of the proposed estimators and tests are examined by simulation. An empirical illustration is provided in which the regional sensitivity of housing rental prices to available job numbers is studied with national labor force participation rate as the communal smoothing covariate. Strong evidence is found supporting the functional coefficient specification with this country-wide smoothing variable.",http://www.sciencedirect.com/science/article/pii/S0304407621000944
Journal of Econometrics,2022,Simultaneous inference for time-varying models,"Sayar Karmakar, Stefan Richter and Wei Biao Wu","A general class of non-stationary time series is considered in this paper. We estimate the time-varying coefficients by using local linear M-estimation. For these estimators, weak Bahadur representations are obtained and are used to construct simultaneous confidence bands. For practical implementation, we propose a bootstrap based method to circumvent the slow logarithmic convergence of the theoretical simultaneous bands. Our results substantially generalize and unify the treatments for several time-varying regression and auto-regression models. The performance for tvARCH and tvGARCH models is studied in simulations and a few real-life applications of our study are presented through the analysis of some popular financial datasets.",http://www.sciencedirect.com/science/article/pii/S0304407621000725
Journal of Econometrics,2022,Residual-augmented IVX predictive regression,Matei Demetrescu and Paulo Rodrigues,"Bias correction in predictive regressions is known to reduce the empirical size problems of OLS-based predictability tests with persistent predictors. This paper shows that bias correction is also achieved in the context of the extended instrumental variable (IVX) predictability testing framework introduced by Kostakis et al. (2015). To be specific, new IVX-based statistics subject to a bias correction analogous to that proposed by Amihud and Hurvich (2004) are introduced. Four important contributions are provided: first, we characterize the effects that bias-reduction adjustments have on the asymptotic distributions of the IVX test statistics in a general context allowing for short-run dynamics and heterogeneity; second, we discuss the validity of the procedure when predictors are stationary as well as near-integrated; third, we conduct an exhaustive Monte Carlo analysis to investigate the small in- and out-of-sample properties of the test procedures and their sensitivity to distinctive features that characterize predictive regressions in practice, such as strong persistence, endogeneity, and non-Gaussian innovations; and fourth, we provide an analysis of real estate return and rent growth predictability in 19 OECD countries.",http://www.sciencedirect.com/science/article/pii/S030440762030395X
Journal of Econometrics,2022,The drift burst hypothesis,"Kim Christensen, Roel Oomen and Roberto Renò","The drift burst hypothesis postulates the existence of short-lived locally explosive trends in the price paths of financial assets. The recent U.S. equity and treasury flash crashes can be viewed as two high-profile manifestations of such dynamics, but we argue that drift bursts of varying magnitude are an expected and regular occurrence in financial markets that can arise through established mechanisms of liquidity provision. We show how to build drift bursts into the continuous-time Itô semimartingale model, elaborate on the conditions required for the process to remain arbitrage-free, and propose a nonparametric test statistic that identifies drift bursts from noisy high-frequency data. We apply the test and demonstrate that drift bursts are a stylized fact of the price dynamics across equities, fixed income, currencies and commodities. Drift bursts occur once a week on average, and the majority of them are accompanied by subsequent price reversion and can thus be regarded as “flash crashes.” The reversal is found to be stronger for negative drift bursts with large trading volume, which is consistent with endogenous demand for immediacy during market crashes.",http://www.sciencedirect.com/science/article/pii/S0304407620303912
Journal of Econometrics,2022,Comment on “Large Bayesian vector autoregressions with stochastic volatility and non-conjugate priors”,Mark Bognanni,"Fully Bayesian inference in a vector autoregression with stochastic volatility (VAR-SV) typically relies on simulations from a multi-step Markov chain Monte Carlo (MCMC) algorithm. Carriero et al. (2019) propose a new, faster, “triangular” algorithm (TA) to replace the systemwide algorithm (SWA) in the most time-consuming step of the VAR-SV’s standard MCMC algorithm. This paper analytically shows that the TA and SWA generally sample from different distributions, thereby disproving a central claim of Carriero et al. (2019). Replacing the SWA with the TA thus results in an ad hoc change to the MCMC algorithm’s transition kernel, leaving a priori unknown the formal relationship between the model’s posterior and simulations from the MCMC algorithm using the TA.",http://www.sciencedirect.com/science/article/pii/S0304407621002554
Journal of Econometrics,2022,Goodness-of-fit testing for time series models via distance covariance,Phyllis Wan and Richard A. Davis,"In many statistical modeling frameworks, goodness-of-fit tests are typically administered to the estimated residuals. In the time series setting, whiteness of the residuals is assessed using the sample autocorrelation function. For many time series models, especially those used for financial time series, the key assumption on the residuals is that they are in fact independent and not just uncorrelated. In this paper, we apply the auto-distance covariance function (ADCV) to evaluate the serial dependence of the estimated residuals. Distance covariance can discriminate between dependence and independence of two random vectors. The limit behavior of the test statistic based on the ADCV is derived for a general class of time series models. One of the key aspects in this theory is adjusting for the dependence that arises due to parameter estimation. This adjustment has essentially the same form regardless of the model specification. We illustrate the results in simulated examples.",http://www.sciencedirect.com/science/article/pii/S0304407620302256
Journal of Econometrics,2022,Understanding temporal aggregation effects on kurtosis in financial indices,Offer Lieberman and Peter Phillips,"Indices of financial returns typically display sample kurtosis that declines towards the Gaussian value 3 as the sampling interval increases. This paper uses stochastic unit root (STUR) and continuous time analysis to explain the phenomenon. Limit theory for the sample kurtosis reveals that STUR specifications provide two sources of excess kurtosis, both of which decline with the sampling interval. Limiting kurtosis is shown to be random and is a functional of the limiting price process. Using a continuous time version of the model under no-drift, local drift, and drift inclusions, we suggest a new continuous time kurtosis measure for financial returns that assists in reconciling these models with the empirical kurtosis characteristics of returns. Simulations are reported and applications to several financial indices demonstrate the usefulness of this approach.",http://www.sciencedirect.com/science/article/pii/S030440762030258X
Journal of Econometrics,2022,Testing the existence of moments for GARCH processes,Christian Francq and Jean-Michel Zakoian,"It is generally admitted that many financial time series have heavy tailed marginal distributions. When time series models are fitted on such data, the non-existence of appropriate moments may invalidate standard statistical tools used for inference. Moreover, the existence of moments can be crucial for risk management, for instance when risk is measured through the expected shortfall. This paper considers testing the existence of moments in the framework of GARCH processes. While the second-order stationarity condition does not depend on the distribution of the innovation, higher-order moment conditions involve moments of the independent innovation process. We propose tests for the existence of high moments of the returns process which are based on the joint asymptotic distribution of the Quasi-Maximum Likelihood (QML) estimator of the volatility parameters and empirical moments of the residuals. A bootstrap procedure is proposed to improve the finite-sample performance of our test. To achieve efficiency gains we consider non Gaussian QML estimators founded on reparameterizations of the GARCH model, and we discuss optimality issues. Monte Carlo experiments and an empirical study illustrate the asymptotic results.",http://www.sciencedirect.com/science/article/pii/S0304407620302268
Journal of Econometrics,2022,A time-varying parameter model for local explosions,"Francisco Blasques, Siem Jan Koopman and Marc Nientker","Financial and economic time series can feature locally explosive behaviour when bubbles are formed. We develop a time-varying parameter model that is capable of describing this behaviour in time series data. Our proposed dynamic model can be used to predict the emergence, existence and burst of bubbles. We adopt a flexible observation driven model specification that allows for different bubble shapes and behaviour. We establish stationarity, ergodicity, and bounded moments of the data generated by our model. Furthermore, we obtain the consistency and asymptotic normality of the maximum likelihood estimator. Given the parameter estimates in the model, the implied filter is capable of extracting the unobserved bubble process from the observed data. We study finite-sample properties of our estimator through a Monte Carlo simulation study. Finally, we show that our model compares well with existing noncausal models in a financial application concerning the Bitcoin/US dollar exchange rate.",http://www.sciencedirect.com/science/article/pii/S0304407621001846
Journal of Econometrics,2022,Testing for episodic predictability in stock returns,"Matei Demetrescu, Iliyan Georgiev, Paulo Rodrigues and Robert Taylor","Standard tests based on predictive regressions estimated over the full available sample data have tended to find little evidence of predictability in stock returns. Recent approaches based on the analysis of subsamples of the data suggest in fact that predictability where it occurs might exist only within so-called “pockets of predictability” rather than across the entire sample. However, these methods are prone to the criticism that the subsample dates are endogenously determined such that the use of standard critical values appropriate for full sample tests will result in incorrectly sized tests leading to spurious findings of stock returns predictability. To avoid the problem of endogenously-determined sample splits, we propose new tests derived from sequences of predictability statistics systematically calculated over subsamples of the data. Specifically, we will base tests on the maximum of such statistics from sequences of forward and backward recursive, rolling, and double-recursive predictive subsample regressions. We develop our approach using the over-identified instrumental variable-based predictability test statistics of Breitung and Demetrescu (2015). This approach is based on partial-sum asymptotics and so, unlike many other popular approaches including, for example, those based on Bonferroni corrections, can be readily adapted to implementation over sequences of subsamples. We show that the limiting null distributions of our proposed test statistics depend in general on whether the putative predictor is strongly or weakly persistent and on any heteroskedasticity present (indeed on any time-variation present in the unconditional variance matrix of the innovations), the latter even if the subsample statistics are based on heteroskedasticity-robust standard errors. As a consequence, we develop fixed regressor wild bootstrap implementations of the tests which we demonstrate to be first-order asymptotically valid. Finite sample behaviour against a variety of temporarily predictable processes is considered. An empirical application to US stock returns illustrates the usefulness of the new predictability testing methods we propose.",http://www.sciencedirect.com/science/article/pii/S0304407620300026
Journal of Econometrics,2022,Testing capital asset pricing models using functional-coefficient panel data models with cross-sectional dependence,"Zongwu Cai, Ying Fang and Qiuhua Xu","This paper proposes a functional-coefficient panel data model with cross-sectional dependence motivated by re-examining the empirical performance of conditional capital asset pricing model. In order to characterize the time-varying property of assets’ betas and alpha, our proposed model allows the betas to be unknown functions of some macroeconomic and financial instruments. Moreover, a common factor structure is introduced to characterize cross-sectional dependence which is an attractive feature under a panel data regression setting as different assets or portfolios may be affected by same unobserved shocks. Compared to the existing studies, such as the classic Fama–MacBeth two-step procedure, our model can achieve substantial efficiency gains for inference by adopting a one-step procedure using the entire sample rather than a single cross-sectional regression at each time point. We propose a local linear common correlated effects estimator for estimating time-varying betas by pooling the data. The consistency and asymptotic normality of the proposed estimators are established. Another methodological and empirical challenge in asset pricing is how to test the constancy of conditional betas and the significance of pricing errors, we echo this challenge by constructing an L2-norm statistic for functional-coefficient panel data models allowing for cross-sectional dependence. We show that the new test statistic has a limiting standard normal distribution under the null hypothesis. Finally, the method is applied to test the model in Fama and French (1993) using Fama–French 25 and 100 portfolios, sorted by size and book-to-market ratio, respectively, dated from July 1963 to July 2018.",http://www.sciencedirect.com/science/article/pii/S0304407620302086
Journal of Econometrics,2022,β in the tails,Federico M. Bandi and Roberto Renò,"Do hedge funds hedge? In negative states of the world, often not as much as they should. For several styles, we report larger market betas when market returns are low (i.e., “beta in the tails”). We justify this finding through a combination of negative-mean jumps in the market returns and large market jump betas: when moving to the left tail of the market return distribution jump dynamics dominate continuous dynamics and the overall systematic risk of the fund is driven by the higher systematic risk associated with return discontinuities. Methodologically, the separation of continuous and discontinuous dynamics is conducted by exploiting the informational content of the high-order infinitesimal cross-moments of hedge-fund and market returns.",http://www.sciencedirect.com/science/article/pii/S0304407620302128
Journal of Econometrics,2022,Efficient estimation of high-dimensional dynamic covariance by risk factor mapping: Applications for financial risk management,"Mike K.P. So, Thomas W.C. Chan and Amanda M.Y. Chu","This paper aims to explore a modified method of high-dimensional dynamic variance–covariance matrix estimation via risk factor mapping, which can yield a dependence estimation of asset returns within a large portfolio with high computational efficiency. The essence of our methodology is to express the time-varying dependence of high-dimensional return variables using the co-movement concept of returns with respect to risk factors. A novelty of the proposed methodology is to allow mapping matrices, which govern the co-movement of returns, to be time-varying. We also consider the flexible modeling of risk factors by a copula multivariate generalized autoregressive conditional heteroscedasticity (MGARCH) model. Through the proposed risk factor mapping model, the number of parameters and the time complexity are functions of a small number of risk factors instead of the number of stocks in the portfolio, making our proposed methodology highly scalable. We adopt Bayesian methods to estimate unknown parameters and various risk measures in the proposed model. The proposed risk mapping method and financial applications are demonstrated by an empirical study of the Hong Kong stock market. The assessment of the effectiveness of the mapping via risk measure estimation is also discussed.",http://www.sciencedirect.com/science/article/pii/S0304407620301664
Journal of Econometrics,2022,Asset selection based on high frequency Sharpe ratio,"Christina Dan Wang, Zhao Chen, Yimin Lian and Min Chen","In portfolio choice problems, the classical Mean–Variance model in Markowitz (1952) relies heavily on the covariance structure among assets. As the number and types of assets increase rapidly, traditional methods to estimate the covariance matrix and its inverse suffer from the common issues in high or ultra-high dimensional analysis. To avoid the issue of estimating the covariance matrix with high or ultra-high dimensional data, we propose a fast procedure to reduce dimension based on a new risk/return measure constructed from intra-day high frequency data and select assets via Dependent Sure Explained Variability and Independence Screening (D-SEVIS). While most feature screening methods assume i.i.d. samples, by nature of our data, we make contribution to studying D-SEVIS for samples with serial correlation, specifically, for the stationary α-mixing processes. Under α-mixing condition, we prove that D-SEVIS satisfies sure screening property and ranking consistency property. More importantly, with the assets selected through D-SEVIS, we will build a portfolio that earns more excess return compared with several existing portfolio allocation methods. We illustrate this advantage of our asset selection method with the real data from the stock market.",http://www.sciencedirect.com/science/article/pii/S0304407620302244
Journal of Econometrics,2022,Occupation density estimation for noisy high-frequency data,"Congshan Zhang, Jia Li and Tim Bollerslev","This paper studies the nonparametric estimation of occupation densities for semimartingale processes observed with noise. As leading examples we consider the stochastic volatility of a latent efficient price process, the volatility of the latent noise that separates the efficient price from the actually observed price, and nonlinear transformations of these processes. Our estimation methods are decidedly nonparametric and consist of two steps: the estimation of the spot price and noise volatility processes based on pre-averaging techniques and in-fill asymptotic arguments, followed by a kernel-type estimation of the occupation densities. Our spot volatility estimates attain the optimal rate of convergence, and are robust to leverage effects, price and volatility jumps, general forms of serial dependence in the noise, and random irregular sampling. The convergence rates of our occupation density estimates are directly related to that of the estimated spot volatilities and the smoothness of the true occupation densities. An empirical application involving high-frequency equity data illustrates the usefulness of the new methods in illuminating time-varying risks, market liquidity, and informational asymmetries across time and assets.",http://www.sciencedirect.com/science/article/pii/S030440762030230X
Journal of Econometrics,2022,Identification of structural multivariate GARCH models,"Christian Hafner, Helmut Herwartz and Simone Maxand","The class of multivariate GARCH models is widely used to quantify and monitor volatility and correlation dynamics of financial time series. While many specifications have been proposed in the literature, these models are typically silent about the system inherent transmission of implied orthogonalized shocks to vector returns. In a framework of non-Gaussian independent structural shocks, this paper proposes a loss statistic, based on higher order co-moments, to discriminate in a data-driven way between alternative structural assumptions about the transmission scheme, and hence identify the structural model. Consistency of identification is shown theoretically and via a simulation study. In its structural form, a four dimensional system comprising US and Latin American stock market returns points to a substantial volatility transmission from the US to the Latin American markets. The identified structural model improves the estimation of classical measures of portfolio risk, as well as corresponding variations.",http://www.sciencedirect.com/science/article/pii/S0304407620302098
Journal of Econometrics,2022,"LADE-based inferences for autoregressive models with heavy-tailed G-GARCH(1, 1) noise","Xingfa Zhang, Rongmao Zhang, Yuan Li and Shiqing Ling","This paper explores the least absolute deviation (LAD) estimator of the autoregressive model with heavy-tailed G-GARCH(1, 1) noise. When the tail index α∈(1,2], it is shown that the LAD estimator asymptotically converges to a linear function of a series of α-stable random vectors with a rate of convergence n1−1/α. The result is significantly different from that of the corresponding least square estimator which is not consistent, and partially solves the problem on the asymptoticity of the LAD estimator when the tail index is less than 2. A simulation study is carried out to assess the performance of the LAD estimator and a real example is given to illustrate this approach.",http://www.sciencedirect.com/science/article/pii/S0304407620303742
Journal of Econometrics,2022,"Bootstrap inference on the boundary of the parameter space, with application to conditional volatility models","Giuseppe Cavaliere, Heino Bohn Nielsen, Rasmus Søndergaard Pedersen and Anders Rahbek","It is a well-established fact that – with an unknown number of nuisance parameters at the boundary – testing a null hypothesis on the boundary of the parameter space is infeasible in practice as the limiting distributions of standard test statistics are non-pivotal. In particular, likelihood ratio statistics have limiting distributions which can be characterized in terms of quadratic forms minimized over cones, where the shape of the cones depends on the unknown location of the (possibly multiple) model parameters not restricted by the null hypothesis. We propose to solve this inference problem by a novel bootstrap, which we show to be valid under general conditions, irrespective of the presence of (unknown) nuisance parameters on the boundary. That is, the new bootstrap replicates the unknown limiting distribution of the likelihood ratio statistic under the null hypothesis and is bounded (in probability) under the alternative. The new bootstrap approach, which is very simple to implement, is based on shrinkage of the parameter estimates used to generate the bootstrap sample toward the boundary of the parameter space at an appropriate rate. As an application of our general theory, we treat the problem of inference in finite-order ARCH models with coefficients subject to inequality constraints. Extensive Monte Carlo simulations illustrate that the proposed bootstrap has attractive finite sample properties both under the null and under the alternative hypothesis.",http://www.sciencedirect.com/science/article/pii/S0304407620302232
Journal of Econometrics,2022,Hybrid quantile estimation for asymmetric power GARCH models,"Guochang Wang, Ke Zhu, Guodong Li and Wai Keung Li","Asymmetric power GARCH models have been widely used to study the higher order moments of financial returns, while their quantile estimation has been rarely investigated. This paper introduces a simple monotonic transformation on its conditional quantile function to make the quantile regression tractable. The asymptotic normality of the resulting quantile estimators is established under either stationarity or non-stationarity. Moreover, based on the estimation procedure, new tests for strict stationarity and asymmetry are also constructed. This is the first try of the quantile estimation for non-stationary ARCH-type models in the literature. The usefulness of the proposed methodology is illustrated by simulation results and real data analysis.",http://www.sciencedirect.com/science/article/pii/S0304407620302220
Journal of Econometrics,2022,"Realized matrix-exponential stochastic volatility with asymmetry, long memory and higher-moment spillovers","Manabu Asai, Chia-Lin Chang and Michael McAleer","The paper develops a novel realized matrix-exponential stochastic volatility model of multivariate returns and realized covariances that incorporates asymmetry and long memory (hereafter the RMESV-ALM model), and higher-moment spillovers. The matrix exponential transformation guarantees the positive definiteness of the dynamic covariance matrix. We decompose the likelihood function of the RMESV-ALM model into two components: one based on the conventional Kalman filter, and the other evaluated by a Monte Carlo likelihood technique. We consider a two-step quasi-maximum likelihood estimator for maximizing the likelihood function, and examine the finite sample properties of the estimator. The specification enables us to analyze asymmetric and higher-moment spillover effects in the covariance dynamics via news impact curves and impulse response functions. Using high frequency data for three US financial assets, the new model is estimated and evaluated. The forecasting performance of the new model is compared with a novel dynamic realized matrix-exponential conditional covariance model. Our empirical results suggest the RMESV-ALE specification to be superior, and spillover effects are found from returns or volatility to the remaining volatilities.",http://www.sciencedirect.com/science/article/pii/S0304407621001809
Journal of Econometrics,2022,"Identification of semiparametric model coefficients, with an application to collective households",Arthur Lewbel and Xirong Lin,"We prove identification of coefficients for a set of semiparametric specifications that are related to multiple index models. Potential applications of these results include models of observed heterogeneity in production functions and in consumer demand systems. We then generalize these results to identify a class of collective household consumption models. We extend the existing literature by proving point identification, rather than the weaker generic identification, of all the features of the collective household model, including price effects. We estimate the model using Japanese consumption data, and find substantial variation in resource shares and indifference scales across households of different sizes.",http://www.sciencedirect.com/science/article/pii/S0304407621001834
Journal of Econometrics,2022,Quantile regression methods for first-price auctions,Nathalie Gimenes and Emmanuel Guerre,"The paper proposes a quantile-regression inference framework for first-price auctions with symmetric risk-neutral bidders under the independent private-value paradigm. It is first shown that a private-value quantile regression generates a quantile regression for the bids. The private-value quantile regression can be easily estimated from the bid quantile regression and its derivative with respect to the quantile level. This also allows to test for various specification or exogeneity null hypothesis using the observed bids in a simple way. A new local polynomial technique is proposed to estimate the latter over the whole quantile level interval. Plug-in estimation of functionals is also considered, as needed for the expected revenue or the case of CRRA risk-averse bidders, which is amenable to our framework. A quantile-regression analysis to USFS timber is found more appropriate than the homogenized-bid methodology and illustrates the contribution of each explanatory variable to the private-value distribution. Linear interactive sieve extensions are proposed and studied in the Appendices.",http://www.sciencedirect.com/science/article/pii/S0304407621001524
Journal of Econometrics,2022,Inference on estimators defined by mathematical programming,"Yu-Wei Hsieh, Xiaoxia Shi and Matthew Shum","We propose an inference procedure for a class of estimators defined as the solutions to linear and convex quadratic programming problems in which the coefficients in both the objective function and the constraints of the problem are estimated from data and hence involve sampling error. We argue that the Karush–Kuhn–Tucker conditions that characterize the solutions to these programming problems can be treated as moment conditions; by doing so, we transform the problem of inference on the solution to a constrained optimization problem (which is non-standard) into one involving inference on inequalities with pre-estimated coefficients, which is better understood. Our approach is valid regardless of whether the problem has a unique solution or multiple solutions. We apply our method to various portfolio selection models, in which the confidence sets can be non-convex, lower-dimensional manifolds.",http://www.sciencedirect.com/science/article/pii/S030440762100172X
Journal of Econometrics,2022,Identification of nonparametric monotonic regression models with continuous nonclassical measurement errors,"Yingyao Hu, Susanne Schennach and Ji-Liang Shiu","This paper provides sufficient conditions for identification of a nonparametric regression model with an unobserved continuous regressor subject to nonclassical measurement error. The measurement error may be directly correlated with the latent regressor in the model. Our identification strategy does not require the availability of additional data information, such as a secondary measurement, an instrumental variable, or an auxiliary sample. Our main assumptions for nonparametric identification include monotonicity of the regression function, independence of the regression error, and completeness of the measurement error distribution. We also propose a sieve maximum likelihood estimator and investigate its finite sample property through Monte Carlo simulations.",http://www.sciencedirect.com/science/article/pii/S0304407621001305
Journal of Econometrics,2022,Testing for risk aversion in first-price sealed-bid auctions,Sung Jae Jun and Federico Zincenko,"We consider testing for risk aversion in first-price sealed-bid auctions with symmetric bidders and independent private values. We impose several restrictions on the parameter space, which are all implied by Guerre et al. (2009)’s exclusion restriction, and we articulate what restrictions are needed for our test to control the limiting size and to be pointwise consistent. Critical values can be obtained from the standard normal distribution. We also analyze local-power properties and show that our test detects local alternative at the parametric rate.",http://www.sciencedirect.com/science/article/pii/S0304407621001469
Journal of Econometrics,2022,Sample selection models with monotone control functions,Ruixuan Liu and Zhengfei Yu,"The celebrated Heckman selection model yields a selection correction function (control function) proportional to the inverse Mills ratio, which is monotone. This paper studies a sample selection model that does not impose parametric distributional assumptions on the latent error terms, while maintaining the monotonicity of the control function. We show that a positive (negative) dependence condition on the latent error terms is sufficient for the monotonicity of the control function. The condition is equivalent to a restriction on the copula function of latent error terms. Using the monotonicity, we propose a tuning-parameter-free semiparametric estimation method and establish root n-consistency and asymptotic normality for the estimates of finite-dimensional parameters. A new test for selectivity is also developed in the presence of the shape restriction. Simulations and an empirical application are conducted to illustrate the usefulness of the proposed methods.",http://www.sciencedirect.com/science/article/pii/S0304407621001342
Journal of Econometrics,2022,Identification of dynamic games with unobserved heterogeneity and multiple equilibria,"Yao Luo, Ping Xiao and Ruli Xiao","This paper provides sufficient conditions for nonparametrically identifying dynamic games with incomplete information, allowing for multiple equilibria and payoff-relevant unobservables. Our identification involves two steps. We first identify the equilibrium conditional choice probabilities and state transitions using the Markov property and four-period data. The first step of our identification relies on eigenvalue-eigenvector decomposition, and thus incurs the same issue of identification up-to-label-swapping as the existing literature. This makes it difficult to identify payoff primitives in the second step, which requires consistent matching of unobserved types across different values of the observed variables. Instead of imposing assumptions such as monotonicity, we address this type-matching problem by exploiting the Markov property and longitudinal variations of observables in the intermediate periods to link different decompositions.",http://www.sciencedirect.com/science/article/pii/S0304407621001470
Journal of Econometrics,2022,Estimating multinomial choice models with unobserved choice sets,Zhentong Lu,"This paper proposes a new approach to estimating multinomial choice models when each consumer’s actual choice set is unobservable but could be bounded by two known sets, i.e., the largest and smallest possible choice sets. The bounds on choice set, combined with a monotonicity property derived from utility maximization, imply a system of inequality restrictions on observed choice probabilities that could be used to identify and estimate the model. A key insight is that the identification of random utility model can be achieved without exact information on consumers’ choice sets, which generalizes the identification result of the standard multinomial choice model. The effectiveness of the proposed approach is demonstrated via a range of Monte Carlo experiments as well as an empirical application to consumer demand for potato chips using household scanner data.",http://www.sciencedirect.com/science/article/pii/S0304407621001755
Journal of Econometrics,2022,A wavelet method for panel models with jump discontinuities in the parameters,"O. Bada, A. Kneip, D. Liebl, T. Mensinger, J. Gualtieri and Robin Sickles","While a substantial literature on structural break change point analysis exists for univariate time series, research on large panel data models has not been as extensive. In this paper, a novel method for estimating panel models with multiple structural changes is proposed. The breaks are allowed to occur at unknown points in time and may affect the multivariate slope parameters individually. Our method adapts Haar wavelets to the structure of the observed variables in order to detect the change points of the parameters consistently. We also develop methods to address endogenous regressors within our modeling framework. The asymptotic property of our estimator is established. In our application, we examine the impact of algorithmic trading on standard measures of market quality such as liquidity and volatility over a time period that covers the financial meltdown that began in 2007. We are able to detect jumps in regression slope parameters automatically without using ad-hoc subsample selection criteria.",http://www.sciencedirect.com/science/article/pii/S0304407621002189
Journal of Econometrics,2022,A test of the selection on observables assumption using a discontinuously distributed covariate,Umair Khalil and Neşe Yıldız,"We present a test of the selection on observables assumption that neither requires instruments nor excluded covariates from the structural function. Instead, we rely on the presence of a discontinuously distributed variable among the set of controls. We develop formal testing procedures for a non-parametric additively separable model for binary and finite treatment variables. We also outline a nonparametric nonseparable extension. Our test is easy to implement and should be useful in many empirical settings. Specifically, we employ it to study selection concerns in the estimation of the impact of a nutritional aid program for pregnant women on birth weight.",http://www.sciencedirect.com/science/article/pii/S0304407621002451
Journal of Econometrics,2022,Inference in ordered response games with complete information,Andres Aradillas-Lopez and Adam Rosen,"We study inference in complete information games with discrete strategy spaces. Unlike binary games, we allow for rich strategy spaces and we only assume that they are ordinal in nature. We derive observable implications of equilibrium play under mild shape restrictions on payoff functions, and we characterize sharp identified sets for model parameters. We propose a novel inference method based on a test statistic that embeds conditional moment inequalities implied by equilibrium behavior. Our statistic has asymptotically pivotal properties that depend on the measure of contact sets, to which our statistic adapts automatically. In the case of two players and strategic substitutes we show that certain payoff parameters are point identified under mild conditions. We embed conventional point estimates for these parameters in our conditional moment inequality test statistic in order to perform inference on the remaining (partially identified) parameters. We apply our method to model the number of stores operated by Lowe’s and Home Depot in geographic markets and perform inference on several quantities of economic interest.",http://www.sciencedirect.com/science/article/pii/S0304407621002347
Journal of Econometrics,2022,Estimating unobserved individual heterogeneity using pairwise comparisons,"Elena Krasnokutskaya, Kyungchul Song and Xun Tang","We propose a new method for studying environments with unobserved individual heterogeneity. Based on model-implied pairwise inequalities, the method classifies individuals in the sample into groups defined by discrete unobserved heterogeneity with unknown support. We establish conditions under which the groups are identified and consistently estimated through our method. We show that the method performs well in finite samples through Monte Carlo simulation. We then apply the method to estimate a model of lowest-price procurement auctions with unobserved bidder heterogeneity, using data from the California highway procurement market.",http://www.sciencedirect.com/science/article/pii/S0304407621000142
Journal of Econometrics,2022,Feedback in panel data models,Gary Chamberlain,"Much of the analysis of panel data has been based on an assumption of strict exogeneity. Distributions are specified for outcome variables conditional on a latent individual effect and conditional on observed predictor variables at all dates, with the future values of the predictor variables assumed to have no effect on the conditional distribution. The paper relaxes this assumption in order to allow for lagged dependent variables and, more generally, for feedback from lagged dependent variables to current values of the predictor variables. Such feedback would arise in an evaluation study if the treatment variable is randomly assigned only conditional on the individual effect and on previous outcomes.",http://www.sciencedirect.com/science/article/pii/S0304407621001937
Journal of Econometrics,2022,Robust likelihood estimation of dynamic panel data models,Javier Alvarez and Manuel Arellano,"We develop likelihood-based estimators for autoregressive panel data models that are consistent in the presence of time series heteroskedasticity. Bias-corrected conditional score estimators, random effects maximum likelihood in levels and first differences, and estimators that impose mean stationarity are considered for general autoregressive models with individual effects. We investigate identification under unit roots, and show that random effects estimation in levels may achieve substantial efficiency gains relative to estimation from data in differences. In an empirical application, we find evidence against unit roots in individual earnings processes from the Panel Study of Income Dynamics and the Spanish section of the European Community Household Panel.",http://www.sciencedirect.com/science/article/pii/S0304407621000956
Journal of Econometrics,2022,Design-based analysis in Difference-In-Differences settings with staggered adoption,Susan Athey and Guido Imbens,"In this paper we study estimation of and inference for average treatment effects in a setting with panel data. We focus on the staggered adoption setting where units, e.g, individuals, firms, or states, adopt the policy or treatment of interest at a particular point in time, and then remain exposed to this treatment at all times afterwards. We take a design perspective where we investigate the properties of estimators and procedures given assumptions on the assignment process. We show that under random assignment of the adoption date the standard Difference-In-Differences (DID) estimator is an unbiased estimator of a particular weighted average causal effect. We characterize the exact finite sample properties of this estimand, and show that the standard variance estimator is conservative.",http://www.sciencedirect.com/science/article/pii/S0304407621000488
Journal of Econometrics,2022,Estimation and inference of semiparametric models using data from several sources,"Moshe Buchinsky, Fanghua Li and Zhipeng Liao","This paper studies the estimation and inference of nonlinear econometric models when the economic variables are contained in different data sets. We construct a semiparametric minimum distance (SMD) estimator of the unknown structural parameter of interest when there are some common conditioning variables in different data sets. The SMD estimator is shown to be consistent and has an asymptotic normal distribution. We provide the explicit form of the optimal weight for the SMD estimation. We provide a consistent estimator of the variance–covariance matrix of the SMD estimator, and hence inference procedures of the unknown parameter vector. The finite sample performances of the SMD estimators and the proposed inference procedures are investigated in few alternative Monte Carlo simulation studies.",http://www.sciencedirect.com/science/article/pii/S0304407621000385
Journal of Econometrics,2022,"Minimax-regret sample design in anticipation of missing data, with application to panel data",Jeff Dominitz and Charles Manski,"Missing data problems are ubiquitous in data collection. In surveys, these problems may arise from unit response, item nonresponse, and panel attrition. Building on the Dominitz and Manski (2017) study of choice between two or more sampling processes that differ in cost and quality, we study minimax-regret sample design in anticipation of missing data, where the collected data will be used for prediction under square loss of the values of functions of two variables. The analysis imposes no assumptions that restrict unobserved outcomes. Findings are reported for prediction of the values of linear and indicator functions using panel data with attrition. We also consider choice between a panel and repeated cross sections.",http://www.sciencedirect.com/science/article/pii/S0304407620304000
Journal of Econometrics,2022,Semiparametrically efficient estimation of the average linear regression function,Bryan S. Graham and Cristine Pinto,"Let Y be an outcome of interest, X a vector of treatment measures, and W a vector of pre-treatment control variables. Here X may include (combinations of) continuous, discrete, or non-mutually exclusive “treatments”. Consider the linear regression of Y onto X in a subpopulation homogeneous in W=w (formally a conditional linear predictor). Let b0w be the coefficient vector on X in this regression. We introduce a semiparametrically efficient estimate of the average β0=Eb0W. When X is binary-valued (multi-valued) our procedure recovers the (a vector of) average treatment effect(s). When X is continuously-valued, or consists of multiple non-exclusive treatments, our estimand coincides with the average partial effect (APE) of X on Y when the underlying potential response function is linear in X, but otherwise heterogeneous across agents. When the potential response function takes a general nonlinear/heterogeneous form, and X is continuously-valued, our procedure recovers a weighted average of the gradient of this response across individuals and values of X. We provide a simple, and semiparametrically efficient, method of covariate adjustment for settings with complicated treatment regimes. Our method generalizes familiar methods of covariate adjustment used for program evaluation as well as methods of semiparametric regression (e.g., the partially linear regression model).",http://www.sciencedirect.com/science/article/pii/S0304407621001925
Journal of Econometrics,2022,Analyzing cross-validation for forecasting with structural instability,Keisuke Hirano and Jonathan Wright,"When forecasting with economic time series data, researchers often use a restricted window of observations or downweight past observations in order to mitigate the potential effects of parameter instability. In this paper, we study the problem of selecting a window for point forecasts made at the end of the sample. We develop asymptotic approximations to the sampling properties of window selection methods, and post-window selection point forecasts, where there is local parameter instability of various sorts. We examine risk properties of point forecasts made after cross-validation to select the window, and compare this approach to some alternative methods of selecting the window. We also propose a quasi-Bayesian form of cross-validation that we find to have good risk properties.",http://www.sciencedirect.com/science/article/pii/S0304407620304024
Journal of Econometrics,2022,"Who wins, who loses? Identification of conditional causal effects, and the welfare impact of changing wages",Maximilian Kasy,"The incidence of tax and other policy changes depends on their impact on equilibrium wages. In a standard model of labor supply, the impact of wage changes on a worker’s welfare equals current labor supply times the induced wage change. Worker heterogeneity implies that wage changes vary across workers. In this context, in order to identify welfare effects one needs to identify the causal effect of policy changes on wages conditional on baseline labor supply and wages.",http://www.sciencedirect.com/science/article/pii/S0304407621000452
Journal of Econometrics,2022,Approximation of sign-regular kernels,Thomas A. Knox,"Parameterized integrals, qy=∫Kx,ydPx, are common in economic applications. To optimize a parameterized integral, or to relate one such integral to others, it is helpful to reduce the rank of the kernel K while controlling approximation error. A bound on the uniform approximation error of Kx,y≈∑i=1nfixgiy also bounds the uniform approximation error of qy≈∑i=1ncigiy=∑i=1n∫fixdPxgiy over all y and all signed measures P whose total variation does not exceed a fixed bound (such as probability measures), which may be useful in optimizing q or in relating q to other parameterized integrals. Bounding the mean squared error or the local error in approximating K generally does not bound the uniform approximation error of q. Many economically interesting kernels of parameterized integrals, including expcxy, the Gaussian probability density function, and a wide class of Green’s functions, satisfy a condition known as strict sign-regularity.",http://www.sciencedirect.com/science/article/pii/S0304407621001949
Journal of Econometrics,2022,Censored quantile regression survival models with a cure proportion,Naveen Narisetty and Roger Koenker,"A new quantile regression model for survival data is proposed that permits a positive proportion of subjects to become unsusceptible to recurrence of disease following treatment or based on other observable characteristics. In contrast to prior proposals for quantile regression estimation of censored survival models, we propose a new “data augmentation” approach to estimation. Our approach has computational advantages over earlier approaches proposed by Wu and Yin (2013, 2017). We compare our method with the two estimation strategies proposed by Wu and Yin and demonstrate its advantageous empirical performance in simulations. The methods are also illustrated with data from a Lung Cancer survival study.",http://www.sciencedirect.com/science/article/pii/S0304407620303997
