journal,year,title,authors,abstract,url
Econometrica,2021,"Inequality, Business Cycles, and Monetary‐Fiscal Policy","Anmol Bhandari, David Evans, Mikhail Golosov and Thomas Sargent","We study optimal monetary and fiscal policies in a New Keynesian model with heterogeneous agents, incomplete markets, and nominal rigidities. Our approach uses small‐noise expansions and Fréchet derivatives to approximate equilibria quickly and efficiently. Responses of optimal policies to aggregate shocks differ qualitatively from what they would be in a corresponding representative agent economy and are an order of magnitude larger. A motive to provide insurance that arises from heterogeneity and incomplete markets outweighs price stabilization motives.",https://doi.org/10.3982/ECTA16414
Econometrica,2021,Learning Dynamics in Social Networks,Simon Board and Moritz Meyer‐ter‐Vehn,"This paper proposes a tractable model of Bayesian learning on large random networks where agents choose whether to adopt an innovation. We study the impact of the network structure on learning dynamics and product diffusion. In directed networks, all direct and indirect links contribute to agents' learning. In comparison, learning and welfare are lower in undirected networks and networks with cliques. In a rich class of networks, behavior is described by a small number of differential equations, making the model useful for empirical work.",https://doi.org/10.3982/ECTA18659
Econometrica,2021,Team Players: How Social Skills Improve Team Performance,Ben Weidmann and David Deming,"Most jobs require teamwork. Are some people good team players? In this paper, we design and test a new method for identifying individual contributions to team production. We randomly assign people to multiple teams and predict team performance based on previously assessed individual skills. Some people consistently cause their team to exceed its predicted performance. We call these individuals “team players.” Team players score significantly higher on a well‐established measure of social intelligence, but do not differ across a variety of other dimensions, including IQ, personality, education, and gender. Social skills—defined as a single latent factor that combines social intelligence scores with the team player effect—improve team performance about as much as IQ. We find suggestive evidence that team players increase effort among teammates.",https://doi.org/10.3982/ECTA18461
Econometrica,2021,The Reputation Trap,David Levine,"Few want to do business with a partner who has a bad reputation. Consequently, once a bad reputation is established, it can be difficult to get rid of. This leads on the one hand to the intuitive idea that a good reputation is easy to lose and hard to gain. On the other hand, it can lead to a strong form of history dependence in which a single beneficial or adverse event can cast a shadow over a very long period of time. It gives rise to a reputational trap where an agent rationally chooses not to invest in a good reputation because the chances others will find out is too low. Nevertheless, the same agent with a good reputation will make every effort to maintain it. Here, a simple reputational model is constructed and the conditions for there to be a unique equilibrium that constitutes a reputation trap are characterized.",https://doi.org/10.3982/ECTA17891
Econometrica,2021,Are Poor Cities Cheap for Everyone? Non‐Homotheticity and the Cost of Living Across U.S. Cities,Jessie Handbury,"This paper shows that the products and prices offered in markets are correlated with local income‐specific tastes. To quantify the welfare impact of this variation, I calculate local price indexes micro‐founded by a model of non‐homothetic demand over thousands of grocery products. These indexes reveal large differences in how wealthy and poor households perceive the choice sets available in wealthy and poor cities. Relative to low‐income households, high‐income households enjoy 40 percent higher utility per dollar expenditure in wealthy cities, relative to poor cities. Similar patterns are observed across stores in different neighborhoods. Most of this variation is explained by differences in the product assortment offered, rather than the relative prices charged, by chains that operate in different markets.",https://doi.org/10.3982/ECTA11738
Econometrica,2021,Lumpy Durable Consumption Demand and the Limited Ammunition of Monetary Policy,Alisdair McKay and Johannes Wieland,"The prevailing neo‐Wicksellian view holds that the central bank's objective is to track the natural rate of interest (r*), which itself is largely exogenous to monetary policy. We challenge this view using a fixed‐cost model of durable consumption demand, in which expansionary monetary policy prompts households to accelerate purchases of durable goods. This yields an intertemporal trade‐off in aggregate demand as encouraging households to increase durable holdings today leaves fewer households acquiring durables going forward. Interest rates must be kept low to support demand going forward, so accommodative monetary policy today reduces r* in the future. We show that this mechanism is quantitatively important in explaining the persistently low level of real interest rates and r* after the Great Recession.",https://doi.org/10.3982/ECTA18821
Econometrica,2021,Investment Demand and Structural Change,"Manuel García‐Santana, Josep Pijoan‐Mas and Lucciano Villacorta","We study the joint evolution of the sectoral composition and the investment rate of developing economies. Using panel data for several countries in different stages of development, we document three novel facts: (a) the share of industry and the investment rate are strongly correlated and follow a hump‐shaped profile with development, (b) investment goods contain more domestic value added from industry and less from services than consumption goods do, and (c) the evolution of the sectoral composition of investment and consumption goods differs from the one of GDP. We build a multi‐sector growth model to fit these patterns and provide two important results. First, the hump‐shaped evolution of investment demand explains half of the hump in industry with development. Second, asymmetric sectoral productivity growth helps explain the decline in the relative price of investment goods along the development path, which in turn increases capital accumulation and promotes growth.",https://doi.org/10.3982/ECTA16295
Econometrica,2021,When Moving‐Average Models Meet High‐Frequency Data: Uniform Inference on Volatility,Rui Da and Dacheng Xiu,"We conduct inference on volatility with noisy high‐frequency data. We assume the observed transaction price follows a continuous‐time Itô‐semimartingale, contaminated by a discrete‐time moving‐average noise process associated with the arrival of trades. We estimate volatility, defined as the quadratic variation of the semimartingale, by maximizing the likelihood of a misspecified moving‐average model, with its order selected based on an information criterion. Our inference is uniformly valid over a large class of noise processes whose magnitude and dependence structure vary with sample size. We show that the convergence rate of our estimator dominates n1/4 as noise vanishes, and is determined by the selected order of noise dependence when noise is sufficiently small. Our implementation guarantees positive estimates in finite samples.",https://doi.org/10.3982/ECTA15593
Econometrica,2021,Econometrics for Decision Making: Building Foundations Sketched by Haavelmo and Wald,Charles Manski,"Haavelmo (1944) proposed a probabilistic structure for econometric modeling, aiming to make econometrics useful for decision making. His fundamental contribution has become thoroughly embedded in econometric research, yet it could not answer all the deep issues that the author raised. Notably, Haavelmo struggled to formalize the implications for decision making of the fact that models can at most approximate actuality. In the same period, Wald (1939, 1945) initiated his own seminal development of statistical decision theory. Haavelmo favorably cited Wald, but econometrics did not embrace statistical decision theory. Instead, it focused on study of identification, estimation, and statistical inference. This paper proposes use of statistical decision theory to evaluate the performance of models in decision making. I consider the common practice of as‐if optimization: specification of a model, point estimation of its parameters, and use of the point estimate to make a decision that would be optimal if the estimate were accurate. A central theme is that one should evaluate as‐if optimization or any other model‐based decision rule by its performance across the state space, listing all states of nature that one believes feasible, not across the model space. I apply the theme to prediction and treatment choice. Statistical decision theory is conceptually simple, but application is often challenging. Advancing computation is the primary task to complete the foundations sketched by Haavelmo and Wald.",https://doi.org/10.3982/ECTA17985
Econometrica,2021,Identification at the Zero Lower Bound,Sophocles Mavroeidis,"I show that the zero lower bound (ZLB) on interest rates can be used to identify the causal effects of monetary policy. Identification depends on the extent to which the ZLB limits the efficacy of monetary policy. I propose a simple way to test the efficacy of unconventional policies, modeled via a “shadow rate.” I apply this method to U.S. monetary policy using a three‐equation structural vector autoregressive model of inflation, unemployment, and the Federal Funds rate. I reject the null hypothesis that unconventional monetary policy has no effect at the ZLB, but find some evidence that it is not as effective as conventional monetary policy.",https://doi.org/10.3982/ECTA17388
Econometrica,2021,Exchange Design and Efficiency,Marzena Rostek and Ji Hee Yoon,"Most assets clear independently rather than jointly. This paper presents a model based on the uniform‐price double auction which accommodates arbitrary restrictions on market clearing, including independent clearing across assets (allowed when demand for each asset is contingent only on the price of that asset) and joint market clearing for all assets (required when demand for each asset is contingent on the prices of all assets). Additional trading protocols for traded assets—neutral when the market clears jointly—are generally not redundant innovations, even if all traders participate in all protocols. Multiple trading protocols that clear independently can be designed to be at least as efficient as joint market clearing for all assets. The change in price impact brought by independence in market clearing can overcome the loss of information, and enhance diversification and risk sharing. Except when the market is competitive, market characteristics should guide innovation in trading technology.",https://doi.org/10.3982/ECTA16537
Econometrica,2021,Pairwise Stable Matching in Large Economies,Michael Greinecker and Christopher Kah,"We formulate a stability notion for two‐sided pairwise matching problems with individually insignificant agents in distributional form. Matchings are formulated as joint distributions over the characteristics of the populations to be matched. Spaces of characteristics can be high‐dimensional and need not be compact. Stable matchings exist with and without transfers, and stable matchings correspond precisely to limits of stable matchings for finite‐agent models. We can embed existing continuum matching models and stability notions with transferable utility as special cases of our model and stability notion. In contrast to finite‐agent matching models, stable matchings exist under a general class of externalities.",https://doi.org/10.3982/ECTA16228
Econometrica,2021,Capital Buffers in a Quantitative Model of Banking Industry Dynamics,P. Dean Corbae and Pablo D'Erasmo,"We develop a model of banking industry dynamics to study the quantitative impact of regulatory policies on bank risk‐taking and market structure. Since our model is matched to U.S. data, we propose a market structure where big banks with market power interact with small, competitive fringe banks as well as non‐bank lenders. Banks face idiosyncratic funding shocks in addition to aggregate shocks which affect the fraction of performing loans in their portfolio. A nontrivial bank size distribution arises out of endogenous entry and exit, as well as banks' buffer stock of capital. We show that the model predictions are consistent with untargeted business cycle properties, the bank lending channel, and empirical studies of the role of concentration on financial stability. We find that regulatory policies can have an important impact on banking market structure, which, along with selection effects, can generate changes in allocative efficiency and stability.",https://doi.org/10.3982/ECTA16930
Econometrica,2021,Learning With Heterogeneous Misspecified Models: Characterization and Robustness,J. Aislinn Bohren and Daniel N. Hauser,"This paper develops a general framework to study how misinterpreting information impacts learning. Our main result is a simple criterion to characterize long‐run beliefs based on the underlying form of misspecification. We present this characterization in the context of social learning, then highlight how it applies to other learning environments, including individual learning. A key contribution is that our characterization applies to settings with model heterogeneity and provides conditions for entrenched disagreement. Our characterization can be used to determine whether a representative agent approach is valid in the face of heterogeneity, study how differing levels of bias or unawareness of others' biases impact learning, and explore whether the impact of a bias is sensitive to parametric specification or the source of information. This unified framework synthesizes insights gleaned from previously studied forms of misspecification and provides novel insights in specific applications, as we demonstrate in settings with partisan bias, overreaction, naive learning, and level‐k reasoning.",https://doi.org/10.3982/ECTA15318
Econometrica,2021,Heterogeneous Choice Sets and Preferences,"Levon Barseghyan, Maura Coughlin, Francesca Molinari and Joshua Teitelbaum","We propose a robust method of discrete choice analysis when agents' choice sets are unobserved. Our core model assumes nothing about agents' choice sets apart from their minimum size. Importantly, it leaves unrestricted the dependence, conditional on observables, between choice sets and preferences. We first characterize the sharp identification region of the model's parameters by a finite set of conditional moment inequalities. We then apply our theoretical findings to learn about households' risk preferences and choice sets from data on their deductible choices in auto collision insurance. We find that the data can be explained by expected utility theory with low levels of risk aversion and heterogeneous non‐singleton choice sets, and that more than three in four households require limited choice sets to explain their deductible choices. We also provide simulation evidence on the computational tractability of our method in applications with larger feasible sets or higher‐dimensional unobserved heterogeneity.",https://doi.org/10.3982/ECTA17448
Econometrica,2021,Market Selection and the Information Content of Prices,Alp Atakan and Mehmet Ekmekci,"We study information aggregation when n bidders choose, based on their private information, between two concurrent common‐value auctions. There are ks identical objects on sale through a uniform‐price auction in market s and there are an additional kr objects on auction in market r, which is identical to market s except for a positive reserve price. The reserve price in market r implies that information is not aggregated in this market. Moreover, if the object‐to‐bidder ratio in market s exceeds a certain cutoff, then information is not aggregated in market s either. Conversely, if the object‐to‐bidder ratio is less than this cutoff, then information is aggregated in market s as the market grows arbitrarily large. Our results demonstrate how frictions in one market can disrupt information aggregation in a linked, frictionless market because of the pattern of market selection by imperfectly informed bidders.",https://doi.org/10.3982/ECTA14935
Econometrica,2021,An Axiomatic Model of Persuasion,Alexander M. Jakobsen,"A sender ranks information structures knowing that a receiver processes the information before choosing an action affecting them both. The sender and receiver may differ in their utility functions and/or prior beliefs, yielding a model of dynamic inconsistency when they represent the same individual at two points in time. I take as primitive (i) a collection of preference orderings over all information structures, indexed by menus of acts (the sender's ex ante preferences for information), and (ii) a collection of correspondences over menus of acts, indexed by signals (the receiver's signal‐contingent choice(s) from menus). I provide axiomatic representation theorems characterizing the sender as a sophisticated planner and the receiver as a Bayesian information processor, and show that all parameters can be uniquely identified from the sender's preferences for information. I also establish a series of results characterizing common priors, common utility functions, and intuitive measures of disagreement for these parameters—all in terms of the sender's preferences for information.",https://doi.org/10.3982/ECTA16729
Econometrica,2021,A Model of Scientific Communication,Isaiah Andrews and Jesse Shapiro,"We propose a positive model of empirical science in which an analyst makes a report to an audience after observing some data. Agents in the audience may differ in their beliefs or objectives, and may therefore update or act differently following a given report. We contrast the proposed model with a classical model of statistics in which the report directly determines the payoff. We identify settings in which the predictions of the proposed model differ from those of the classical model, and seem to better match practice.",https://doi.org/10.3982/ECTA18155
Econometrica,2021,Bootstrap With Cluster‐Dependence in Two or More Dimensions,Konrad Menzel,"We propose a bootstrap procedure for data that may exhibit cluster‐dependence in two or more dimensions. The asymptotic distribution of the sample mean or other statistics may be non‐Gaussian if observations are dependent but uncorrelated within clusters. We show that there exists no procedure for estimating the limiting distribution of the sample mean under two‐way clustering that achieves uniform consistency. However, we propose bootstrap procedures that achieve adaptivity with respect to different uniformity criteria. Important cases and extensions discussed in the paper include regression inference, U‐ and V‐statistics, subgraph counts for network data, and non‐exhaustive samples of matched data.",https://doi.org/10.3982/ECTA15383
Econometrica,2021,An Empirical Model of R&D Procurement Contests: An Analysis of the DOD SBIR Program,Vivek Bhattacharya,"Firms and governments often use R&D contests to incentivize suppliers to develop and deliver innovative products. The optimal design of such contests depends on empirical primitives: the cost of research, the uncertainty in outcomes, and the surplus participants capture. Can R&D contests in real‐world settings be redesigned to increase social surplus? I ask this question in the context of the Department of Defense's Small Business Innovation Research program, a multistage R&D contest. I develop a structural model to estimate the primitives from data on R&D and procurement contracts. I find that the optimal design substantially increases social surplus, and simple design changes in isolation (e.g., inviting more contestants) can capture up to half these gains; however, these changes reduce the DOD's own welfare. These results suggest there is substantial scope for improving the design of real‐world contests but that a designer must balance competing objectives.",https://doi.org/10.3982/ECTA16581
Econometrica,2021,Random Evolving Lotteries and Intrinsic Preference for Information,"Faruk Gul, Paulo Natenzon and Wolfgang Pesendorfer","We introduce random evolving lotteries to study preference for non‐instrumental information. Each period, the agent enjoys a flow payoff from holding a lottery that will resolve at the terminal date. We provide a representation theorem for non‐separable risk consumption preferences and use it to characterize agents' attitude to non‐instrumental information. To address applications, we characterize peak‐trough utilities that aggregate trajectories of flow utilities linearly but, in addition, put weight on the best (peak) and worst (trough) lotteries along each path. We show that the model is consistent with recent experimental evidence on attitudes to information, including a preference for gradual arrival of good news and the ostrich effect, that is, decision makers' tendency to prefer information after good news to information after bad news.",https://doi.org/10.3982/ECTA16190
Econometrica,2021,Reconciling Models of Diffusion and Innovation: A Theory of the Productivity Distribution and Technology Frontier,"Jess Benhabib, Jesse Perla and Christopher Tonetti","We study how endogenous innovation and technology diffusion interact to determine the shape of the productivity distribution and generate aggregate growth. We model firms that choose to innovate, adopt technology, or produce with their existing technology. Costly adoption creates a spread between the best and worst technologies concurrently used to produce similar goods. The balance of adoption and innovation determines the shape of the distribution; innovation stretches the distribution, while adoption compresses it. On the balanced growth path, the aggregate growth rate equals the maximum growth rate of innovators. While innovation drives long‐run growth, changes in the adoption environment can influence growth by affecting innovation incentives, either directly, through licensing of excludable technologies, or indirectly, via the option value of adoption.",https://doi.org/10.3982/ECTA15020
Econometrica,2021,What Do Data on Millions of U.S. Workers Reveal About Lifecycle Earnings Dynamics?,"Fatih Guvenen, Fatih Karahan, Serdar Ozkan and Jae Song","We study individual male earnings dynamics over the life cycle using panel data on millions of U.S. workers. Using nonparametric methods, we first show that the distribution of earnings changes exhibits substantial deviations from lognormality, such as negative skewness and very high kurtosis. Further, the extent of these nonnormalities varies significantly with age and earnings level, peaking around age 50 and between the 70th and 90th percentiles of the earnings distribution. Second, we estimate nonparametric impulse response functions and find important asymmetries: Positive changes for high‐income individuals are quite transitory, whereas negative ones are very persistent; the opposite is true for low‐income individuals. Third, we turn to long‐run outcomes and find substantial heterogeneity in the cumulative growth rates of earnings and the total number of years individuals spend nonemployed between ages 25 and 55. Finally, by targeting these rich sets of moments, we estimate stochastic processes for earnings that range from the simple to the complex. Our preferred specification features normal mixture innovations to both persistent and transitory components and includes state‐dependent long‐term nonemployment shocks with a realization probability that varies with age and earnings.",https://doi.org/10.3982/ECTA14603
Econometrica,2021,Whither Formal Contracts?,Raúl Sánchez  de la Sierra,"To measure the benefits of formal contract enforcement for society, I create a market with merchants and buyers, in which buyers can choose whether to buy, and whether to pay. A set of multiple “state‐favored” ethnic groups control the state. I experimentally vary whether formal contracts are required and the composition of buyer‐merchant pairs. The design separately identifies the effect of the contracts on the buyers' incentive to pay and on their incentive to buy. I document two ways in which society limits the benefits of contracts. First, contracts reduce buyer cheating, thus increasing merchants' profits, if, and only if, the merchant is state‐favored. Buyers' beliefs suggest that the merchants can enforce the contracts if, and only if, the merchant is state‐favored. Second, holding constant whether the pair is state‐favored, contracts only influence buyer choices when the buyer and the merchant belong to two, different, state‐favored ethnic groups. Buyers' choices and beliefs confirm that, in that case, the contracts are expected to be enforceable, but they have no effect on buyers' choices because reputation already governs the incentives to cheat within groups. The findings temper the view of the state as independent from society, offer a rationale for why contracts are not adopted, and nuance the notion of state weakness.",https://doi.org/10.3982/ECTA16083
Econometrica,2021,Using the Sequence‐Space Jacobian to Solve and Estimate Heterogeneous‐Agent Models,"Adrien Auclert, Bence Bardóczy, Matthew Rognlie and Ludwig Straub","We propose a general and highly efficient method for solving and estimating general equilibrium heterogeneous‐agent models with aggregate shocks in discrete time. Our approach relies on the rapid computation of sequence‐space Jacobians—the derivatives of perfect‐foresight equilibrium mappings between aggregate sequences around the steady state. Our main contribution is a fast algorithm for calculating Jacobians for a large class of heterogeneous‐agent problems. We combine this algorithm with a systematic approach to composing and inverting Jacobians to solve for general equilibrium impulse responses. We obtain a rapid procedure for likelihood‐based estimation and computation of nonlinear perfect‐foresight transitions. We apply our methods to three canonical heterogeneous‐agent models: a neoclassical model, a New Keynesian model with one asset, and a New Keynesian model with two assets.",https://doi.org/10.3982/ECTA17434
Econometrica,2021,Economic Predictions With Big Data: The Illusion of Sparsity,"Domenico Giannone, Michele Lenza and Giorgio Primiceri","We compare sparse and dense representations of predictive models in macroeconomics, microeconomics, and finance. To deal with a large number of possible predictors, we specify a prior that allows for both variable selection and shrinkage. The posterior distribution does not typically concentrate on a single sparse model, but on a wide set of models that often include many predictors.",https://doi.org/10.3982/ECTA17842
Econometrica,2021,A Projection Framework for Testing Shape Restrictions That Form Convex Cones,Zheng Fang and Juwon Seo,"This paper develops a uniformly valid and asymptotically nonconservative test based on projection for a class of shape restrictions. The key insight we exploit is that these restrictions form convex cones, a simple and yet elegant structure that has been barely harnessed in the literature. Based on a monotonicity property afforded by such a geometric structure, we construct a bootstrap procedure that, unlike many studies in nonstandard settings, dispenses with estimation of local parameter spaces, and the critical values are obtained in a way as simple as computing the test statistic. Moreover, by appealing to strong approximations, our framework accommodates nonparametric regression models as well as distributional/density‐related and structural settings. Since the test entails a tuning parameter (due to the nonstandard nature of the problem), we propose a data‐driven choice and prove its validity. Monte Carlo simulations confirm that our test works well.",https://doi.org/10.3982/ECTA17764
Econometrica,2021,Location as an Asset,Adrien Bilal and Esteban Rossi‐Hansberg,"The location of individuals determines their job and schooling opportunities, amenities, and housing costs. We conceptualize the location choice of individuals as a decision to invest in a “location asset.” This asset has a current cost equal to the location's rent, and a future payoff through better job and schooling opportunities. As with any asset, savers in the location asset transfer resources into the future by going to expensive locations with high future returns. In contrast, borrowers transfer resources to the present by going to cheap locations that offer few other advantages. Holdings of the location asset depend on its comparison to other assets, with the distinction that the location asset is not subject to borrowing constraints. We propose a dynamic location model and derive an agent's mobility choices after experiencing income shocks. We document the investment dimension of location and confirm the core predictions of our theory using French individual panel data from tax returns.",https://doi.org/10.3982/ECTA16699
Econometrica,2021,The Size‐Power Tradeoff in HAR Inference,"Eben Lazarus, Daniel Lewis and James H. Stock","Heteroskedasticity‐ and autocorrelation‐robust (HAR) inference in time series regression typically involves kernel estimation of the long‐run variance. Conventional wisdom holds that, for a given kernel, the choice of truncation parameter trades off a test's null rejection rate and power, and that this tradeoff differs across kernels. We formalize this intuition: using higher‐order expansions, we provide a unified size‐power frontier for both kernel and weighted orthonormal series tests using nonstandard “fixed‐b” critical values. We also provide a frontier for the subset of these tests for which the fixed‐b distribution is t or F. These frontiers are respectively achieved by the QS kernel and equal‐weighted periodogram. The frontiers have simple closed‐form expressions, which show that the price paid for restricting attention to tests with t and F critical values is small. The frontiers are derived for the Gaussian multivariate location model, but simulations suggest the qualitative findings extend to stochastic regressors.",https://doi.org/10.3982/ECTA15404
Econometrica,2021,Inferring Inequality With Home Production,Job Boerma and Loukas Karabarbounis,"We revisit the causes, welfare consequences, and policy implications of the dispersion in households' labor market outcomes using a model with uninsurable risk, incomplete asset markets, and home production. Allowing households to be heterogeneous in both their disutility of home work and their home production efficiency, we find that home production amplifies welfare‐based differences, meaning that inequality in standards of living is larger than we thought. We infer significant home production efficiency differences across households because hours working at home do not covary with consumption and wages in the cross section of households. Heterogeneity in home production efficiency is essential for inequality, as home production would not amplify inequality if differences at home only reflected heterogeneity in disutility of work.",https://doi.org/10.3982/ECTA15966
Econometrica,2021,Corrigendum to Crawford and Sobel (1982) “Strategic Information Transmission”,Haruki Kono and Michihiro Kandori,"In their analysis of strategic information transmission, Vincent Crawford and Joel Sobel (1982) showed the existence of partition equilibria (Theorem 1). Although the theorem itself is correct, the proof contains some incorrect statements. We present a counter‐example and provide a correct version of the proof.",https://doi.org/10.3982/ECTA17617
Econometrica,2021,Corrigendum to Capital Investment in “Assortative Matching With Large Firms”,"Jan Eeckhout, Philipp Kircher, Cristina Lafuente and Gabriele Macci",,https://doi.org/10.3982/ECTA18054
Econometrica,2021,Comment on “Efficient Resource Allocation on the Basis of Priorities”,Yusuke Narita,"This note points out that the proof of Theorem 1, the main theorem, in Ergin (2002) needs two corrections. We provide two counterexamples to Ergin's (2002) proof and show that the theorem holds as it is by providing an alternative proof.",https://doi.org/10.3982/ECTA8740
Econometrica,2021,Corrigendum to “Maximality in the Farsighted Stable Set”,Jonathan Newton,"Lemma 1 of Ray and Vohra (2019) is false as stated, but holds under alternative conditions which are consistent with the ideas of coalitional sovereignty that motivate the cited paper.",https://doi.org/10.3982/ECTA18420
Econometrica,2021,Robust Bayesian Inference for Set‐Identified Models,Raffaella Giacomini and Toru Kitagawa,"This paper reconciles the asymptotic disagreement between Bayesian and frequentist inference in set‐identified models by adopting a multiple‐prior (robust) Bayesian approach. We propose new tools for Bayesian inference in set‐identified models and show that they have a well‐defined posterior interpretation in finite samples and are asymptotically valid from the frequentist perspective. The main idea is to construct a prior class that removes the source of the disagreement: the need to specify an unrevisable prior for the structural parameter given the reduced‐form parameter. The corresponding class of posteriors can be summarized by reporting the ‘posterior lower and upper probabilities’ of a given event and/or the ‘set of posterior means’ and the associated ‘robust credible region’. We show that the set of posterior means is a consistent estimator of the true identified set and the robust credible region has the correct frequentist asymptotic coverage for the true identified set if it is convex. Otherwise, the method provides posterior inference about the convex hull of the identified set. For impulse‐response analysis in set‐identified Structural Vector Autoregressions, the new tools can be used to overcome or quantify the sensitivity of standard Bayesian inference to the choice of an unrevisable prior.",https://doi.org/10.3982/ECTA16773
Econometrica,2021,Extreme Points and Majorization: Economic Applications,"Andreas Kleiner, Benny Moldovanu and Philipp Strack","We characterize the set of extreme points of monotonic functions that are either majorized by a given function f or themselves majorize f and show that these extreme points play a crucial role in many economic design problems. Our main results show that each extreme point is uniquely characterized by a countable collection of intervals. Outside these intervals the extreme point equals the original function f and inside the function is constant. Further consistency conditions need to be satisfied pinning down the value of an extreme point in each interval where it is constant. We apply these insights to a varied set of economic problems: equivalence and optimality of mechanisms for auctions and (matching) contests, Bayesian persuasion, optimal delegation, and decision making under uncertainty.",https://doi.org/10.3982/ECTA18312
Econometrica,2021,Quantitative Analysis of Multiparty Tariff Negotiations,"Kyle Bagwell, Robert Staiger and Ali Yurukoglu","We develop a model of international tariff negotiations to study the design of the institutional rules of the GATT/WTO. A key principle of the GATT/WTO is its most‐favored‐nation (MFN) requirement of nondiscrimination, a principle that has long been criticized for inviting free‐riding behavior. We embed a multisector model of international trade into a model of interconnected bilateral negotiations over tariffs and assess the value of the MFN principle. Using 1990 trade flows and tariff outcomes from the Uruguay Round of GATT/WTO negotiations, we estimate the model and use it to simulate what would happen if the MFN requirement were abandoned and countries negotiated over discriminatory tariffs. We find that if tariff bargaining in the Uruguay Round had proceeded without the MFN requirement, it would have wiped out the world real income gains that MFN tariff bargaining in the Uruguay Round produced and would have instead led to a small reduction in world real income relative to the 1990 status quo.",https://doi.org/10.3982/ECTA16084
Econometrica,2021,Recovering Preferences From Finite Data,"Christopher Chambers, Federico Echenique and Nicolas Lambert","We study preferences estimated from finite choice experiments and provide sufficient conditions for convergence to a unique underlying “true” preference. Our conditions are weak and, therefore, valid in a wide range of economic environments. We develop applications to expected utility theory, choice over consumption bundles, and menu choice. Our framework unifies the revealed preference tradition with models that allow for errors.",https://doi.org/10.3982/ECTA17845
Econometrica,2021,Redistribution Through Markets,"Piotr Dworczak, Scott Kominers and Mohammad Akbarpour","Policymakers frequently use price regulations as a response to inequality in the markets they control. In this paper, we examine the optimal structure of such policies from the perspective of mechanism design. We study a buyer‐seller market in which agents have private information about both their valuations for an indivisible object and their marginal utilities for money. The planner seeks a mechanism that maximizes agents' total utilities, subject to incentive and market‐clearing constraints. We uncover the constrained Pareto frontier by identifying the optimal trade‐off between allocative efficiency and redistribution. We find that competitive‐equilibrium allocation is not always optimal. Instead, when there is inequality across sides of the market, the optimal design uses a tax‐like mechanism, introducing a wedge between the buyer and seller prices, and redistributing the resulting surplus to the poorer side of the market via lump‐sum payments. When there is significant same‐side inequality that can be uncovered by market behavior, it may be optimal to impose price controls even though doing so induces rationing.",https://doi.org/10.3982/ECTA16671
Econometrica,2021,A New Parametrization of Correlation Matrices,Ilya Archakov and Peter Hansen,"We introduce a novel parametrization of the correlation matrix. The reparametrization facilitates modeling of correlation and covariance matrices by an unrestricted vector, where positive definiteness is an innate property. This parametrization can be viewed as a generalization of Fisher's Z‐transformation to higher dimensions and has a wide range of potential applications. An algorithm for reconstructing the unique n × n correlation matrix from any vector in Rn(n−1)/2 is provided, and we derive its numerical complexity.",https://doi.org/10.3982/ECTA16910
Econometrica,2021,Attention Please!,"Olivier Gossner, Jakub Steiner and Colin Stewart","We study the impact of manipulating the attention of a decision‐maker who learns sequentially about a number of items before making a choice. Under natural assumptions on the decision‐maker's strategy, directing attention toward one item increases its likelihood of being chosen regardless of its value. This result applies when the decision‐maker can reject all items in favor of an outside option with known value; if no outside option is available, the direction of the effect of manipulation depends on the value of the item. A similar result applies to manipulation of choices in bandit problems.",https://doi.org/10.3982/ECTA17173
Econometrica,2021,Sales and Markup Dispersion: Theory and Empirics,"Monika Mrázová, J. Peter Neary and Mathieu Parenti","We characterize the relationship between the distributions of two variables linked by a structural model. We then show that, in models of heterogeneous firms in monopolistic competition, this relationship implies a new demand function that we call “CREMR” (Constant Revenue Elasticity of Marginal Revenue). This demand function is the only one that is consistent with productivity and sales distributions having the same form (whether Pareto, lognormal, or Fréchet) in the cross section, and it is necessary and sufficient for Gibrat's Law to hold over time. Among the applications we consider, we use our methodology to characterize misallocation across firms; we derive the distribution of markups implied by any assumptions on demand and productivity; and we show empirically that CREMR‐based markup distributions provide an excellent parsimonious fit to Indian firm‐level data, which in turn allows us to calculate the proportion of firms that are of suboptimal size in the market equilibrium.",https://doi.org/10.3982/ECTA17416
Econometrica,2021,Local Projection Inference Is Simpler and More Robust Than You Think,José Luis Montiel Olea and Mikkel Plagborg‐Møller,"Applied macroeconomists often compute confidence intervals for impulse responses using local projections, that is, direct linear regressions of future outcomes on current covariates. This paper proves that local projection inference robustly handles two issues that commonly arise in applications: highly persistent data and the estimation of impulse responses at long horizons. We consider local projections that control for lags of the variables in the regression. We show that lag‐augmented local projections with normal critical values are asymptotically valid uniformly over (i) both stationary and non‐stationary data, and also over (ii) a wide range of response horizons. Moreover, lag augmentation obviates the need to correct standard errors for serial correlation in the regression residuals. Hence, local projection inference is arguably both simpler than previously thought and more robust than standard autoregressive inference, whose validity is known to depend sensitively on the persistence of the data and on the length of the horizon.",https://doi.org/10.3982/ECTA18756
Econometrica,2021,Generalized Local‐to‐Unity Models,Liyu Dou and Ulrich K. Müller,"We introduce a generalization of the popular local‐to‐unity model of time series persistence by allowing for p autoregressive (AR) roots and p − 1 moving average (MA) roots close to unity. This generalized local‐to‐unity model, GLTU(p), induces convergence of the suitably scaled time series to a continuous time Gaussian ARMA(p,p − 1) process on the unit interval. Our main theoretical result establishes the richness of this model class, in the sense that it can well approximate a large class of processes with stationary Gaussian limits that are not entirely distinct from the unit root benchmark. We show that Campbell and Yogo's (2006) popular inference method for predictive regressions fails to control size in the GLTU(2) model with empirically plausible parameter values, and we propose a limited‐information Bayesian framework for inference in the GLTU(p) model and apply it to quantify the uncertainty about the half‐life of deviations from purchasing power parity.",https://doi.org/10.3982/ECTA17944
Econometrica,2021,TV Advertising Effectiveness and Profitability: Generalizable Results From 288 Brands,"Bradley T. Shapiro, Günter J. Hitsch and Anna E. Tuchman","We estimate the distribution of television advertising elasticities and the distribution of the advertising return on investment (ROI) for a large number of products in many categories. Our results reveal substantially smaller advertising elasticities compared to the results documented in the literature, as well as a sizable percentage of statistically insignificant or negative estimates. The results are robust to functional form assumptions and are not driven by insufficient statistical power or measurement error. The ROI analysis shows negative ROIs at the margin for more than 80% of brands, implying over‐investment in advertising by most firms. Further, the overall ROI of the observed advertising schedule is only positive for one third of all brands.",https://doi.org/10.3982/ECTA17674
Econometrica,2021,Taxing Identity: Theory and Evidence From Early Islam,Mohamed Saleh and Jean Tirole,"A ruler who does not identify with a social group, whether on religious, ethnic, cultural, or socioeconomic grounds, is confronted with a trade‐off between taking advantage of the out‐group population's eagerness to maintain its identity and inducing it to “comply” (conversion, quitting, exodus, or any other way to accommodate the ruler's own identity). This paper first nests economists' extraction model, in which rulers are revenue‐maximizers, within a more general identity‐based model, in which rulers care also about inducing people to lose their identity, both in a static and an evolving environment. This paper then constructs novel data sources to test the implications of both models in the context of Egypt's conversion to Islam between 641 and 1170. The evidence supports the identity‐based model.",https://doi.org/10.3982/ECTA17265
Econometrica,2021,Present Bias,Anujit Chakraborty,"Present bias is the inclination to prefer a smaller present reward to a larger later reward, but reversing this preference when both rewards are equally delayed. Such behavior violates stationarity of temporal choices, and hence exponential discounting. This paper provides a weakening of the stationarity axiom that can accommodate present‐biased choice reversals. We call this new behavioral postulate Weak Present Bias and characterize the general class of utility functions that is consistent with it. We show that present‐biased preferences can be represented as those of a decision maker who makes her choices according to conservative present‐equivalents, in the face of uncertainty about future tastes.",https://doi.org/10.3982/ECTA16467
Econometrica,2021,Bootstrap Standard Error Estimates and Inference,Jinyong Hahn and Zhipeng Liao,"Asymptotic justification of the bootstrap often takes the form of weak convergence of the bootstrap distribution to some limit distribution. Theoretical literature recognized that the weak convergence does not imply consistency of the bootstrap second moment or the bootstrap variance as an estimator of the asymptotic variance, but such concern is not always reflected in the applied practice. We bridge the gap between the theory and practice by showing that such common bootstrap based standard error in fact leads to a potentially conservative inference.",https://doi.org/10.3982/ECTA17912
Econometrica,2021,Reputation and Sovereign Default,Manuel Amador and Christopher Phelan,"This paper presents a continuous‐time model of sovereign debt. In it, a relatively impatient sovereign government's hidden type switches back and forth between a commitment type, which cannot default, and an opportunistic type, which can, and where we assume outside lenders have particular beliefs regarding how a commitment type should borrow for any given level of debt and bond price. In any Markov equilibrium, the opportunistic type mimics the commitment type when borrowing, revealing its type only by defaulting on its debt at random times. The equilibrium features a “graduation date”: a finite amount of time since the last default, after which time reputation reaches its highest level and is unaffected by not defaulting. Before such date, not defaulting always increases the country's reputation. For countries that have recently defaulted, bond prices and the total amount of debt are increasing functions of the amount of time since the country's last default. For countries that have not recently defaulted (i.e., those that have graduated), bond prices are constant.",https://doi.org/10.3982/ECTA16685
Econometrica,2021,General Equilibrium Oligopoly and Ownership Structure,José Azar and Xavier Vives,"We develop a tractable general equilibrium framework in which firms are large and have market power with respect to both products and labor, and in which a firm's decisions are affected by its ownership structure. We characterize the Cournot–Walras equilibrium of an economy where each firm maximizes a share‐weighted average of shareholder utilities—rendering the equilibrium independent of price normalization. In a one‐sector economy, if returns to scale are non‐increasing, then an increase in “effective” market concentration (which accounts for common ownership) leads to declines in employment, real wages, and the labor share. Yet when there are multiple sectors, due to an intersectoral pecuniary externality, an increase in common ownership could stimulate the economy when the elasticity of labor supply is high relative to the elasticity of substitution in product markets. We characterize for which ownership structures the monopolistically competitive limit or an oligopolistic one is attained as the number of sectors in the economy increases. When firms have heterogeneous constant returns to scale technologies, we find that an increase in common ownership leads to markets that are more concentrated.",https://doi.org/10.3982/ECTA17906
Econometrica,2021,A Comment on: “General Equilibrium Oligopoly and Ownership Structure” by José Azar and Xavier Vives,Jan Eeckhout,,https://doi.org/10.3982/ECTA18810
Econometrica,2021,A Comment on: “General Equilibrium Oligopoly and Ownership Structure” by José Azar and Xavier Vives,Thomas Philippon,,https://doi.org/10.3982/ECTA18862
Econometrica,2021,Reply to: Comments on “General Equilibrium Oligopoly and Ownership Structure”,José Azar and Xavier Vives,,https://doi.org/10.3982/ECTA18868
Econometrica,2021,Limit Points of Endogenous Misspecified Learning,"Drew Fudenberg, Giacomo Lanzani and Philipp Strack","We study how an agent learns from endogenous data when their prior belief is misspecified. We show that only uniform Berk–Nash equilibria can be long‐run outcomes, and that all uniformly strict Berk–Nash equilibria have an arbitrarily high probability of being the long‐run outcome for some initial beliefs. When the agent believes the outcome distribution is exogenous, every uniformly strict Berk–Nash equilibrium has positive probability of being the long‐run outcome for any initial belief. We generalize these results to settings where the agent observes a signal before acting.",https://doi.org/10.3982/ECTA18508
Econometrica,2021,Optimal Asset Management Contracts With Hidden Savings,Sebastian Di Tella and Yuliy Sannikov,"We characterize optimal asset management contracts in a classic portfolio‐investment setting. When the agent has access to hidden savings, his incentives to misbehave depend on his precautionary saving motive. The contract dynamically distorts the agent's access to capital to manipulate his precautionary saving motive and reduce incentives for misbehavior. We provide a sufficient condition for the validity of the first‐order approach, which holds in the optimal contract: global incentive compatibility is ensured if the agent's precautionary saving motive weakens after bad outcomes. We extend our results to incorporate market risk, hidden investment, and renegotiation.",https://doi.org/10.3982/ECTA14929
Econometrica,2021,Finite‐Sample Optimal Estimation and Inference on Average Treatment Effects Under Unconfoundedness,Timothy Armstrong and Michal Kolesár,"We consider estimation and inference on average treatment effects under unconfoundedness conditional on the realizations of the treatment variable and covariates. Given nonparametric smoothness and/or shape restrictions on the conditional mean of the outcome variable, we derive estimators and confidence intervals (CIs) that are optimal in finite samples when the regression errors are normal with known variance. In contrast to conventional CIs, our CIs use a larger critical value that explicitly takes into account the potential bias of the estimator. When the error distribution is unknown, feasible versions of our CIs are valid asymptotically, even when n‐inference is not possible due to lack of overlap, or low smoothness of the conditional mean. We also derive the minimum smoothness conditions on the conditional mean that are necessary for n‐inference. When the conditional mean is restricted to be Lipschitz with a large enough bound on the Lipschitz constant, the optimal estimator reduces to a matching estimator with the number of matches set to one. We illustrate our methods in an application to the National Supported Work Demonstration.",https://doi.org/10.3982/ECTA16907
Econometrica,2021,Nash Equilibria on (Un)Stable Networks,Anton Badev,"In response to a change, individuals may choose to follow the responses of their friends or, alternatively, to change their friends. To model these decisions, consider a game where players choose their behaviors and friendships. In equilibrium, players internalize the need for consensus in forming friendships and choose their optimal strategies on subsets of k players—a form of bounded rationality. The k‐player consensual dynamic delivers a probabilistic ranking of a game's equilibria, and via a varying k, facilitates estimation of such games. Applying the model to adolescents' smoking suggests that: (a) the response of the friendship network to changes in tobacco price amplifies the intended effect of price changes on smoking, (b) racial desegregation of high schools decreases the overall smoking prevalence, (c) peer effect complementarities are substantially stronger between smokers compared to between nonsmokers.",https://doi.org/10.3982/ECTA12576
Econometrica,2021,Viability and Arbitrage Under Knightian Uncertainty,"Matteo Burzoni, Frank Riedel and H. Mete Soner","We reconsider the microeconomic foundations of financial economics. Motivated by the importance of Knightian uncertainty in markets, we present a model that does not carry any probabilistic structure ex ante, yet is based on a common order. We derive the fundamental equivalence of economic viability of asset prices and absence of arbitrage. We also obtain a modified version of the fundamental theorem of asset pricing using the notion of sublinear pricing measures. Different versions of the efficient market hypothesis are related to the assumptions one is willing to impose on the common order.",https://doi.org/10.3982/ECTA16535
Econometrica,2021,Aggregate Dynamics in Lumpy Economies,Isaac Baley and Andrés Blanco,How does an economy's capital respond to aggregate productivity shocks when firms make lumpy investments? We show that capital's transitional dynamics are structurally linked to two steady‐state moments: the dispersion of capital to productivity ratios—an indicator of capital misallocation—and the covariance of capital to productivity ratios with the time elapsed since their last adjustment—an indicator of asymmetric costs of upsizing and downsizing the capital stock. We compute these two sufficient statistics using data on the size and frequency of investment of Chilean plants. The empirical values indicate significant effects of aggregate productivity shocks and favor investment models with a strong downsizing rigidity and random opportunities for free adjustments.,https://doi.org/10.3982/ECTA17344
Econometrica,2021,Screening in Vertical Oligopolies,Hector Chade and Jeroen Swinkels,"A finite number of vertically differentiated firms simultaneously compete for and screen agents with private information about their payoffs. In equilibrium, higher firms serve higher types. Each firm distorts the allocation downward from the efficient level on types below a threshold, but upward above. While payoffs in this game are neither quasi‐concave nor continuous, if firms are sufficiently differentiated, then any strategy profile that satisfies a simple set of necessary conditions is a pure‐stategy equilibrium, and an equilibrium exists. A mixed‐strategy equilibrium exists even when firms are less differentiated. The welfare effects of private information are drastically different than under monopoly. The equilibrium approaches the competitive limit quickly as entry costs grow small. We solve the problem of a multi‐plant firm facing a type‐dependent outside option and use this to study the effect of mergers.",https://doi.org/10.3982/ECTA17016
Econometrica,2021,Optimal Auction Design With Common Values: An Informationally Robust Approach,Benjamin Brooks and Songzi Du,"A profit‐maximizing seller has a single unit of a good to sell. The bidders have a pure common value that is drawn from a distribution that is commonly known. The seller does not know the bidders' beliefs about the value and thinks that beliefs are designed adversarially by Nature to minimize profit. We construct a strong maxmin solution to this joint mechanism design and information design problem, consisting of a mechanism, an information structure, and an equilibrium, such that neither the seller nor Nature can move profit in their respective preferred directions, even if the deviator can select the new equilibrium. The mechanism and information structure solve a family of maxmin mechanism design and minmax information design problems, regardless of how an equilibrium is selected. The maxmin mechanism takes the form of a proportional auction: each bidder submits a one‐dimensional bid, the aggregate allocation and aggregate payment depend on the aggregate bid, and individual allocations and payments are proportional to bids. We report a number of additional properties of the maxmin mechanisms, including what happens as the number of bidders grows large and robustness with respect to the prior over the value.",https://doi.org/10.3982/ECTA16297
Econometrica,2021,A Macroeconomic Model With Financially Constrained Producers and Intermediaries,"Vadim Elenev, Tim Landvoigt and Stijn Van Nieuwerburgh","How much capital should financial intermediaries hold? We propose a general equilibrium model with a financial sector that makes risky long‐term loans to firms, funded by deposits from savers. Government guarantees create a role for bank capital regulation. The model captures the sharp and persistent drop in macro‐economic aggregates and credit provision as well as the sharp change in credit spreads observed during financial crises. Policies requiring intermediaries to hold more capital reduce financial fragility, reduce the size of the financial and non‐financial sectors, and lower intermediary profits. They redistribute wealth from savers to the owners of banks and non‐financial firms. Pre‐crisis capital requirements are close to optimal. Counter‐cyclical capital requirements increase welfare.",https://doi.org/10.3982/ECTA16438
Econometrica,2021,Inference for Iterated GMM Under Misspecification,Bruce E. Hansen and Seojeong Lee,"This paper develops inference methods for the iterated overidentified Generalized Method of Moments (GMM) estimator. We provide conditions for the existence of the iterated estimator and an asymptotic distribution theory, which allows for mild misspecification. Moment misspecification causes bias in conventional GMM variance estimators, which can lead to severely oversized hypothesis tests. We show how to consistently estimate the correct asymptotic variance matrix. Our simulation results show that our methods are properly sized under both correct specification and mild to moderate misspecification. We illustrate the method with an application to the model of Acemoglu, Johnson, Robinson, and Yared (2008).",https://doi.org/10.3982/ECTA16274
Econometrica,2021,Salvaging Falsified Instrumental Variable Models,Matthew Masten and Alexandre Poirier,"What should researchers do when their baseline model is falsified? We recommend reporting the set of parameters that are consistent with minimally nonfalsified models. We call this the falsification adaptive set (FAS). This set generalizes the standard baseline estimand to account for possible falsification. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. In the classical linear IV model with multiple instruments, we show that the FAS has a simple closed‐form expression that only depends on a few 2SLS coefficients. We apply our results to an empirical study of roads and trade. We show how the FAS complements traditional overidentification tests by summarizing the variation in estimates obtained from alternative nonfalsified models.",https://doi.org/10.3982/ECTA17969
Econometrica,2021,Asset Pricing With Endogenously Uninsurable Tail Risk,Hengjie Ai and Anmol Bhandari,"This paper studies asset pricing and labor market dynamics when idiosyncratic risk to human capital is not fully insurable. Firms use long‐term contracts to provide insurance to workers, but neither side can fully commit; furthermore, owing to costly and unobservable retention effort, worker‐firm relationships have endogenous durations. Uninsured tail risk in labor earnings arises as a part of an optimal risk‐sharing scheme. In equilibrium, exposure to the tail risk generates higher aggregate risk premia and higher return volatility. Consistent with data, firm‐level labor share predicts both future returns and pass‐throughs of firm‐level shocks to labor compensation.",https://doi.org/10.3982/ECTA15142
Econometrica,2021,Strategic Analysis of Auctions,Robert Wilson,,https://doi.org/10.3982/ECTA19347
Econometrica,2021,Equitable Voting Rules,"Laurent Bartholdi, Wade Hann‐Caruthers, Maya Josyula, Omer Tamuz and Leeat Yariv","May's theorem (1952), a celebrated result in social choice, provides the foundation for majority rule. May's crucial assumption of symmetry, often thought of as a procedural equity requirement, is violated by many choice procedures that grant voters identical roles. We show that a weakening of May's symmetry assumption allows for a far richer set of rules that still treat voters equally. We show that such rules can have minimal winning coalitions comprising a vanishing fraction of the population, but not less than the square root of the population size. Methodologically, we introduce techniques from group theory and illustrate their usefulness for the analysis of social choice questions.",https://doi.org/10.3982/ECTA17032
Econometrica,2021,Spurious Factor Analysis,Alexei Onatski and Chen Wang,"This paper draws parallels between the principal components analysis of factorless high‐dimensional nonstationary data and the classical spurious regression. We show that a few of the principal components of such data absorb nearly all the data variation. The corresponding scree plot suggests that the data contain a few factors, which is corroborated by the standard panel information criteria. Furthermore, the Dickey–Fuller tests of the unit root hypothesis applied to the estimated “idiosyncratic terms” often reject, creating an impression that a few factors are responsible for most of the nonstationarity in the data. We warn empirical researchers of these peculiar effects and suggest to always compare the analysis in levels with that in differences.",https://doi.org/10.3982/ECTA16703
Econometrica,2021,Selecting Applicants,Alex Frankel,"A firm selects applicants to hire based on hard information, such as a test result, and soft information, such as a manager's evaluation of an interview. The contract that the firm offers to the manager can be thought of as a restriction on acceptance rates as a function of test results. I characterize optimal acceptance rate functions both when the firm knows the manager's mix of information and biases and when the firm is uncertain. These contracts may admit a simple implementation in which the manager can accept any set of applicants with a sufficiently high average test score.",https://doi.org/10.3982/ECTA15510
Econometrica,2021,Learning From Coworkers,"Gregor Jarosch, Ezra Oberfield and Esteban Rossi‐Hansberg","We investigate learning at the workplace. To do so, we use German administrative data that contain information on the entire workforce of a sample of establishments. We document that having more‐highly‐paid coworkers is strongly associated with future wage growth, particularly if those workers earn more. Motivated by this fact, we propose a dynamic theory of a competitive labor market where firms produce using teams of heterogeneous workers that learn from each other. We develop a methodology to structurally estimate knowledge flows using the full‐richness of the German employer‐employee matched data. The methodology builds on the observation that a competitive labor market prices coworker learning. Our quantitative approach imposes minimal restrictions on firms' production functions, can be implemented on a very short panel, and allows for potentially rich and flexible coworker learning functions. In line with our reduced‐form results, learning from coworkers is significant, particularly from more knowledgeable coworkers. We show that between 4 and 9% of total worker compensation is in the form of learning and that inequality in total compensation is significantly lower than inequality in wages.",https://doi.org/10.3982/ECTA16915
Econometrica,2021,Information Technology and Government Decentralization: Experimental Evidence From Paraguay,"Ernesto Dal Bó, Frederico Finan, Nicholas Y. Li and Laura Schechter",Standard models of hierarchy assume that agents and middle managers are better informed than principals. We estimate the value of the informational advantage held by supervisors—middle managers—when ministerial leadership—the principal—introduced a new monitoring technology aimed at improving the performance of agricultural extension agents (AEAs) in rural Paraguay. Our approach employs a novel experimental design that elicited treatment‐priority rankings from supervisors before randomization of treatment. We find that supervisors have valuable information—they prioritize AEAs who would be more responsive to the monitoring treatment. We develop a model of monitoring under different scales of treatment roll‐out and different treatment allocation rules. We semiparametrically estimate marginal treatment effects (MTEs) to demonstrate that the value of information and the benefits to decentralizing treatment decisions depend crucially on the sophistication of the principal and on the scale of roll‐out.,https://doi.org/10.3982/ECTA17497
Econometrica,2021,Micro Data and Macro Technology,Ezra Oberfield and Devesh Raval,"We develop a framework to estimate the aggregate capital‐labor elasticity of substitution by aggregating the actions of individual plants. The aggregate elasticity reflects substitution within plants and reallocation across plants; the extent of heterogeneity in capital intensities determines their relative importance. We use micro data on the cross‐section of plants to build up to the aggregate elasticity at a point in time. Interpreting our econometric estimates through the lens of several different models, we find that the aggregate elasticity for the U.S. manufacturing sector is in the range of 0.5–0.7, and has declined slightly since 1970. We use our estimates to measure the bias of technical change and assess the decline in labor's share of income in the U.S. manufacturing sector. Mechanisms that rely on changes in the relative supply of factors, such as an acceleration of capital accumulation, cannot account for the decline.",https://doi.org/10.3982/ECTA12807
Econometrica,2021,Theory of Weak Identification in Semiparametric Models,Tetsuya Kaji,"We provide general formulation of weak identification in semiparametric models and an efficiency concept. Weak identification occurs when a parameter is weakly regular, that is, when it is locally homogeneous of degree zero. When this happens, consistent or equivariant estimation is shown to be impossible. We then show that there exists an underlying regular parameter that fully characterizes the weakly regular parameter. While this parameter is not unique, concepts of sufficiency and minimality help pin down a desirable one. If estimation of minimal sufficient underlying parameters is inefficient, it introduces noise in the corresponding estimation of weakly regular parameters, whence we can improve the estimators by local asymptotic Rao–Blackwellization. We call an estimator weakly efficient if it does not admit such improvement. New weakly efficient estimators are presented in linear IV and nonlinear regression models. Simulation of a linear IV model demonstrates how 2SLS and optimal IV estimators are improved.",https://doi.org/10.3982/ECTA16413
Econometrica,2021,Reasonable Doubt: Experimental Detection of Job‐Level Employment Discrimination,Patrick Kline and Christopher Walters,"This paper develops methods for detecting discrimination by individual employers using correspondence experiments that send fictitious resumes to real job openings. We establish identification of higher moments of the distribution of job‐level callback rates as a function of the number of resumes sent to each job and propose shape‐constrained estimators of these moments. Applying our methods to three experimental data sets, we find striking job‐level heterogeneity in the extent to which callback probabilities differ by race or sex. Estimates of higher moments reveal that while most jobs barely discriminate, a few discriminate heavily. These moment estimates are then used to bound the share of jobs that discriminate and the posterior probability that each individual job is engaged in discrimination. In a recent experiment manipulating racially distinctive names, we find that at least 85% of jobs that contact both of two white applications and neither of two black applications are engaged in discrimination. To assess the potential value of our methods for regulators, we consider the accuracy of decision rules for investigating suspicious callback behavior in various experimental designs under a simple two‐type model that rationalizes the experimental data. Though we estimate that only 17% of employers discriminate on the basis of race, we find that an experiment sending 10 applications to each job would enable detection of 7–10% of discriminatory jobs while yielding Type I error rates below 0.2%. A minimax decision rule acknowledging partial identification of the distribution of callback rates yields only slightly fewer investigations than a Bayes decision rule based on the two‐type model. These findings suggest illegal labor market discrimination can be reliably monitored with relatively small modifications to existing correspondence designs.",https://doi.org/10.3982/ECTA17489
Econometrica,2021,Long‐Term Contracting With Time‐Inconsistent Agents,Daniel Gottlieb and Xingtan Zhang,"We study contracts between naive present‐biased consumers and risk‐neutral firms. We show that the welfare loss from present bias vanishes as the contracting horizon grows. This is true both when bargaining power is on the consumers' and on the firms' side, when consumers cannot commit to long‐term contracts, and when firms do not know the consumers' naiveté. However, the welfare loss from present bias does not vanish when firms do not know the consumers' present bias or when they cannot offer exclusive contracts.",https://doi.org/10.3982/ECTA17126
Econometrica,2021,Model Selection for Treatment Choice: Penalized Welfare Maximization,Eric Mbakop and Max Tabord‐Meehan,"This paper studies a penalized statistical decision rule for the treatment assignment problem. Consider the setting of a utilitarian policy maker who must use sample data to allocate a binary treatment to members of a population, based on their observable characteristics. We model this problem as a statistical decision problem where the policy maker must choose a subset of the covariate space to assign to treatment, out of a class of potential subsets. We focus on settings in which the policy maker may want to select amongst a collection of constrained subset classes: examples include choosing the number of covariates over which to perform best‐subset selection, and model selection when approximating a complicated class via a sieve. We adapt and extend results from statistical learning to develop the Penalized Welfare Maximization (PWM) rule. We establish an oracle inequality for the regret of the PWM rule which shows that it is able to perform model selection over the collection of available classes. We then use this oracle inequality to derive relevant bounds on maximum regret for PWM. An important consequence of our results is that we are able to formalize model‐selection using a “holdout” procedure, where the policy maker would first estimate various policies using half of the data, and then select the policy which performs the best when evaluated on the other half of the data.",https://doi.org/10.3982/ECTA16437
Econometrica,2021,Errors in the Dependent Variable of Quantile Regression Models,"Jerry Hausman, Haoyang Liu, Ye Luo and Christopher Palmer","We study the consequences of measurement error in the dependent variable of random‐coefficients models, focusing on the particular case of quantile regression. The popular quantile regression estimator of Koenker and Bassett (1978) is biased if there is an additive error term. Approaching this problem as an errors‐in‐variables problem where the dependent variable suffers from classical measurement error, we present a sieve maximum likelihood approach that is robust to left‐hand‐side measurement error. After providing sufficient conditions for identification, we demonstrate that when the number of knots in the quantile grid is chosen to grow at an adequate speed, the sieve‐maximum‐likelihood estimator is consistent and asymptotically normal, permitting inference via bootstrapping. Monte Carlo evidence verifies our method outperforms quantile regression in mean bias and MSE. Finally, we illustrate our estimator with an application to the returns to education highlighting changes over time in the returns to education that have previously been masked by measurement‐error bias.",https://doi.org/10.3982/ECTA14667
Econometrica,2021,Quantile Factor Models,"Liang Chen, Juan Dolado and Jesus Gonzalo","Quantile factor models (QFM) represent a new class of factor models for high‐dimensional panel data. Unlike approximate factor models (AFM), which only extract mean factors, QFM also allow unobserved factors to shift other relevant parts of the distributions of observables. We propose a quantile regression approach, labeled Quantile Factor Analysis (QFA), to consistently estimate all the quantile‐dependent factors and loadings. Their asymptotic distributions are established using a kernel‐smoothed version of the QFA estimators. Two consistent model selection criteria, based on information criteria and rank minimization, are developed to determine the number of factors at each quantile. QFA estimation remains valid even when the idiosyncratic errors exhibit heavy‐tailed distributions. An empirical application illustrates the usefulness of QFA by highlighting the role of extra factors in the forecasts of U.S. GDP growth and inflation rates using a large set of predictors.",https://doi.org/10.3982/ECTA15746
Econometrica,2021,Strategic Sample Selection,"Alfredo Di Tillio, Marco Ottaviani and Peter Sørensen","Are the highest sample realizations selected from a larger presample more or less informative than the same amount of random data? Developing multivariate accuracy for interval dominance ordered preferences, we show that sample selection always benefits (or always harms) a decision maker if the reverse hazard rate of the data distribution is log‐supermodular (or log‐submodular), as in location experiments with normal noise. We find nonpathological conditions under which the information contained in the winning bids of a symmetric auction decreases in the number of bidders. Exploiting extreme value theory, we quantify the limit amount of information revealed when the presample size (number of bidders) goes to infinity. In a model of equilibrium persuasion with costly information, we derive implications for the optimal design of selected experiments when selection is made by an examinee, a biased researcher, or contending sides with the peremptory challenge right to eliminate a number of jurors.",https://doi.org/10.3982/ECTA17288
Econometrica,2021,Local Projections and VARs Estimate the Same Impulse Responses,Mikkel Plagborg‐Møller and Christian Wolf,"We prove that local projections (LPs) and Vector Autoregressions (VARs) estimate the same impulse responses. This nonparametric result only requires unrestricted lag structures. We discuss several implications: (i) LP and VAR estimators are not conceptually separate procedures; instead, they are simply two dimension reduction techniques with common estimand but different finite‐sample properties. (ii) VAR‐based structural identification—including short‐run, long‐run, or sign restrictions—can equivalently be performed using LPs, and vice versa. (iii) Structural estimation with an instrument (proxy) can be carried out by ordering the instrument first in a recursive VAR, even under noninvertibility. (iv) Linear VARs are as robust to nonlinearities as linear LPs.",https://doi.org/10.3982/ECTA17813
Econometrica,2021,Intergenerational Mobility in Africa,"Alberto Alesina, Sebastian Hohmann, Stelios Michalopoulos and Elias Papaioannou","We examine intergenerational mobility (IM) in educational attainment in Africa since independence using census data. First, we map IM across 27 countries and more than 2800 regions, documenting wide cross‐country and especially within‐country heterogeneity. Inertia looms large as differences in the literacy of the old generation explain about half of the observed spatial disparities in IM. The rural‐urban divide is substantial. Though conspicuous in some countries, there is no evidence of systematic gender gaps in IM. Second, we characterize the geography of IM, finding that colonial investments in railroads and Christian missions, as well as proximity to capitals and the coastline are the strongest correlates. Third, we ask whether the regional differences in mobility reflect spatial sorting or their independent role. To isolate the two, we focus on children whose families moved when they were young. Comparing siblings, looking at moves triggered by displacement shocks, and using historical migrations to predict moving‐families' destinations, we establish that, while selection is considerable, regional exposure effects are at play. An extra year spent in a high‐mobility region before the age of 12 (and after 5) significantly raises the likelihood for children of uneducated parents to complete primary school. Overall, the evidence suggests that geographic and historical factors laid the seeds for spatial disparities in IM that are cemented by sorting and the independent impact of regions.",https://doi.org/10.3982/ECTA17018
Econometrica,2021,Equilibrium Allocations Under Alternative Waitlist Designs: Evidence From Deceased Donor Kidneys,"Nikhil Agarwal, Itai Ashlagi, Michael A. Rees, Paulo Somaini and Daniel Waldinger","Waitlists are often used to ration scarce resources, but the trade‐offs in designing these mechanisms depend on agents' preferences. We study equilibrium allocations under alternative designs for the deceased donor kidney waitlist. We model the decision to accept an organ or wait for a preferable one as an optimal stopping problem and estimate preferences using administrative data from the New York City area. Our estimates show that while some kidney types are desirable for all patients, there is substantial match‐specific heterogeneity in values. We then develop methods to evaluate alternative mechanisms, comparing their effects on patient welfare to an equivalent change in donor supply. Past reforms to the kidney waitlist primarily resulted in redistribution, with similar welfare and organ discard rates to the benchmark first‐come, first‐served mechanism. These mechanisms and other commonly studied theoretical benchmarks remain far from optimal. We design a mechanism that increases patient welfare by the equivalent of an 18.2% increase in donor supply.",https://doi.org/10.3982/ECTA17017
Econometrica,2021,A Preferred‐Habitat Model of the Term Structure of Interest Rates,Dimitri Vayanos and Jean‐Luc Vila,"We model the term structure of interest rates that results from the interaction between investors with preferences for specific maturities and risk‐averse arbitrageurs. Shocks to the short rate are transmitted to long rates through arbitrageurs' carry trades. Arbitrageurs earn rents from transmitting the shocks through bond risk premia that relate positively to the slope of the term structure. When the short rate is the only risk factor, changes in investor demand have the same relative effect on interest rates across maturities regardless of the maturities where they originate. When investor demand is also stochastic, demand effects become more localized. A calibration indicates that long rates underreact to forward‐guidance announcements about short rates. Large‐scale asset purchases can be more effective in moving long rates, especially if they are concentrated at long maturities.",https://doi.org/10.3982/ECTA17440
Econometrica,2021,Adaptive Treatment Assignment in Experiments for Policy Choice,Maximilian Kasy and Anja Sautmann,"Standard experimental designs are geared toward point estimation and hypothesis testing, while bandit algorithms are geared toward in‐sample outcomes. Here, we instead consider treatment assignment in an experiment with several waves for choosing the best among a set of possible policies (treatments) at the end of the experiment. We propose a computationally tractable assignment algorithm that we call “exploration sampling,” where assignment probabilities in each wave are an increasing concave function of the posterior probabilities that each treatment is optimal. We prove an asymptotic optimality result for this algorithm and demonstrate improvements in welfare in calibrated simulations over both non‐adaptive designs and bandit algorithms. An application to selecting between six different recruitment strategies for an agricultural extension service in India demonstrates practical feasibility.",https://doi.org/10.3982/ECTA17527
Econometrica,2021,Policy Learning With Observational Data,Susan Athey and Stefan Wager,"In many areas, practitioners seek to use observational data to learn a treatment assignment policy that satisfies application‐specific constraints, such as budget, fairness, simplicity, or other functional form constraints. For example, policies may be restricted to take the form of decision trees based on a limited set of easily observable individual characteristics. We propose a new approach to this problem motivated by the theory of semiparametrically efficient estimation. Our method can be used to optimize either binary treatments or infinitesimal nudges to continuous treatments, and can leverage observational data where causal effects are identified using a variety of strategies, including selection on observables and instrumental variables. Given a doubly robust estimator of the causal effect of assigning everyone to treatment, we develop an algorithm for choosing whom to treat, and establish strong guarantees for the asymptotic utilitarian regret of the resulting policy.",https://doi.org/10.3982/ECTA15732
Econometrica,2021,Instability of Centralized Markets,Ahmad Peivandi and Rakesh V. Vohra,"Centralized markets reduce search for buyers and sellers. Their “thickness” increases the chance of order execution at nearly competitive prices. In spite of the incentives to consolidate, some markets, securities markets and on‐line advertising being the most notable, are fragmented into multiple trading venues. We argue that fragmentation is an inevitable feature of any centralized market except in special circumstances.",https://doi.org/10.3982/ECTA15579
Econometrica,2021,Deep Neural Networks for Estimation and Inference,"Max Farrell, Tengyuan Liang and Sanjog Misra","We study deep neural networks and their use in semiparametric inference. We establish novel nonasymptotic high probability bounds for deep feedforward neural nets. These deliver rates of convergence that are sufficiently fast (in some cases minimax optimal) to allow us to establish valid second‐step inference after first‐step estimation with deep learning, a result also new to the literature. Our nonasymptotic high probability bounds, and the subsequent semiparametric inference, treat the current standard architecture: fully connected feedforward neural networks (multilayer perceptrons), with the now‐common rectified linear unit activation function, unbounded weights, and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed‐width, very deep networks. We establish the nonasymptotic bounds for these deep nets for a general class of nonparametric regression‐type loss functions, which includes as special cases least squares, logistic regression, and other generalized linear models. We then apply our theory to develop semiparametric inference, focusing on causal parameters for concreteness, and demonstrate the effectiveness of deep learning with an empirical application to direct mail marketing.",https://doi.org/10.3982/ECTA16901
Econometrica,2021,The “New” Economics of Trade Agreements: From Trade Liberalization to Regulatory Convergence?,"Gene M. Grossman, Phillip McCalman and Robert Staiger","What incentives do governments have to negotiate trade agreements that constrain their domestic regulatory policies? We study a model in which firms design products to appeal to local consumer tastes, but their fixed costs increase with the difference between versions of their product destined for different markets. In this setting, firms' profit‐maximizing choices of product attributes are globally optimal in the absence of consumption externalities, but national governments have unilateral incentives to invoke regulatory protectionism to induce firm delocation. An efficient trade agreement requires commitments not to engage in such opportunistic behavior. A rule requiring mutual recognition of standards can be used to achieve efficiency, but one that requires only national treatment falls short. When product attributes confer local consumption externalities, an efficient trade agreement must coordinate the fine details of countries' regulatory policies.",https://doi.org/10.3982/ECTA17536
Econometrica,2021,Policy Persistence and Drift in Organizations,German Gieczewski,"This paper models the evolution of organizations that allow free entry and exit of members, such as cities and trade unions. In each period, current members choose a policy for the organization. Policy changes attract newcomers and drive away dissatisfied members, altering the set of future policymakers. The resulting feedback effects take the organization down a “slippery slope” that converges to a myopically stable policy, even if the agents are forward‐looking, but convergence becomes slower the more patient they are. The model yields a tractable characterization of the steady state and the transition dynamics. The analysis is also extended to situations in which the organization can exclude members, such as enfranchisement and immigration.",https://doi.org/10.3982/ECTA15873
Econometrica,2021,Media Capture Through Favor Exchange,Adam Szeidl and Ferenc Szucs,"We use data from Hungary to establish two results about the relationship between the government and the media. (i) We document large advertising favors from the government to connected media, and large corruption coverage favors from connected media to the government. Our empirical strategy exploits sharp reallocations around changes in media ownership and other events to rule out market‐based explanations. (ii) Under the assumptions of a structural model, we distinguish between owner ideology and favor exchange as the mechanism driving favors. We estimate our model exploiting within‐owner changes in coverage for identification and find that both mechanisms are important. These results imply that targeted government advertising can meaningfully influence content. Counterfactuals show that targeted advertising can also influence owner ideology, by making media ownership more profitable to pro‐government connected investors. Our results are consistent with qualitative evidence from many democracies and suggest that government advertising affects media content worldwide.",https://doi.org/10.3982/ECTA15641
Econometrica,2021,Structural Change With Long‐Run Income and Price Effects,"Diego Comin, Danial Lashkari and Martí Mestieri","We present a new multi‐sector growth model that features nonhomothetic, constant elasticity of substitution preferences, and accommodates long‐run demand and supply drivers of structural change for an arbitrary number of sectors. The model is consistent with the decline in agriculture, the hump‐shaped evolution of manufacturing, and the rise of services over time. We estimate the demand system derived from the model using household‐level data from the United States and India, as well as historical aggregate‐level panel data for 39 countries during the postwar period. The estimated model parsimoniously accounts for the broad patterns of sectoral reallocation observed among rich, miracle, and developing economies. Our estimates support the presence of strong nonhomotheticity across time, income levels, and countries. We find that income effects account for the bulk of the within‐country evolution of sectoral reallocation.",https://doi.org/10.3982/ECTA16317
Econometrica,2021,Dynamic Belief Elicitation,Christopher Chambers and Nicolas Lambert,"At an initial time, an individual forms a belief about a future random outcome. As time passes, the individual may obtain, privately or subjectively, further information, until the outcome is eventually revealed. How can a protocol be devised that induces the individual, as a strict best response, to reveal at the outset his prior assessment of both the final outcome and the information flows he anticipates and, subsequently, what information he privately receives? The protocol can provide the individual with payoffs that depend only on the outcome realization and his reports. We develop a framework to design such protocols, and apply it to construct simple elicitation mechanisms for common dynamic environments. The framework is general: we show that strategyproof protocols exist for any number of periods and large outcome sets. For these more general settings, we build a family of strategyproof protocols based on a hierarchy of choice menus, and show that any strategyproof protocol can be approximated by a protocol of this family.",https://doi.org/10.3982/ECTA15293
Econometrica,2021,A Practical Guide to Updating Beliefs From Contradictory Evidence,Evan Sadler,"We often make high stakes choices based on complex information that we have no way to verify. Careful Bayesian reasoning—assessing every reason why a claim could be false or misleading—is not feasible, so we necessarily act on faith: we trust certain sources and treat claims as if they were direct observations of payoff relevant events. This creates a challenge when trusted sources conflict: Practically speaking, is there a principled way to update beliefs in response to contradictory claims? I propose a model of belief formation along with several updating axioms. An impossibility theorem shows there is no obvious best answer, while a representation theorem delineates the boundary of what is possible.",https://doi.org/10.3982/ECTA17378
Econometrica,2021,Nonparametric Analysis of Random Utility Models: Computational Tools for Statistical Testing,"Bart Smeulders, Laurens Cherchye and Bram De Rock","Kitamura and Stoye (2018) recently proposed a nonparametric statistical test for random utility models of consumer behavior. The test is formulated in terms of linear inequality constraints and a quadratic objective function. While the nonparametric test is conceptually appealing, its practical implementation is computationally challenging. In this paper, we develop a column generation approach to operationalize the test. These novel computational tools generate considerable computational gains in practice, which substantially increases the empirical usefulness of Kitamura and Stoye's statistical test.",https://doi.org/10.3982/ECTA17605
Econometrica,2021,The Empirical Content of Binary Choice Models,Debopam Bhattacharya,"An important goal of empirical demand analysis is choice and welfare prediction on counterfactual budget sets arising from potential policy interventions. Such predictions are more credible when made without arbitrary functional‐form/distributional assumptions, and instead based solely on economic rationality, that is, that choice is consistent with utility maximization by a heterogeneous population. This paper investigates nonparametric economic rationality in the empirically important context of binary choice. We show that under general unobserved heterogeneity, economic rationality is equivalent to a pair of Slutsky‐like shape restrictions on choice‐probability functions. The forms of these restrictions differ from Slutsky inequalities for continuous goods. Unlike McFadden–Richter's stochastic revealed preference, our shape restrictions (a) are global, that is, their forms do not depend on which and how many budget sets are observed, (b) are closed form, hence easy to impose on parametric/semi/nonparametric models in practical applications, and (c) provide computationally simple, theory‐consistent bounds on demand and welfare predictions on counterfactual budge sets.",https://doi.org/10.3982/ECTA16801
Econometrica,2021,From Blackwell Dominance in Large Samples to Rényi Divergences and Back Again,"Xiaosheng Mu, Luciano Pomatto, Philipp Strack and Omer Tamuz","We study repeated independent Blackwell experiments; standard examples include drawing multiple samples from a population, or performing a measurement in different locations. In the baseline setting of a binary state of nature, we compare experiments in terms of their informativeness in large samples. Addressing a question due to Blackwell (1951), we show that generically an experiment is more informative than another in large samples if and only if it has higher Rényi divergences. We apply our analysis to the problem of measuring the degree of dissimilarity between distributions by means of divergences. A useful property of Rényi divergences is their additivity with respect to product distributions. Our characterization of Blackwell dominance in large samples implies that every additive divergence that satisfies the data processing inequality is an integral of Rényi divergences.",https://doi.org/10.3982/ECTA17548
