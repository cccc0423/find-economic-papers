journal,year,title,authors,abstract,url
Journal of Econometrics,2023,Cluster-robust inference: A guide to empirical practice,"James MacKinnon, Morten Nielsen and Matthew Webb","Methods for cluster-robust inference are routinely used in economics and many other disciplines. However, it is only recently that theoretical foundations for the use of these methods in many empirically relevant situations have been developed. In this paper, we use these theoretical results to provide a guide to empirical practice. We do not attempt to present a comprehensive survey of the (very large) literature. Instead, we bridge theory and practice by providing a thorough guide on what to do and why, based on recently available econometric theory and simulation evidence. To practice what we preach, we include an empirical analysis of the effects of the minimum wage on labor supply of teenagers using individual data.",http://www.sciencedirect.com/science/article/pii/S0304407622000781
Journal of Econometrics,2023,Fully modified least squares cointegrating parameter estimation in multicointegrated systems,Igor L. Kheifets and Peter Phillips,"Multicointegration is traditionally defined as a particular long run relationship among variables in a parametric vector autoregressive model that introduces additional cointegrating links between these variables and partial sums of the equilibrium errors. This paper departs from the parametric model, using a semiparametric formulation that reveals the explicit role that singularity of the long run conditional covariance matrix plays in determining multicointegration. The semiparametric framework has the advantage that short run dynamics do not need to be modeled and estimation by standard techniques such as fully modified least squares (FM-OLS) on the original I1 system is straightforward. The paper derives FM-OLS limit theory in the multicointegrated setting, showing how faster rates of convergence are achieved in the direction of singularity and that the limit distribution depends on the distribution of the conditional one-sided long run covariance estimator used in FM-OLS estimation. Wald tests of restrictions on the regression coefficients have nonstandard limit theory which depends on nuisance parameters in general. The usual tests are shown to be conservative when the restrictions are isolated to the directions of singularity and, under certain conditions, are invariant to singularity otherwise. Simulations show that approximations derived in the paper work well in finite samples. The findings are illustrated empirically in an analysis of fiscal sustainability of the US government over the post-war period.",http://www.sciencedirect.com/science/article/pii/S030440762100186X
Journal of Econometrics,2023,High dimensional semiparametric moment restriction models,"Chaohua Dong, Jiti Gao and Oliver Linton","We consider nonlinear moment restriction semiparametric models where both the dimension of the parameter vector and the number of restrictions are divergent with sample size and an unknown smooth function is involved. We propose an estimation method based on the sieve generalized method of moments (sieve-GMM). We establish consistency and asymptotic normality for the estimated quantities when the number of parameters increases modestly with sample size. We also consider the case where the number of potential parameters/covariates is very large, i.e., increases rapidly with sample size, but the true model exhibits sparsity. We use a penalized sieve GMM approach to select the relevant variables, and establish the oracle property of our method in this case. We also provide new results for inference. We propose several new test statistics for the over-identification and establish their large sample properties. We provide a simulation study and an application to data from the NLSY79 used by Carneiro et al. (2011).",http://www.sciencedirect.com/science/article/pii/S0304407621001883
Journal of Econometrics,2023,Second-order refinements for t-ratios with many instruments,Yukitoshi Matsushita and Taisuke Otsu,"This paper studies second-order properties of the many instruments robust t-ratios based on the limited information maximum likelihood and Fuller estimators for instrumental variable regression models with homoskedastic errors under the many instruments asymptotics, where the number of instruments may increase proportionally with the sample size n, and proposes second-order refinements to the t-ratios to improve the size and power properties. Based on asymptotic expansions of the null and non-null distributions of the t-ratios derived under the many instruments asymptotics, we show that the second-order terms of those expansions may have non-trivial impacts on the size as well as the power properties. Furthermore, we propose adjusted t-ratios whose approximation errors for the null rejection probabilities are of order O(n−1) in contrast to the ones for the unadjusted t-ratios of order O(n−1/2), and show that these adjustments induce some desirable power properties in terms of the local maximinity. Although these results are derived under homoskedastic errors, we also establish a stochastic expansion for a heteroskedasticity robust t-ratio, and propose an analogous adjustment under slight deviations from homoskedasticity.",http://www.sciencedirect.com/science/article/pii/S0304407621001901
Journal of Econometrics,2023,Smoothed quantile regression with large-scale inference,"Xuming He, Xiaoou Pan, Kean Ming Tan and Wen-Xin Zhou","Quantile regression is a powerful tool for learning the relationship between a response variable and a multivariate predictor while exploring heterogeneous effects. This paper focuses on statistical inference for quantile regression in the “increasing dimension” regime. We provide a comprehensive analysis of a convolution smoothed approach that achieves adequate approximation to computation and inference for quantile regression. This method, which we refer to as conquer, turns the non-differentiable check function into a twice-differentiable, convex and locally strongly convex surrogate, which admits fast and scalable gradient-based algorithms to perform optimization, and multiplier bootstrap for statistical inference. Theoretically, we establish explicit non-asymptotic bounds on estimation and Bahadur–Kiefer linearization errors, from which we show that the asymptotic normality of the conquer estimator holds under a weaker requirement on dimensionality than needed for conventional quantile regression. The validity of multiplier bootstrap is also provided. Numerical studies confirm conquer as a practical and reliable approach to large-scale inference for quantile regression. Software implementing the methodology is available in the R package conquer.",http://www.sciencedirect.com/science/article/pii/S0304407621001950
Journal of Econometrics,2023,Modeling and forecasting realized volatility with the fractional Ornstein–Uhlenbeck process,"Xiaohu Wang, Weilin Xiao and Jun Yu","This paper proposes to model and forecast realized volatility (RV) using the fractional Ornstein–Uhlenbeck (fO–U) process with a general Hurst parameter, H. A two-stage method is introduced for estimating parameters in the fO–U process based on discrete-sampled observations. In the first stage, H is estimated based on the ratio of two second-order differences of observations from different frequencies. In the second stage, with the estimated H, the other parameters of the model are estimated by the method of moments. All estimators have closed-form expressions and are easy to implement. A large sample theory of the proposed estimators is derived. Extensive simulations show that the proposed estimators and the large-sample theory perform well in finite samples. We apply the model and the method to the logarithmic daily RV series of various financial assets. Our empirical findings suggest that H is much smaller than 1/2, indicating that the RV series have rough sample paths, and that the mean reversion parameter takes a small positive number, indicating that the RV series are stationary but have slow mean reversion. The proposed model is compared with many alternative models, including the fractional Brownian motion, ARFIMA, and HAR, in forecasting RV and logarithmic RV.",http://www.sciencedirect.com/science/article/pii/S0304407621002037
Journal of Econometrics,2023,A discrete-time hedging framework with multiple factors and fat tails: On what matters,"Maciej Augustyniak, Alexandru Badescu and Jean-François Bégin","This article presents a quadratic hedging framework for a general class of discrete-time affine multi-factor models and investigates the extent to which multi-component volatility factors, fat tails, and a non-monotonic pricing kernel can improve the hedging performance. A semi-explicit hedging formula is derived for our general framework which applies to a myriad of the option pricing models proposed in the discrete-time literature. We conduct an extensive empirical study of the impact of modelling features on the hedging effectiveness of S&P 500 options. Overall, we find that fat tails can be credited for half of the hedging improvement observed, while a second volatility factor and a non-monotonic pricing kernel each contribute to a quarter of this improvement. Moreover, our study indicates that the added value of these features for hedging is different than for pricing. A robustness analysis shows that a similar conclusion can be reached when considering the Dow Jones Industrial Average. Finally, the use of a hedging-based loss function in the estimation process is investigated in an additional robustness test, and this choice has a rather marginal impact on hedging performance.",http://www.sciencedirect.com/science/article/pii/S0304407621002049
Journal of Econometrics,2023,Estimating the variance of a combined forecast: Bootstrap-based approach,Ulrich Hounyo and Kajal Lahiri,"This paper considers bootstrap inference in model averaging for predictive regressions. We first show that the standard pairwise bootstrap is not valid in the context of model averaging. This common bootstrap approach induces a bias-related term in the bootstrap variance of averaging estimators. We then propose and justify a fixed-design residual-based bootstrap resampling approach for model averaging. In a local asymptotic framework, we show the validity of the bootstrap in estimating the variance of a combined forecast and the asymptotic covariance matrix of a combined parameter vector with fixed weights. Our proposed method preserves non-parametrically the cross-sectional dependence between different models and the time series dependence in the errors simultaneously. The finite sample performance of these methods is assessed via Monte Carlo simulations. We illustrate our approach using an empirical study of the Taylor rule equation with 24 alternative specifications.",http://www.sciencedirect.com/science/article/pii/S0304407621002244
Journal of Econometrics,2023,When bias contributes to variance: True limit theory in functional coefficient cointegrating regression,Peter Phillips and Ying Wang,"Limit distribution theory in the econometric literature for functional coefficient cointegrating regression is incorrect in important ways, influencing rates of convergence, distributional properties, and practical work. The correct limit theory reveals that components from both bias and variance terms contribute to variability in the asymptotics. The errors in the literature arise because random variability in the bias term has been neglected in earlier research. In stationary regression this random variability is of smaller order and can be ignored in asymptotic analysis but not without consequences for finite sample performance. Implications of the findings for rate efficient estimation are discussed. Simulations in the Online Supplement provide further evidence supporting the new limit theory in nonstationary functional coefficient regressions.",http://www.sciencedirect.com/science/article/pii/S0304407621002190
Journal of Econometrics,2023,Relaxing conditional independence in an endogenous binary response model,Alyssa Carlson,"For binary response models, the literature primarily addresses endogeneity by a control function approach assuming conditional independence (CF-CI). However, as the literature also notes, CF-CI implies conditions like homoskedasticity (of the latent error with respect to the instruments) that fail in many empirical settings. I propose an alternative approach that allows for heteroskedasticity, achieving identification with a conditional mean restriction. These identification results apply to a latent Gaussian error term with flexibly parametrized heteroskedasticity. I propose a two step conditional maximum likelihood estimator and derive its asymptotic distribution. In simulations, the new estimator outperforms others when CF-CI fails and is fairly robust to distributional misspecification.",http://www.sciencedirect.com/science/article/pii/S030440762100230X
Journal of Econometrics,2023,Scalable inference for a full multivariate stochastic volatility model,"Petros Dellaportas, Michalis K. Titsias, Katerina Petrova and Anastasios Plataniotis","We introduce a multivariate stochastic volatility model that imposes no restrictions on the structure of the volatility matrix and treats all its elements as functions of latent stochastic processes. Inference is achieved via a carefully designed feasible and scalable MCMC that has quadratic, rather than cubic, computational complexity for evaluating the multivariate normal densities required. We illustrate how our model can be applied on macroeconomic applications through a stochastic volatility VAR model, comparing it to competing approaches in the literature. We also demonstrate how our approach can be applied to a large dataset containing 571 stock daily returns of Euro STOXX index.",http://www.sciencedirect.com/science/article/pii/S030440762100227X
Journal of Econometrics,2023,"A simple joint model for returns, volatility and volatility of volatility","Ding, Yashuang (Dexter)","We propose a model that allows for conditional heteroskedasticity in the volatility of asset returns and incorporates current return information into the volatility nowcast and forecast. Our model can capture all stylised facts of asset returns even with Gaussian innovations and is simple to implement. Moreover, we show that our model converges weakly to the GARCH-type diffusion as the length of the discrete time intervals between observations goes to zero. Empirical evidence shows that our model has a better fit, a more efficient parameter estimator as well as more accurate volatility and VaR forecasts than other common GARCH-type models.",http://www.sciencedirect.com/science/article/pii/S0304407621002268
Journal of Econometrics,2023,Testing and support recovery of correlation structures for matrix-valued observations with an application to stock market data,"Xin Chen, Dan Yang, Yan Xu, Yin Xia, Dong Wang and Haipeng Shen","Estimation of the covariance matrix of asset returns is crucial to portfolio construction. As suggested by economic theories, the correlation structure among assets differs between emerging markets and developed countries. It is therefore imperative to make rigorous statistical inference on correlation matrix equality between the two groups of countries. However, if the traditional vector-valued approach is undertaken, such inference is either infeasible due to limited number of countries comparing to the relatively abundant assets, or invalid due to the violations of temporal independence assumption. This highlights the necessity of treating the observations as matrix-valued rather than vector-valued. With matrix-valued observations, our problem of interest can be formulated as statistical inference on covariance structures under sub-Gaussian distributions, i.e., testing non-correlation and correlation equality, as well as the corresponding support estimations. We develop procedures that are asymptotically optimal under some regularity conditions. Simulation results demonstrate the computational and statistical advantages of our procedures over certain existing state-of-the-art methods for both normal and non-normal distributions. Application of our procedures to stock market data reveals interesting patterns and validates several economic propositions via rigorous statistical testing.",http://www.sciencedirect.com/science/article/pii/S0304407621002281
Journal of Econometrics,2023,Why randomize? Minimax optimality under permutation invariance,Yuehao Bai,"This paper studies finite sample minimax optimal randomization schemes and estimation schemes in estimating parameters including the average treatment effect, when treatment effects are heterogeneous. A randomization scheme is a distribution over a group of permutations of a given treatment assignment vector. An estimation scheme is a joint distribution over assignment vectors, linear estimators, and permutations of assignment vectors. The key element in the minimax problem is that the worst case is over a class of distributions of the data which is invariant to a group of permutations. First, I show that given any assignment vector and any estimator, the uniform distribution over the same group of permutations, namely the complete randomization scheme, is minimax optimal. Second, under further assumptions on the class of distributions and the objective function, I show the minimax optimal estimation scheme involves completely randomizing an assignment vector, while the optimal estimator is the difference-in-means under complete invariance and a weighted average of within-block differences under a block structure, and the number of treated units is determined by the Neyman allocation.",http://www.sciencedirect.com/science/article/pii/S0304407621002566
Journal of Econometrics,2023,"Identification of time-varying transformation models with fixed effects, with an application to unobserved heterogeneity in resource shares","Irene Botosaru, Chris Muris and Krishna Pendakur","We provide new results showing identification of a large class of fixed-T panel models, where the response variable is an unknown, weakly monotone, time-varying transformation of a latent linear index of fixed effects, regressors, and an error term drawn from an unknown stationary distribution. Our results identify the transformation, the coefficient on regressors, and features of the distribution of the fixed effects. We then develop a full-commitment intertemporal collective household model, where the implied quantity demand equations are time-varying functions of a linear index. The fixed effects in this index equal logged resource shares, defined as the fractions of household expenditure enjoyed by each household member. Using Bangladeshi data, we show that women’s resource shares decline with household budgets and that half of the variation in women’s resource shares is due to unobserved household-level heterogeneity.",http://www.sciencedirect.com/science/article/pii/S0304407621002633
Journal of Econometrics,2023,Time series analysis of COVID-19 infection curve: A change-point perspective,"Feiyu Jiang, Zifeng Zhao and Xiaofeng Shao","In this paper, we model the trajectory of the cumulative confirmed cases and deaths of COVID-19 (in log scale) via a piecewise linear trend model. The model naturally captures the phase transitions of the epidemic growth rate via change-points and further enjoys great interpretability due to its semiparametric nature. On the methodological front, we advance the nascent self-normalization (SN) technique (Shao, 2010) to testing and estimation of a single change-point in the linear trend of a nonstationary time series. We further combine the SN-based change-point test with the NOT algorithm (Baranowski et al., 2019) to achieve multiple change-point estimation. Using the proposed method, we analyze the trajectory of the cumulative COVID-19 cases and deaths for 30 major countries and discover interesting patterns with potentially relevant implications for effectiveness of the pandemic responses by different countries. Furthermore, based on the change-point detection algorithm and a flexible extrapolation function, we design a simple two-stage forecasting scheme for COVID-19 and demonstrate its promising performance in predicting cumulative deaths in the U.S.",http://www.sciencedirect.com/science/article/pii/S0304407620302633
Journal of Econometrics,2023,Nowcasting the output gap,"Tino Berger, James Morley and Benjamin Wong","We propose a way to directly nowcast the output gap using the Beveridge–Nelson decomposition based on a mixed-frequency Bayesian VAR. The mixed-frequency approach produces similar but more timely estimates of the U.S. output gap compared to those based on a quarterly model, the CBO measure of potential, or the HP filter. We find that within-quarter nowcasts for the output gap are more reliable than for output growth, with monthly indicators for a credit risk spread, consumer sentiment, and the unemployment rate providing particularly useful new information about the final estimate of the output gap. An out-of-sample analysis of the COVID-19 crisis anticipates the exceptionally large negative output gap of −8.3% in 2020Q2 before the release of real GDP data for the quarter, with both conditional and scenario nowcasts tracking a dramatic decline in the output gap given the April data.",http://www.sciencedirect.com/science/article/pii/S0304407620303523
Journal of Econometrics,2023,Time varying Markov process with partially observed aggregate data: An application to coronavirus,C. Gourieroux and Joann Jasiak,"A major difficulty in the analysis of Covid-19 transmission is that many infected individuals are asymptomatic. For this reason, the total counts of infected individuals and of recovered immunized individuals are unknown, especially during the early phase of the epidemic. In this paper, we consider a parametric time varying Markov process of Coronavirus transmission and show how to estimate the model parameters and approximate the unobserved counts from daily data on infected and detected individuals and the total daily death counts. This model-based approach is illustrated in an application to French data, performed on April 6, 2020.",http://www.sciencedirect.com/science/article/pii/S0304407620303791
Journal of Econometrics,2023,Nowcasting in a pandemic using non-parametric mixed frequency VARs,"Florian Huber, Gary Koop, Luca Onorante, Michael Pfarrhofer and Josef Schreiner","This paper develops Bayesian econometric methods for posterior inference in non-parametric mixed frequency VARs using additive regression trees. We argue that regression tree models are ideally suited for macroeconomic nowcasting in the face of extreme observations, for instance those produced by the COVID-19 pandemic of 2020. This is due to their flexibility and ability to model outliers. In an application involving four major euro area countries, we find substantial improvements in nowcasting performance relative to a linear mixed frequency VAR.",http://www.sciencedirect.com/science/article/pii/S0304407620303936
Journal of Econometrics,2023,How to go viral: A COVID-19 model with endogenously time-varying parameters,"Paul Ho, Thomas A. Lubik and Christian Matthes","We estimate a panel model with endogenously time-varying parameters for COVID-19 cases and deaths in U.S. states. The functional form for infections incorporates important features of epidemiological models but is flexibly parameterized to capture different trajectories of the pandemic. Daily deaths are modeled as a spike-and-slab regression on lagged cases. Our Bayesian estimation reveals that social distancing and testing have significant effects on the parameters. For example, a 10 percentage point increase in the positive test rate is associated with a 2 percentage point increase in the death rate among reported cases. The model forecasts perform well, even relative to models from epidemiology and statistics.",http://www.sciencedirect.com/science/article/pii/S0304407621000105
Journal of Econometrics,2023,Nonparametric comparison of epidemic time trends: The case of COVID-19,Marina Khismatullina and Michael Vogt,"The COVID-19 pandemic is one of the most pressing issues at present. A question which is particularly important for governments and policy makers is the following: Does the virus spread in the same way in different countries? Or are there significant differences in the development of the epidemic? In this paper, we devise new inference methods that allow to detect differences in the development of the COVID-19 epidemic across countries in a statistically rigorous way. In our empirical study, we use the methods to compare the outbreak patterns of the epidemic in a number of European countries.",http://www.sciencedirect.com/science/article/pii/S030440762100155X
Journal of Econometrics,2023,Who should get vaccinated? Individualized allocation of vaccines over SIR network,Toru Kitagawa and Guanyi Wang,"How to allocate vaccines over heterogeneous individuals is one of the important policy decisions in pandemic times. This paper develops a procedure to estimate an individualized vaccine allocation policy under limited supply, exploiting social network data containing individual demographic characteristics and health status. We model the spillover effects of vaccination based on a Heterogeneous-Interacted-SIR network model and estimate an individualized vaccine allocation policy by maximizing an estimated social welfare (public health) criterion incorporating these spillovers. While this optimization problem is generally an NP-hard integer optimization problem, we show that the SIR structure leads to a submodular objective function, and provide a computationally attractive greedy algorithm for approximating a solution that has a theoretical performance guarantee. Moreover, we characterize a finite sample welfare regret bound and examine how its uniform convergence rate depends on the complexity and riskiness of the social network. In the simulation, we illustrate the importance of considering spillovers by comparing our method with targeting without network information.",http://www.sciencedirect.com/science/article/pii/S0304407621002219
Journal of Econometrics,2023,Sparse spatio-temporal autoregressions by profiling and bagging,"Yingying Ma, Shaojun Guo and Hansheng Wang","We consider a new class of spatio-temporal models with sparse autoregressive coefficient matrices and exogenous variable. To estimate the model, we first profile the exogenous variable out of the response. This leads to a profiled model structure. Next, to overcome endogeneity issue, we propose a class of generalized methods of moment (GMM) estimators to estimate the autoregressive coefficient matrices. A novel bagging-based estimator is further developed to conquer the over-determined issue which also occurs in Chang et al. (2015) and Dou et al. (2016). An adaptive forward–backward greedy algorithm is proposed to learn the sparse structure of the autoregressive coefficient matrices. A new BIC-type selection criteria is further developed to conduct variable selection for GMM estimators. Asymptotic properties are further studied. The proposed methodology is illustrated with extensive simulation studies. A social network dataset is analyzed for illustration purpose.",http://www.sciencedirect.com/science/article/pii/S030440762100035X
Journal of Econometrics,2023,Efficient closed-form estimation of large spatial autoregressions,Abhimanyu Gupta,"Newton-step approximations to pseudo maximum likelihood estimates of spatial autoregressive models with a large number of parameters are examined, in the sense that the parameter space grows slowly as a function of sample size. These have the same asymptotic efficiency properties as maximum likelihood under Gaussianity but are of closed form. Hence they are computationally simple and free from compactness assumptions, thereby avoiding two notorious pitfalls of implicitly defined estimates of large spatial autoregressions. When commencing from an initial least squares estimate, the Newton step can also lead to weaker regularity conditions for a central limit theorem than some extant in the literature. A simulation study demonstrates excellent finite sample gains from Newton iterations, especially in large multiparameter models for which grid search is costly. A small empirical illustration shows improvements in estimation precision with real data.",http://www.sciencedirect.com/science/article/pii/S0304407621001597
Journal of Econometrics,2023,Spatial econometrics for misaligned data,Guillaume Allaire Pouliot,"We produce methodology for regression analysis when the geographic locations of the independent and dependent variables do not coincide, in which case we speak of misaligned data. We develop and investigate two complementary methods for regression analysis with misaligned data that circumvent the need to estimate or specify the covariance of the regression errors. We carry out a detailed reanalysis of Maccini and Yang (2009) and find economically significant quantitative differences but sustain most qualitative conclusions.",http://www.sciencedirect.com/science/article/pii/S0304407621001627
Journal of Econometrics,2023,A spatial panel quantile model with unobserved heterogeneity,"Tomohiro Ando, Kunpeng Li and Lina Lu","This paper introduces a spatial panel quantile model with unobserved heterogeneity. The proposed model is capable of capturing high-dimensional cross-sectional dependence and allows heterogeneous regression coefficients. For estimating model parameters, a new estimation procedure is proposed. When both the time and cross-sectional dimensions of the panel go to infinity, the uniform consistency and the asymptotic normality of the estimated parameters are established. In order to determine the dimension of the interactive fixed effects, we propose a new information criterion. It is shown that the criterion asymptotically selects the true dimension. Monte Carlo simulations document the satisfactory performance of the proposed method. Finally, the method is applied to study the quantile co-movement structure of the U.S. stock market by taking into account the input–output linkages as firms are connected through the input–output production network.",http://www.sciencedirect.com/science/article/pii/S0304407621002323
Journal of Econometrics,2023,Estimation of spatial sample selection models: A partial maximum likelihood approach,Renata Rabovič and Pavel Cizek,"We study estimation of sample selection models with the spatially lagged latent dependent variable or spatial errors in both the selection and outcome equations under cross-sectional dependence. Since there is no estimation framework for the spatial-lag model and the existing estimators for the spatial-error model are computationally demanding or have poor small sample properties, we suggest to estimate these models by the partial maximum likelihood estimator. We show that the estimator is consistent and asymptotically normally distributed. To facilitate easy and precise estimation of the variance matrix, we propose the parametric bootstrap method. Simulations demonstrate the advantages of the estimators.",http://www.sciencedirect.com/science/article/pii/S0304407621002815
Journal of Econometrics,2023,Higher-order least squares inference for spatial autoregressions,Francesca Rossi and Peter M. Robinson,"We develop refined inference for spatial regression models with predetermined regressors. The ordinary least squares estimate of the spatial parameter is neither consistent nor asymptotically normal, unless the elements of the spatial weight matrix uniformly vanish as sample size diverges. We develop refined testing of the hypothesis of no spatial dependence, without requiring such negligibility of spatial weights, by formal Edgeworth expansions. We also develop such higher-order expansions for both an unstudentized and a studentized transformed estimate, where the studentized one can be used to provide refined interval estimates. A Monte Carlo study of finite sample performance is included.",http://www.sciencedirect.com/science/article/pii/S0304407622000458
