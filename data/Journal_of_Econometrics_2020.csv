journal,year,title,authors,abstract,url
Journal of Econometrics,2020,Nonparametric filtering of conditional state-price densities,Jeroen Dalderop,This paper studies the use of noisy high-frequency data to estimate the time-varying state-price density implicit in European option prices. A dynamic kernel estimator of the conditional pricing function and its derivatives is proposed that can be used for model-free risk measurement. Infill asymptotic theory is derived that applies when the pricing function is either smoothly varying or driven by diffusive state variables. Trading times and moneyness levels are modeled by marked point processes that capture intraday trading patterns. A simulation study investigates the performance of the estimator using a varying plug-in bandwidth in various scenarios. Empirical analysis using S&P 500 E-mini European option quotes reveals significant time-variation at intraday frequencies. An application towards delta- and minimum variance-hedging further illustrates the use of the estimator.,http://www.sciencedirect.com/science/article/pii/S030440761930168X
Journal of Econometrics,2020,Variance disparity and market frictions,Yang-Ho Park,"This paper introduces a new model-free approach to measuring the expectation of market variance using VIX derivatives. This approach shows that VIX derivatives carry different information about future variance than S&P 500 (SPX) options, especially during the 2008 financial crisis. I find that the segmentation is associated with frictions such as funding illiquidity, market illiquidity, and asymmetric information. When they are segmented, VIX derivatives contribute more to the variance discovery process than SPX options. These findings imply that VIX derivatives would offer a better estimate of expected variance than SPX options, and that a measure of segmentation may be useful for policymakers as it signals the severity of frictions.",http://www.sciencedirect.com/science/article/pii/S0304407619301654
Journal of Econometrics,2020,Nonparametric assessment of hedge fund performance,"Caio Almeida, Kym Ardison and René Garcia","We propose a new class of performance measures for Hedge Fund (HF) returns based on a family of empirically identifiable stochastic discount factors (SDFs). The SDF-based measures incorporate no-arbitrage pricing restrictions and naturally embed information about higher-order mixed moments between HF and benchmark factors returns. We provide a full asymptotic theory for our SDF estimators to test for the statistical significance of each fund’s performance and for the relevance of individual benchmark factors within each proposed measure. We apply our methodology to a panel of 4815 individual hedge funds. Our empirical analysis reveals that fewer funds have a statistically significant positive alpha compared to the Jensen’s alpha obtained by the traditional linear regression approach. Moreover, the funds’ rankings vary considerably between the two approaches. Performance also varies between the members of our family because of a different fund exposure to higher-order moments of the benchmark factors, highlighting the potential heterogeneity across investors in evaluating performance.",http://www.sciencedirect.com/science/article/pii/S0304407619301617
Journal of Econometrics,2020,On rank estimators in increasing dimensions,"Yanqin Fan, Fang Han, Wei Li and Xiao-Hua Zhou","The family of rank estimators, including Han’s maximum rank correlation (Han, 1987) as a notable example, has been widely exploited in studying regression problems. For these estimators, although the linear index is introduced for alleviating the impact of dimensionality, the effect of large dimension on inference is rarely studied. This paper fills this gap via studying the statistical properties of a larger family of M-estimators, whose objective functions are formulated as U-processes and may be discontinuous in increasing dimension set-up where the number of parameters, pn, in the model is allowed to increase with the sample size, n. First, we find that often in estimation, as pn∕n→0, (pn∕n)1∕2 rate of convergence is obtainable. Second, we establish Bahadur-type bounds and study the validity of normal approximation, which we find often requires a much stronger scaling requirement than pn2∕n→0. Third, we state conditions under which the numerical derivative estimator of asymptotic covariance matrix is consistent, and show that the step size in implementing the covariance estimator has to be adjusted with respect to pn. All theoretical results are further backed up by simulation studies.",http://www.sciencedirect.com/science/article/pii/S0304407619301678
Journal of Econometrics,2020,"Measurement error in multiple equations: Tobin’s q and corporate investment, saving, and debt",Karim Chalak and Daniel Kim,"We characterize the sharp identification regions for the coefficients in a system of linear equations that share an explanatory variable measured with classical error. We demonstrate the identification gain from analyzing the equations jointly. We derive the sharp identification regions under any configuration of three auxiliary assumptions. These restrict the “noise-to-signal” ratio, the coefficients of determination, and the signs of the correlations among the cross-equation disturbances. For inference, we implement results on intersection bounds. The application studies the effects of cash flow on the investment, saving, and debt of firms when Tobin’s q serves as a proxy for marginal q.",http://www.sciencedirect.com/science/article/pii/S0304407619301575
Journal of Econometrics,2020,Inference in heavy-tailed vector error correction models,Rui She and Shiqing Ling,"This paper first studies the full rank least squares estimator (FLSE) of the heavy-tailed vector error correction (VEC) models. It is shown that the rate of convergence of the FLSE related to the long-run parameters is n (sample size) and its limiting distribution is a stochastic integral in terms of two stable random processes when the tail index α∈(0,2). Furthermore, we show that the rate of convergence of the FLSE related to the short-term parameters is n1∕αL̃(n) and its limiting distribution is a functional of two stable processes when α∈(1,2), where L̃(n) is a slowly varying function. However, when α∈(0,1), we show that the rate of convergence of the FLSE related to the short-term parameters is n and its limiting distribution not only depends on the stationary component itself but also depends on the unit root component. Based on the FLSE, we then study the limiting behavior of the reduced rank LSE (RLSE). The results related to the short-term parameters of both FLSE and RLSE are significantly different from those of heavy-tailed time series in the literature, and it may provide new insights in the area for future research. Simulation study is carried out to demonstrate the performance of both estimators. A real example with application to 3-month Treasury Bill rate, 1-year Treasury Bill rate and Federal Fund rate is given.",http://www.sciencedirect.com/science/article/pii/S0304407619301691
Journal of Econometrics,2020,Panel threshold regressions with latent group structures,"Ke Miao, Liangjun Su and Wendun Wang","In this paper, we consider the least squares estimation of a panel structure threshold regression (PSTR) model where both the slope coefficients and threshold parameters may exhibit latent group structures. We study the asymptotic properties of the estimators of the latent group structure and the slope and threshold coefficients. We show that we can estimate the latent group structure correctly with probability approaching 1 and the estimators of the slope and threshold coefficients are asymptotically equivalent to the infeasible estimators that are obtained as if the true group structures were known. We study likelihood-ratio-based inferences on the group-specific threshold parameters under the shrinking-threshold-effect framework. We also propose two specification tests: one tests whether the threshold parameters are homogeneous across groups, and the other tests whether the threshold effects are present. When the number of latent groups is unknown, we propose a BIC-type information criterion to determine the number of groups in the data. Simulations demonstrate that our estimators and tests perform reasonably well in finite samples. We apply our model to revisit the relationship between capital market imperfection and the investment behavior of firms and to examine the impact of bank deregulation on income inequality. We document a large degree of heterogeneous effects in both applications that cannot be captured by conventional panel threshold regressions.",http://www.sciencedirect.com/science/article/pii/S0304407619301708
Journal of Econometrics,2020,High-dimensional minimum variance portfolio estimation based on high-frequency data,"T. Tony Cai, Jianchang Hu, Yingying Li and Xinghua Zheng","This paper studies the estimation of high-dimensional minimum variance portfolio (MVP) based on the high frequency returns which can exhibit heteroscedasticity and possibly be contaminated by microstructure noise. Under certain sparsity assumptions on the precision matrix, we propose estimators of the MVP and prove that our portfolios asymptotically achieve the minimum variance in a sharp sense. In addition, we introduce consistent estimators of the minimum variance, which provide reference targets. Simulation and empirical studies demonstrate the favorable performance of the proposed portfolios.",http://www.sciencedirect.com/science/article/pii/S0304407619301630
Journal of Econometrics,2020,Robust estimation with many instruments,Mikkel Sølvsten,"Linear instrumental variables models are widely used in empirical work, but often associated with low estimator precision. This paper proposes an estimator that is robust to outliers and shows that the estimator is minimax optimal in a class of estimators that includes the limited maximum likelihood estimator (LIML). Intuitively, this optimal robust estimator combines LIML with Winsorization of the structural residuals and the Winsorization leads to improved precision under thick-tailed error distributions. Consistency and asymptotic normality of the estimator are established under many instruments asymptotics and a consistent variance estimator which allows for asymptotically valid inference is provided.",http://www.sciencedirect.com/science/article/pii/S0304407619301721
Journal of Econometrics,2020,Modelling regional patterns of inefficiency: A Bayesian approach to geoadditive panel stochastic frontier analysis with an application to cereal production in England and Wales,"Nadja Klein, Helmut Herwartz and Thomas Kneib",We propose a flexible Bayesian approach to inefficiency modelling that accounts for regional patterns of local performance. The model allows for a separated treatment of individual heterogeneity and determinants of inefficiency. Regional dependence structures and location-specific unobserved spatial heterogeneity are modelled via geoadditive predictors in the inefficiency term of the stochastic frontier model. Inference becomes feasible through Markov chain Monte Carlo simulation techniques. In an empirical illustration we find that regional patterns of inefficiency characterize cereal production in England and Wales. Neglecting common performance patterns of farms located in the same region induces systematic biases to inefficiency estimates.,http://www.sciencedirect.com/science/article/pii/S0304407619301587
Journal of Econometrics,2020,Econometric estimates of Earth’s transient climate sensitivity,"Peter Phillips, Thomas Leirvik and Trude Storelvmo","How sensitive is Earth’s climate to a given increase in atmospheric greenhouse gas (GHG) concentrations? This long-standing question in climate science was recently analyzed by dynamic panel data methods using extensive spatio-temporal data of global surface temperatures, solar radiation, and GHG concentrations over the last half century to 2010 (Storelvmo et al, 2016). Those methods revealed that atmospheric aerosol effects masked approximately one-third of the continental warming due to increasing GHG concentrations over this period, thereby implying greater climate sensitivity to GHGs than previously thought. The present study provides regularity conditions and asymptotic theory justifying the use of time series cointegration-based methods of estimation when there are both stochastic process and deterministic trends in the global forcing variables, such as GHGs, and station-level trend effects from such sources as local aerosol pollutants. The asymptotics validate estimation and confidence interval construction for econometric measures of Earth’s transient climate sensitivity (TCS). The methods are applied to observational data and to data generated from several groups of global climate models (GCMs) that are sampled spatio-temporally and aggregated in the same way as the empirical observations for the time period 1964–2005. The findings indicate that 7 out of 9 of the GCM reported TCS values lie within the 95% empirical confidence interval computed econometrically from the GCM output. The analysis shows the potential of econometric methods to provide empirical estimates and confidence limits for TCS, to calibrate GCM simulation output against observational data in terms of the implied TCS estimates obtained via the econometric model, and to reveal the respective sensitivity parameters (GHG and non-GHG related) governing GCM temperature trends.",http://www.sciencedirect.com/science/article/pii/S0304407619301058
Journal of Econometrics,2020,Modeling time series when some observations are zero,Andrew Harvey and Ryoko Ito,"Sometimes a significant proportion of observations in a time series are zero, but the remaining observations are positive and measured on a continuous scale. We propose a new dynamic model in which the conditional distribution of the observations is constructed by shifting a distribution for non-zero observations to the left and censoring negative values. The key to generalizing the censoring approach to the dynamic case is to have (the logarithm of) the location/scale parameter driven by a filter that depends on the score of the conditional distribution. An exponential link function means that seasonal effects can be incorporated into the model and this is done by means of a cubic spline (which can potentially be time-varying). The model is fitted to daily rainfall in locations in northern Australia and England and compared with a dynamic zero-augmented model.",http://www.sciencedirect.com/science/article/pii/S030440761930106X
Journal of Econometrics,2020,Long-term forecasting of El Niño events via dynamic factor simulations,"Mengheng Li, Siem Jan Koopman, Rutger Lit and Desislava Petrova","We propose a new forecasting procedure which particularly explores opportunities for improving the precision of medium and long-term forecasts of the Niño3.4 time series that is linked with the well-known El Niño phenomenon. This important climatic time series is subject to an intricate dynamic structure and is interrelated to other climatological variables. The procedure consists of three steps. First, a univariate time series model is considered for producing prediction errors. Second, signal paths of the prediction errors are simulated via a dynamic factor model for the errors and explanatory variables. From these simulated errors, ensemble time series for Niño3.4 are constructed. Third, forecasts are generated from the ensemble time series and their sample average is our final forecast. As part of these dynamic factor simulations, we also obtain the forecast of the El Niño event which is a categorical variable. We present empirical evidence that our procedure can be superior in its forecasting performance when compared to other econometric forecasting methods.",http://www.sciencedirect.com/science/article/pii/S0304407619301071
Journal of Econometrics,2020,Statistical approximation of high-dimensional climate models,"Alena Miftakhova, Kenneth Judd, Thomas S. Lontzek and Karl Schmedders","We propose a general emulation method for constructing low-dimensional approximations of complex dynamic climate models. Our method uses artificially designed uncorrelated CO2 emissions scenarios, which are much better suited for the construction of an emulator than are conventional emissions scenarios. We apply our method to the climate model MAGICC to approximate the impact of emissions on global temperature. Comparing the temperature forecasts of MAGICC and our emulator, we show that the average relative out-of-sample forecast errors in the low-dimensional emulation models are below 2%. Our emulator offers an avenue to merge modern macroeconomic models with complex dynamic climate models.",http://www.sciencedirect.com/science/article/pii/S0304407619301083
Journal of Econometrics,2020,Autoregressive wild bootstrap inference for nonparametric trends,"Marina Friedrich, Stephan Smeekes and Jean-Pierre Urbain","In this paper we propose an autoregressive wild bootstrap method to construct confidence bands around a smooth deterministic trend. The bootstrap method is easy to implement and does not require any adjustments in the presence of missing data, which makes it particularly suitable for climatological applications. We establish the asymptotic validity of the bootstrap method for both pointwise and simultaneous confidence bands under general conditions, allowing for general patterns of missing data, serial dependence and heteroskedasticity. The finite sample properties of the method are studied in a simulation study. We use the method to study the evolution of trends in daily measurements of atmospheric ethane obtained from a weather station in the Swiss Alps, where the method can easily deal with the many missing observations due to adverse weather conditions.",http://www.sciencedirect.com/science/article/pii/S0304407619301095
Journal of Econometrics,2020,Expected utility and catastrophic risk in a stochastic economy–climate model,"Masako Ikefuji, Roger Laeven, Jan Magnus and Chris Muris","We analyze a stochastic dynamic finite-horizon economic model with climate change, in which the social planner faces uncertainty about future climate change and its economic damages. Our model (SDICE*) incorporates, possibly heavy-tailed, stochasticity in Nordhaus’ deterministic DICE model. We develop a regression-based numerical method for solving a general class of dynamic finite-horizon economy–climate models with potentially heavy-tailed uncertainty and general utility functions. We then apply this method to SDICE* and examine the effects of light- and heavy-tailed uncertainty. The results indicate that the effects can be substantial, depending on the nature and extent of the uncertainty and the social planner’s preferences.",http://www.sciencedirect.com/science/article/pii/S0304407619301101
Journal of Econometrics,2020,Inference related to common breaks in a multivariate system with joined segmented trends with applications to global and hemispheric temperatures,"Dukpa Kim, Tatsushi Oka, Francisco Estrada and Pierre Perron","What transpires from recent research is that temperatures and radiative forcing seem to be characterized by a linear trend with two changes in the rate of growth. The first occurs in the early 60s and indicates a very large increase in the rate of growth of both temperature and radiative forcing series. This was termed as the “onset of sustained global warming”. The second is related to the more recent so-called hiatus period, which suggests that temperatures and total radiative forcing have increased less rapidly since the mid-90s compared to the larger rate of increase from 1960 to 1990. There are two issues that remain unresolved. The first is whether the breaks in the slope of the trend functions of temperatures and radiative forcing are common. This is important because common breaks coupled with the basic science of climate change would strongly suggest a causal effect from anthropogenic factors to temperatures. The second issue relates to establishing formally via a proper testing procedure that takes into account the noise in the series, whether there was indeed a ‘hiatus period’ for temperatures since the mid 90s. This is important because such a test would counter the widely held view that the hiatus is the product of natural internal variability. Our paper provides tests related to both issues. The results show that the breaks in temperatures and radiative forcing are common and that the hiatus is characterized by a significant decrease in their rate of growth. The statistical results are of independent interest and applicable more generally.",http://www.sciencedirect.com/science/article/pii/S0304407619301113
Journal of Econometrics,2020,Trends in distributional characteristics: Existence of global warming,María Dolores Gadea Rivas and Jesus Gonzalo,"What type of global warming exists? This study introduces a novel methodology to answer this question, which is the starting point for all issues related to climate change analyses. Global warming is defined as an increasing trend in certain distributional characteristics (moments, quantiles, etc.) of global temperatures, in addition to simply examining the average values. Temperatures are viewed as a functional stochastic process from which we obtain distributional characteristics as time series objects. Here, we present a simple robust trend test and prove that it is able to detect the existence of an unknown trend component (deterministic or stochastic) in these characteristics. Applying this trend test to daily temperatures in Central England (for the period 1772–2017) and to global cross-sectional temperatures (1880–2015), we obtain the same strong conclusions: (i) there is an increasing trend in all distributional characteristics (time series and cross-sectional), and this trend is larger in the lower quantiles than it is in the mean, median, and upper quantiles; (ii) there is a negative trend in the characteristics that measure dispersion (i.e., lower temperatures approach the median faster than higher temperatures do). This type of global warming has more serious consequences than those found by analyzing only the average.",http://www.sciencedirect.com/science/article/pii/S0304407619301125
Journal of Econometrics,2020,A multicointegration model of global climate change,"Stephan B. Bruns, Zsuzsanna Csereklyei and David Stern","We model the role of the ocean in climate change, using the concept of multicointegration. Surface temperature and radiative forcing cointegrate and the accumulated cointegration disequilibria represent the change in Earth system heat content, which is predominantly stored in the ocean. System heat content in turn cointegrates with surface temperature. Using a multicointegrating I(2) model, we find that the climate sensitivity is 2.8 °C and the rate of adjustment to equilibrium is realistically slow. These results contrast strongly with those from I(1) cointegration models and are more consistent with global circulation models. We also estimate Earth system heat content as a latent variable for the full period, 1850–2014, and this predicted heat content cointegrates with available ocean heat content observations for 1940–2014.",http://www.sciencedirect.com/science/article/pii/S0304407619301137
Journal of Econometrics,2020,Global hemispheric temperatures and co-shifting: A vector shifting-mean autoregressive analysis,Matthew Holt and Timo Teräsvirta,"This paper examines local changes in annual temperature data for the northern and southern hemispheres (1850–2017) by using a multivariate generalization of the shifting-meanautoregressive model of González and Teräsvirta (2008). Univariate models are first fitted to each series by using the QuickShift methodology. Full information maximum likelihood estimates of a bivariate system of temperature equations are then obtained and asymptotic properties of the corresponding estimators considered. The system is then used to perform formal tests of co-movements, called co-shifting, in the series. The results show evidence of co-shifting in the two series.",http://www.sciencedirect.com/science/article/pii/S0304407619301149
Journal of Econometrics,2020,Fully modified OLS estimation and inference for seemingly unrelated cointegrating polynomial regressions and the environmental Kuznets curve for carbon dioxide emissions,"Martin Wagner, Peter Grabarczyk and Seung Hyun Hong","This paper develops two fully modified OLS (FM-OLS) estimators for systems of seemingly unrelated cointegrating polynomial regressions, i.e., systems of regressions that include deterministic variables, integrated processes, and integer powers of integrated processes as explanatory variables. The stationary errors are allowed to be serially correlated and the regressors to be endogenous. Furthermore, the errors and regressors are allowed to be dynamically cross-sectionally correlated. The developed estimators have zero mean Gaussian mixture limiting distributions that allow for asymptotic chi-squared inference. The Wald-type hypothesis test results are the basis for considering detailed tests for general forms of group-wise poolability. We provide the corresponding group-wise pooled variants of our estimators, in case the poolability restrictions are not rejected. Our simulations indicate that appropriate pooling leads, as expected, to improved performance of the estimators and tests. Data-driven group-wise pooling turns out to be crucial in our illustrative application that analyzes the environmental Kuznets curve for CO2 emissions for six early industrialized countries.",http://www.sciencedirect.com/science/article/pii/S0304407619301150
Journal of Econometrics,2020,Econometric modelling of climate systems: The equivalence of energy balance models and cointegrated vector autoregressions,Felix Pretis,"Estimates of both the human impact on climate as well as the economic impacts of climate change are crucial to inform policy decisions. Econometric modelling allows us to quantify these impacts and their uncertainties, but models have to be consistent with the underlying physics and the time series properties of the data. Here I show that energy-balance models of climate are equivalent to an econometric cointegrated system and can be estimated in discrete time. This equivalence provides a basis for the use of cointegration methods to estimate climate responses and test their feedback. Further, it is possible to use the estimated parameters to quantify uncertainties in integrated assessment models of the economic impacts of climate change. In an application I estimate a system of temperatures, ocean heat content, and radiative forcing including greenhouse gases, and find statistical support for the cointegrated energy balance model. Accounting for structural breaks from volcanic eruptions highlights large parameter uncertainties and shows that previous empirical estimates of the temperature response to increased CO2 concentrations may be misleadingly low due to model-misspecification.",http://www.sciencedirect.com/science/article/pii/S0304407619301162
Journal of Econometrics,2020,Evaluating trends in time series of distributions: A spatial fingerprint of human effects on climate,"Yoosoon Chang, Robert Kaufmann, Chang Sik Kim, J. Miller, Joon Y. Park and Sungkeun Park","We analyze a time series of global temperature anomaly distributions to identify and estimate persistent features in climate change. We employ a formal test for the existence of functional unit roots in the time series of these densities, and we develop a new test to distinguish functional unit roots from functional deterministic trends or explosive behavior. Results suggest that temperature anomalies contain stochastic trends (as opposed to deterministic trends or explosive roots), two trends are present in the Northern Hemisphere while one stochastic trend is present in the Southern Hemisphere, and the probabilities of observing moderately positive anomalies have increased. We postulate that differences in the pattern and number of unit roots in each hemisphere may be due to a natural experiment which causes human emissions of greenhouse gases and sulfur to be greater in the Northern Hemisphere, decreasing the mean temperature anomaly but increasing the spatial variance relative to the Southern Hemisphere. Together, these results are consistent with the theory of anthropogenic climate change.",http://www.sciencedirect.com/science/article/pii/S0304407619301216
