journal,year,title,authors,abstract,url
Journal of Econometrics,2021,Estimation of dynamic panel spatial vector autoregression: Stability and spatial multivariate cointegration,Kai Yang and Lung-fei Lee,"This paper introduces dynamic panel spatial vector autoregressive models. We study features of dynamics and spatial interactions that an SVAR model can generate and classify the model into stable or unstable cases by partitioning parameter spaces. For stable, spatial cointegration, and mixed cointegration cases, we investigate identification and QML estimation of the models to take into account simultaneity and correlated relationships. Asymptotic properties and bias-corrected estimators are presented. To detect unknown cointegration relationships, we introduce a sequential likelihood ratio testing procedure. Simulations show the advantage of QMLEs on bias reduction and efficiency gains. The empirical application provides evidences on ancient China’s market integration.",http://www.sciencedirect.com/science/article/pii/S030440762030227X
Journal of Econometrics,2021,Robust and optimal estimation for partially linear instrumental variables models with partial identification,Qihui Chen,"This paper studies robust and optimal estimation of the slope coefficients in a partially linear instrumental variables model with nonparametric partial identification. We establish the root-n asymptotic normality of a penalized sieve minimum distance estimator of the slope coefficients. We show that the asymptotic normality holds regardless of whether the nonparametric function is point identified or only partially identified. However, in the presence of nonparametric partial identification, the slope coefficients may not be continuous in the underlying distribution and the asymptotic variance matrix may depend on the penalty, so classical efficiency analysis does not apply. We instead develop an optimally penalized estimator that minimizes the asymptotic variance of a linear functional of the slope coefficients estimator by employing an optimal penalty for a given weight, and propose a feasible two-step procedure. We also propose an iterated procedure to address how to choose both penalty and weight optimally and further improve efficiency. To conduct inference, we provide a consistent variance matrix estimator. Monte Carlo simulations examine the finite sample performance of our estimators.",http://www.sciencedirect.com/science/article/pii/S0304407620302293
Journal of Econometrics,2021,Varying random coefficient models,Christoph Breunig,"This paper analyzes unobserved heterogeneity when observed characteristics are modeled nonlinearly. The proposed model builds on varying random coefficients (VRC) that are determined by nonlinear functions of observed regressors and additively separable unobservables. This paper proposes a novel estimator of the VRC density based on weighted sieve minimum distance. The main example of sieve bases are Hermite functions which yield a numerically stable estimation procedure. This paper shows inference results that go beyond what has been shown in ordinary RC models. We provide in each case rates of convergence and also establish pointwise limit theory of linear functionals, where a prominent example is the density of potential outcomes. In addition, a multiplier bootstrap procedure is proposed to construct uniform confidence bands. A Monte Carlo study examines finite sample properties of the estimator and shows that it performs well even when the regressors associated to RC are far from being heavy tailed. Finally, the methodology is applied to analyze heterogeneity in income elasticity of demand for housing.",http://www.sciencedirect.com/science/article/pii/S030440762030244X
Journal of Econometrics,2021,Testing high-dimensional covariance matrices under the elliptical distribution and beyond,"Xinxin Yang, Xinghua Zheng and Jiaqi Chen","We develop tests for high-dimensional covariance matrices under a generalized elliptical model. Our tests are based on a central limit theorem for linear spectral statistics of the sample covariance matrix based on self-normalized observations. For testing sphericity, our tests neither assume specific parametric distributions nor involve the kurtosis of data. More generally, we can test against any non-negative definite matrix that can even be not invertible. As an interesting application, we illustrate in empirical studies that our tests can be used to test uncorrelatedness among idiosyncratic returns.",http://www.sciencedirect.com/science/article/pii/S0304407620302384
Journal of Econometrics,2021,Spatial dynamic panel data models with correlated random effects,Liyao Li and Zhenlin Yang,"In this paper, M-estimation and inference methods are developed for spatial dynamic panel data models with correlated random effects, based on short panels. The unobserved individual-specific effects are assumed to be correlated with the observed time-varying regressors linearly or in a linearizable way, giving the so-called correlated random effects model, which allows the estimation of effects of time-invariant regressors. The unbiased estimating functions are obtained by adjusting the conditional quasi-scores given the initial observations, leading to M-estimators that are consistent, asymptotically normal, and free from the initial conditions except the process starting time. By decomposing the estimating functions into sums of terms uncorrelated given idiosyncratic errors, a hybrid method is developed for consistently estimating the variance–covariance matrix of the M-estimators, which again depends only on the process starting time. Monte Carlo results demonstrate that the proposed methods perform well in finite sample. An empirical application on the political competition in China is presented.",http://www.sciencedirect.com/science/article/pii/S0304407620302372
Journal of Econometrics,2021,Large-dimensional Dynamic Factor Models: Estimation of Impulse–Response Functions with I(1) cointegrated factors,"Matteo Barigozzi, Marco Lippi and Matteo Luciani","We study a large-dimensional Dynamic Factor Model where: (i) the vector of factors Ft is I(1) and driven by a number of shocks that is smaller than the dimension of Ft; and, (ii) the idiosyncratic components are either I(1) or I(0). Under (i), the factors Ft are cointegrated and can be modeled as a Vector Error Correction Model (VECM). Under (i) and (ii), we provide consistent estimators, as both the cross-sectional size n and the time dimension T go to infinity, for the factors, the loadings, the shocks, the coefficients of the VECM and therefore the Impulse–Response Functions (IRF) of the observed variables to the shocks. Furthermore, possible deterministic linear trends are fully accounted for, and the case of an unrestricted VAR in the levels Ft, instead of a VECM, is also studied. The finite-sample properties the proposed estimators are explored by means of a MonteCarlo exercise. Finally, we revisit two distinct and widely studied empirical applications. By correctly modeling the long-run dynamics of the factors, our results partly overturn those obtained by recent literature. Specifically, we find that: (i) oil price shocks have just a temporary effect on US real activity; and, (ii) in response to a positive news shock, the economy first experiences a significant boom, and then a milder recession.",http://www.sciencedirect.com/science/article/pii/S0304407620302219
Journal of Econometrics,2021,Revisiting the location of FDI in China: A panel data approach with heterogeneous shocks,"Lei Hou, Kunpeng Li, Qi Li and Min Ouyang","Foreign Direct Investment (FDI) is viewed as a primary driving force in shaping the global economy and receives particular attention in empirical studies. In this paper, we argue that many of the existing studies ignore endogeneities that arise from shocks in source and destination countries. To address this endogeneity issue, we take the “controlling through estimating” idea from the econometric literature and propose using panel data models with heterogeneous shocks to deal with it. We consider the quasi maximum likelihood (QML) method to estimate our proposed model. We investigate the asymptotic properties of the QML estimator, including the consistency, the asymptotic representation, and the limiting distribution. We also propose new statistics to test the validity of the use of traditional dynamic and static panel data estimation methods. Applying it to the location determinants of inward FDI in China, we find that the endogeneity issue does exist, and that controlling for heterogeneous shocks helps to improve the estimation results.",http://www.sciencedirect.com/science/article/pii/S0304407620302426
Journal of Econometrics,2021,Detection of units with pervasive effects in large panel data models,"George Kapetanios, Mohammad Pesaran and S. Reese","The importance of units that influence a large number of other units in a network has become increasingly recognized in the literature. In this paper we propose a new method to detect such pervasive units by basing our analysis on unit-specific residual error variances subject to suitable adjustments due to the multiple testing issues involved. Accordingly, a sequential multiple testing (SMT) procedure is proposed, which allows identification of pervasive units (if any) without a priori knowledge of the interconnections amongst cross-section units or availability of a short list of candidate units to search over. The proposed method is applicable even if the cross-section dimension exceeds the time series dimension, and most importantly it could end up with none of the units selected as pervasive when this is in fact the case. The SMT procedure exhibits satisfactory small-sample performance in Monte Carlo simulations and compares well relative to existing approaches. We apply the SMT detection method to sectoral indices of U.S. industrial production, U.S. house price changes by states, and the rates of change of real GDP and real equity prices across the world’s largest economies.",http://www.sciencedirect.com/science/article/pii/S0304407620302141
Journal of Econometrics,2021,Missing observations in observation-driven time series models,"Francisco Blasques, P. Gorgi and Siem Jan Koopman","We argue that existing methods for the treatment of missing observations in time-varying parameter observation-driven models lead to inconsistent inference. We provide a formal proof of this inconsistency for a Gaussian model with time-varying mean. A Monte Carlo simulation study supports this theoretical result and illustrates how the inconsistency problem extends to score-driven and, more generally, to observation-driven models, which include well-known models for conditional volatility. To overcome the problem of inconsistent inference, we propose a novel estimation procedure based on indirect inference. This easy-to-implement method delivers consistent inference. The asymptotic properties of the new method are formally derived. Our proposed estimation procedure shows a promising performance in a Monte Carlo simulation exercise as well as in an empirical study concerning the measurement of conditional volatility from financial returns data.",http://www.sciencedirect.com/science/article/pii/S0304407620302670
Journal of Econometrics,2021,The factor analytical approach in near unit root interactive effects panels,Milda Norkutė and Joakim Westerlund,"In a recent study, Bai (2013) proposes a new factor analytical (FA) method for estimation of stationary dynamic panel data models with fixed effects. Our interest in this method originates with the fact it does not require explicit demeaning of the data, a practice that is known to cause problems of bias and low power in near unit root panels. The purpose is to study the properties of FA when applied to such panels when the common component admits to a interactive effects representation, which is more general than fixed effects. It is shown that the estimator of the autoregressive parameter is consistent with a well centered asymptotic normal distribution, leading to unit root tests with maximal achievable power. In fact, FA is consistent and asymptotically normal regardless of whether the data are near unit root non-stationary or stationary. It is therefore very general and hence widely applicable.",http://www.sciencedirect.com/science/article/pii/S0304407620302682
Journal of Econometrics,2021,Estimation and inference in spatial models with dominant units,Mohammad Pesaran and Cynthia Fan Yang,"In spatial econometrics literature estimation and inference are carried out assuming that the matrix of spatial or network connections has uniformly bounded absolute column sums in the number of units, n, in the network. This paper relaxes this restriction and allows for one or more units to have pervasive effects in the network. The linear–quadratic central limit theorem of Kelejian and Prucha (2001) is generalized to allow for such dominant units, and the asymptotic properties of the GMM estimators are established in this more general setting. A new bias-corrected method of moments (BMM) estimator is also proposed that avoids the problem of weak instruments by self-instrumenting the spatially lagged dependent variable. Both cases of homoskedastic and heteroskedastic errors are considered and the associated estimators are shown to be consistent and asymptotically normal, depending on the rate at which the maximum column sum of the weights matrix rises with n. The small sample properties of GMM and BMM estimators are investigated by Monte Carlo experiments and shown to be satisfactory. An empirical application to sectoral price changes in the US over the pre- and post-2008 financial crisis is also provided. It is shown that the share of capital can be estimated reasonably well from the degree of sectoral interdependence using the input–output tables, despite the evidence of dominant sectors being present in the US economy.",http://www.sciencedirect.com/science/article/pii/S0304407620302360
Journal of Econometrics,2021,Diffusion copulas: Identification and estimation,"Ruijun Bu, Kaddour Hadri and Dennis Kristensen","We propose a new semiparametric approach for modelling nonlinear univariate diffusions, where the observed process is a nonparametric transformation of an underlying parametric diffusion (UPD). This modelling strategy yields a general class of semiparametric Markov diffusion models with parametric dynamic copulas and nonparametric marginal distributions. We provide primitive conditions for the identification of the UPD parameters together with the unknown transformations from discrete samples. Likelihood-based estimators of both parametric and nonparametric components are developed and we analyse their asymptotic properties. Kernel-based drift and diffusion estimators are also proposed and shown to be normally distributed in large samples. A simulation study investigates the finite sample performance of our estimators in the context of modelling US short-term interest rates. We also present a simple application of the proposed method for modelling the CBOE volatility index data.",http://www.sciencedirect.com/science/article/pii/S0304407620302104
Journal of Econometrics,2021,Overlap in observational studies with high-dimensional covariates,"D’Amour, Alexander, Peng Ding, Avi Feller, Lihua Lei and Jasjeet Sekhon","Estimating causal effects under exogeneity hinges on two key assumptions: unconfoundedness and overlap. Researchers often argue that unconfoundedness is more plausible when more covariates are included in the analysis. Less discussed is the fact that covariate overlap is more difficult to satisfy in this setting. In this paper, we explore the implications of overlap in observational studies with high-dimensional covariates and formalize curse-of-dimensionality argument, suggesting that these assumptions are stronger than investigators likely realize. Our key innovation is to explore how strict overlap restricts global discrepancies between the covariate distributions in the treated and control populations. Exploiting results from information theory, we derive explicit bounds on the average imbalance in covariate means under strict overlap and show that these bounds become more restrictive as the dimension grows large. We discuss how these implications interact with assumptions and procedures commonly deployed in observational causal inference, including sparsity and trimming.",http://www.sciencedirect.com/science/article/pii/S0304407620302694
Journal of Econometrics,2021,The continuous-time limit of score-driven volatility models,"Giuseppe Buccheri, Fulvio Corsi, Franco Flandoli and Giulia Livieri","We provide general conditions under which a class of discrete-time volatility models driven by the score of the conditional density converges in distribution to a stochastic differential equation as the interval between observations goes to zero. We show that the form of the diffusion limit depends on: (i) the link function, (ii) the conditional second moment of the score, (iii) the normalization of the score. Interestingly, the properties of the stochastic differential equation are strictly entangled with those of the discrete-time counterpart. Score-driven models with fat-tailed densities lead to continuous-time processes with finite volatility of volatility, as opposed to fat-tailed models with a GARCH update, for which the volatility of volatility is explosive. We examine in simulations the implications of such results on approximate estimation and filtering of diffusion processes. An extension to models with a time-varying conditional mean and to conditional covariance models is also developed.",http://www.sciencedirect.com/science/article/pii/S0304407620302669
Journal of Econometrics,2021,Bootstrap based probability forecasting in multiplicative error models,Indeewara Perera and Mervyn J. Silvapulle,"As evidenced by an extensive empirical literature, multiplicative error models (MEM) show good performance in capturing the stylized facts of nonnegative time series; examples include, trading volume, financial durations, and volatility. This paper develops a bootstrap based method for producing multi-step-ahead probability forecasts for a nonnegative valued time-series obeying a parametric MEM. In order to test the adequacy of the underlying parametric model, a class of bootstrap specification tests is also developed. Rigorous proofs are provided for establishing the validity of the proposed bootstrap methods. The paper also establishes the validity of a bootstrap based method for producing probability forecasts in a class of semiparametric MEMs. Monte Carlo simulations suggest that our methods perform well in finite samples. A real data example illustrates the methods.",http://www.sciencedirect.com/science/article/pii/S0304407620300440
Journal of Econometrics,2021,Computing semiparametric efficiency bounds in discrete choice models with strategic-interactions and rational expectations,Andres Aradillas-Lopez,"This paper computes semiparametric efficiency bounds for finite-dimensional parameters in discrete choice models with nonparametric regressors in the form of conditional expectations. These can include expectations about exogenous events as well as expectations about the choices of other agents. Thus, the models studied here include incomplete-information games, social-interactions models as well as single-agent discrete choice models with uncertainty as special cases. Our bounds rely on the assumption of rational expectations and on regularity conditions of equilibrium beliefs. The paper focuses on binary-choice models but the derivation of the bounds illustrates how our approach can be extended to multinomial choice cases. Explicit efficiency bound expressions for the models examined here had not been derived before. Furthermore, since we also characterize the efficient influence functions, our results can also potentially be used to construct semiparametrically efficient estimators for these models.",http://www.sciencedirect.com/science/article/pii/S0304407620300452
Journal of Econometrics,2021,A general semiparametric approach to inference with marker-dependent hazard rate models,"Gerard. J. van den Berg, Lena Janys, Enno Mammen and Jens Perch Nielsen","We examine a new general class of hazard rate models for duration data, containing a parametric and a nonparametric component. Both can be a mix of a time effect and possibly time-dependent covariate effects. A number of well-known models are special cases. In a counting process framework, a general profile likelihood estimator is developed and the parametric component of the model is shown to be asymptotically normal and efficient. Finite sample properties are investigated in simulations. The estimator is applied to investigate the long-run relationship between birth weight and later-life mortality.",http://www.sciencedirect.com/science/article/pii/S0304407620300439
Journal of Econometrics,2021,Jackknife empirical likelihood for inequality constraints on regular functionals,Ruxin Chen and Rami V. Tabri,"Empirical likelihood is effective in many different practical situations involving moment equality and/or inequality restrictions. However, in applications with nonlinear functionals of the underlying distribution, it becomes computationally more difficult to implement. We propose the use of jackknife empirical likelihood (Jing et al., 2009) to circumvent the computational difficulties with nonlinear inequality constraints and establish the chi-bar-square distribution as the limiting null distribution of the resulting empirical likelihood-ratio statistic, where a finite number of inequalities on functionals that are regular in the sense of Hoeffding (1948), defines the null hypothesis. The class of regular functionals includes many nonlinear functionals that arise in practice and has moments as a special case. To overcome the implementation challenges with this non-pivotal asymptotic null distribution, we propose an empirical likelihood bootstrap procedure that is valid with uniformity. Finally, we investigate the finite-sample properties of the bootstrap procedure using Monte Carlo simulations and find that the results are promising.",http://www.sciencedirect.com/science/article/pii/S0304407620300373
Journal of Econometrics,2021,Efficient size correct subset inference in homoskedastic linear instrumental variables regression,Frank Kleibergen,We show that Moreira’s (2003) conditional critical value function for likelihood ratio (LR) tests on the structural parameter in homoskedastic linear instrumental variables (IV) regression provides a bounding critical value function for subset LR tests on one structural parameter of several for general homoskedastic linear IV regression. The resulting subset LR test is size correct under weak identification and efficient under strong identification. A power study shows that it outperforms the subset Anderson–Rubin test with conditional critical values from Guggenberger et al. (2019a) when the structural parameters are reasonably identified and has slightly less power when identification is weak.,http://www.sciencedirect.com/science/article/pii/S030440762030052X
Journal of Econometrics,2021,"ExpectHill estimation, extreme risk and heavy tails","Abdelaati Daouia, Stéphane Girard and Gilles Stupfler","Risk measures of a financial position are, from an empirical point of view, mainly based on quantiles. Replacing quantiles with their least squares analogues, called expectiles, has recently received increasing attention. The novel expectile-based risk measures satisfy all coherence requirements. We revisit their extreme value estimation for heavy-tailed distributions. First, we estimate the underlying tail index via weighted combinations of top order statistics and asymmetric least squares estimates. The resulting expectHill estimators are then used as the basis for estimating tail expectiles and Expected Shortfall. The asymptotic theory of the proposed estimators is provided, along with numerical simulations and applications to actuarial and financial data.",http://www.sciencedirect.com/science/article/pii/S0304407620300543
Journal of Econometrics,2021,Hierarchical Markov-switching models for multivariate integer-valued time-series,Leopoldo Catania and Roberto Di Mari,"We propose a new flexible dynamic model for multivariate nonnegative integer-valued time-series. Observations are assumed to depend on the realization of two unobserved integer-valued stochastic variables which control for the time- and cross-dependence of the data. We provide conditional and unconditional (cross)-moments implied by the model, as well as the limiting distribution of the series. An Expectation–Maximization algorithm for maximum likelihood estimation of the model parameters is derived, and an extensive Monte Carlo experiment investigates the finite sample properties of the resulting maximum likelihood estimator. Constrained specifications of the model are also formulated by modifying the assumptions about the dependence structure of the latent variables, and model identification is discussed accordingly. An application by means of a crime data set from the New South Wales (NSW) Bureau Of Crime Statistics And Research with observations spanning beyond 20 years is reported to illustrate the methodology. Results indicate that the proposed approach provides a good description of the conditional distribution of crime records, outperforming the standard hidden Markov model.",http://www.sciencedirect.com/science/article/pii/S0304407620300531
Journal of Econometrics,2021,Testing continuity of a density via g-order statistics in the regression discontinuity design,Federico Bugni and Ivan Canay,"In the regression discontinuity design (RDD), it is common practice to assess the credibility of the design by testing the continuity of the density of the running variable at the cut-off, e.g., McCrary (2008). In this paper we propose an approximate sign test for continuity of a density at a point based on the so-called g-order statistics, and study its properties under two complementary asymptotic frameworks. In the first asymptotic framework, the number q of observations local to the cut-off is fixed as the sample size n diverges to infinity, while in the second framework q diverges to infinity slowly as n diverges to infinity. Under both of these frameworks, we show that the test we propose is asymptotically valid in the sense that it has limiting rejection probability under the null hypothesis not exceeding the nominal level. More importantly, the test is easy to implement, asymptotically valid under weaker conditions than those used by competing methods, and exhibits finite sample validity under stronger conditions than those needed for its asymptotic validity. In a simulation study, we find that the approximate sign test provides good control of the rejection probability under the null hypothesis while remaining competitive under the alternative hypothesis. We finally apply our test to the design in Lee (2008), a well-known application of the RDD to study incumbency advantage.",http://www.sciencedirect.com/science/article/pii/S0304407620300579
Journal of Econometrics,2021,Likelihood inference and the role of initial conditions for the dynamic panel data model,José Diogo Barbosa and Marcelo Moreira,"Lancaster (2002) proposes an estimator for the dynamic panel data model with homoskedastic errors and zero initial conditions. In this paper, we show this estimator is invariant to orthogonal transformations, but is inefficient because it ignores additional information available in the data. The zero initial condition is trivially satisfied by subtracting initial observations from the data. We show that differencing out the data further erodes efficiency compared to drawing inference conditional on the first observations.",http://www.sciencedirect.com/science/article/pii/S0304407620301652
Journal of Econometrics,2021,Estimation of a SAR model with endogenous spatial weights constructed by bilateral variables,"Xi Qu, Lung-fei Lee and Chao Yang","This paper studies the estimation of a cross-sectional spatial autoregressive (SAR) model with spatial weights constructed by bilateral variables like the trade or investment between regions. We model the possible endogeneity in spatial weights due to the correlation between the error term in the SAR model and unobserved interactive fixed effects in bilateral variables. Using a control function approach, we propose two-stage estimation methods and establish their consistency and asymptotic normality. Finite sample properties are investigated by a Monte Carlo study. We further apply our method to an empirical study of interactions among different US industries through production networks.",http://www.sciencedirect.com/science/article/pii/S0304407620302281
Journal of Econometrics,2021,Nonstationary panel models with latent group structures and cross-section dependence,"Wenxin Huang, Sainan Jin, Peter Phillips and Liangjun Su","This paper proposes a novel Lasso-based approach to handle unobserved parameter heterogeneity and cross-section dependence in nonstationary panel models. In particular, a penalized principal component (PPC) method is developed to estimate group-specific long-run relationships and unobserved common factors and jointly to identify the unknown group membership. The PPC estimators are shown to be consistent under weakly dependent innovation processes. But they suffer an asymptotically non-negligible bias from correlations between the nonstationary regressors and unobserved stationary common factors and/or the equation errors. To remedy these shortcomings we provide three bias-correction procedures under which the estimators are re-centered about zero as both dimensions (N and T) of the panel tend to infinity. We establish a mixed normal limit theory for the estimators of the group-specific long-run coefficients, which permits inference using standard test statistics. Simulations suggest good finite sample performance. An empirical application applies the methodology to study international R&D spillovers and the results offer a convincing explanation for the growth convergence puzzle through the heterogeneous impact of R&D spillovers.",http://www.sciencedirect.com/science/article/pii/S0304407620302165
Journal of Econometrics,2021,Optimal Linear Instrumental Variables Approximations,Juan Carlos Escanciano and Wei Li,"This paper studies the identification and estimation of the optimal linear approximation of a structural regression function. The parameter in the linear approximation is called the Optimal Linear Instrumental Variables Approximation (OLIVA). This paper shows that a necessary condition for standard inference on the OLIVA is also sufficient for the existence of an IV estimand in a linear model. The instrument in the IV estimand is unknown and may not be identified. A Two-Step IV (TSIV) estimator based on Tikhonov regularization is proposed, which can be implemented by standard regression routines. We establish the asymptotic normality of the TSIV estimator assuming neither completeness nor identification of the instrument. As an important application of our analysis, we robustify the classical Hausman test for exogeneity against misspecification of the linear structural model. We also discuss extensions to weighted least squares criteria. Monte Carlo simulations suggest an excellent finite sample performance for the proposed inferences. Finally, in an empirical application estimating the elasticity of intertemporal substitution (EIS) with US data, we obtain TSIV estimates that are much larger than their standard IV counterparts, with our robust Hausman test failing to reject the null hypothesis of exogeneity of real interest rates.",http://www.sciencedirect.com/science/article/pii/S0304407620302153
Journal of Econometrics,2021,An automated approach towards sparse single-equation cointegration modelling,Stephan Smeekes and Etienne Wijler,"In this paper we propose the Single-equation Penalized Error Correction Selector (SPECS) as an automated estimation procedure for dynamic single-equation models with a large number of potentially (co)integrated variables. By extending the classical single-equation error correction model, SPECS enables the researcher to model large cointegrated datasets without necessitating any form of pre-testing for the order of integration or cointegrating rank. Under an asymptotic regime in which both the number of parameters and time series observations jointly diverge to infinity, we show that SPECS is able to consistently estimate an appropriate linear combination of the cointegrating vectors that may occur in the underlying DGP. In addition, SPECS is shown to enable the correct recovery of sparsity patterns in the parameter space and to possess the same limiting distribution as the OLS oracle procedure. A simulation study shows strong selective capabilities, as well as superior predictive performance in the context of nowcasting compared to high-dimensional models that ignore cointegration. An empirical application to nowcasting Dutch unemployment rates using Google Trends confirms the strong practical performance of our procedure.",http://www.sciencedirect.com/science/article/pii/S0304407620302190
Journal of Econometrics,2021,Estimating multiple breaks in nonstationary autoregressive models,"Tianxiao Pang, Lingjie Du and Terence Tai Leung Chong","Chong (1995) and Bai (1997) proposed a sample-splitting method to estimate a multiple-break model. However, their studies focused on stationary time series models, in which the identification of the first break depends on the magnitude and the duration of the break, and a testing procedure is needed to assist the estimation of the remaining breaks in subsamples split by the break points found earlier. In this paper, we focus on nonstationary multiple-break autoregressive models. Unlike the stationary case, we show that the duration of a break does not affect whether it will be identified first. Rather, it depends on the stochastic order of magnitude of signal strength of the break under the case of constant break magnitude and also the square of the magnitude of the break under the case of shrinking break magnitude. Since the subsamples usually have different stochastic orders in nonstationary autoregressive models with breaks, one can therefore determine which break will be identified first. We apply this finding to the models proposed in Phillips and Yu (2011) and Phillips et al. (2011, 2015a, 2015b). We propose an estimation procedure as well as the asymptotic theory for the model. Some extensions to more general models are provided, and the hypothesis test with the null hypothesis being the unit root model is examined. Results of numerical simulations and an empirical study are given to illustrate the finite-sample performance.",http://www.sciencedirect.com/science/article/pii/S0304407620302116
Journal of Econometrics,2021,Frequentist properties of Bayesian inequality tests,David Kaplan and Longhao Zhuo,"Bayesian and frequentist criteria fundamentally differ, but often posterior and sampling distributions agree asymptotically. For the corresponding single-draw experiment, we characterize the frequentist size of a certain Bayesian hypothesis test of (possibly nonlinear) inequalities. If the null hypothesis is that the parameter lies in a specified half-space, then the Bayesian test’s size equals α; if the null hypothesis is a subset of a half-space, then size is above α; otherwise, size may be equal to, above, or below α. Rejection probabilities at certain points are also characterized. Two examples illustrate our results: translog cost function curvature and ordinal distribution relationships.",http://www.sciencedirect.com/science/article/pii/S0304407620302359
Journal of Econometrics,2021,Second-order corrected likelihood for nonlinear panel models with fixed effects,Geert Dhaene and Yutao Sun,"We propose a second-order correction for nonlinear fixed-effect panel models. The correction is made via the log-likelihood function. It removes the two leading terms of the bias of the log-likelihood that arises from estimating the fixed effects. Maximizing the corrected likelihood gives a second-order bias-corrected estimator, with bias OT−3, where T is the number of time periods. The corrected likelihood also gives second-order corrected test statistics. The correction applies to general nonlinear fixed-effect models with independent observations. The bias correction properties are confirmed in simulations for binary-choice models.",http://www.sciencedirect.com/science/article/pii/S0304407620301196
Journal of Econometrics,2021,Semiparametric identification in panel data discrete response models,Eleni Aristodemou,"This paper studies semiparametric identification in linear index discrete response panel data models with fixed effects. Departing from the classic binary response static panel data model, this paper examines identification in the binary response dynamic panel data model and the ordered response static panel data model. It is shown that under mild distributional assumptions on the fixed effect and the time-varying unobservables point-identification fails, but informative bounds on the regression coefficients can still be derived. Partial identification is achieved by eliminating the fixed effect and discovering features of the distribution of the unobservable time-varying components that do not depend on the unobserved heterogeneity. Numerical analyses illustrate how the identification bounds change as the support of the explanatory variables varies.",http://www.sciencedirect.com/science/article/pii/S0304407620301202
Journal of Econometrics,2021,Identifying latent group structures in nonlinear panels,Wuyi Wang and Liangjun Su,"We propose a procedure to identify latent group structures in nonlinear panel data models where some regression coefficients are heterogeneous across groups but homogeneous within a group and the group number and membership are unknown. To identify the group structures, we consider the order statistics for the preliminary unconstrained consistent estimators of the regression coefficients and translate the problem of classification into the problem of break detection. Then we extend the sequential binary segmentation algorithm of Bai (1997) for break detection from the time series setup to the panel data framework. We demonstrate that our method is able to identify the true latent group structures with probability approaching one and the post-classification estimators are oracle-efficient. The method has the advantage of more convenient implementation compared with some alternative methods, which is a desirable feature in nonlinear panel applications. To improve the finite sample performance, we also consider an alternative version based on the spectral decomposition of certain estimated matrix and link the group identification issue to the community detection problem in the network literature. Simulations show that our method has good finite sample performance. We apply this method to explore how individuals’ portfolio choices respond to their financial status and other characteristics using the Netherlands household panel data from year 1993 to 2015, and find three latent groups.",http://www.sciencedirect.com/science/article/pii/S0304407620301214
Journal of Econometrics,2021,Nonlinear factor models for network and panel data,"Mingli Chen, Ivan Fernandez-Val and Martin Weidner","Factor structures or interactive effects are convenient devices to incorporate latent variables in panel data models. We consider fixed effect estimation of nonlinear panel single-index models with factor structures in the unobservables, which include logit, probit, ordered probit and Poisson specifications. We establish that fixed effect estimators of model parameters and average partial effects have normal distributions when the two dimensions of the panel grow large, but might suffer from incidental parameter bias. We also show how models with factor structures can be applied to capture important features of network data such as reciprocity, degree heterogeneity, homophily in latent variables, and clustering. We illustrate this applicability with an empirical example to the estimation of a gravity equation of international trade between countries using a Poisson model with multiple factors.",http://www.sciencedirect.com/science/article/pii/S0304407620301238
Journal of Econometrics,2021,On the robustness of the pooled CCE estimator,"Artūras Juodis, Hande Karabiyik and Joakim Westerlund","Among the existing estimators of factor-augmented regressions, the CCE approach is the most popular. A major reason for this popularity is the simplicity and good small-sample performance of the approach, making it very attractive from an empirical point of view. The main drawback is that most of the available asymptotic theory is based on quite restrictive assumptions, such as that the common factor component should be independent of the regressors. The present paper can be seen as a reaction to this. The purpose is to study the asymptotic properties of the pooled CCE estimator under more realistic conditions. In particular, the common factor component may be correlated with the regressors, and the true number of common factors, r, can be larger than the number of estimated factors, which in CCE is given by k+1, where k is the number of regressors. The main conclusion is that while the estimator is generally consistent, asymptotic normality can fail when r>k+1.",http://www.sciencedirect.com/science/article/pii/S0304407620301834
Journal of Econometrics,2021,Estimating and testing high dimensional factor models with multiple structural changes,"Badi Baltagi, Chihwa Kao and Fa Wang","This paper considers multiple changes in the factor loadings of a high dimensional factor model occurring at dates that are unknown but common to all subjects. Since the factors are unobservable, the problem is converted to estimating and testing structural changes in the second moments of the pseudo factors. We consider both joint and sequential estimation of the change points and show that the distance between the estimated and the true change points is Op(1). We find that the estimation error contained in the estimated pseudo factors has no effect on the asymptotic properties of the estimated change points as the cross-sectional dimension N and the time dimension T go to infinity jointly. No N-T ratio condition is needed. We also propose (i) tests for no change versus l changes (ii) tests for l changes versus l+1 changes, and show that using estimated factors asymptotically has no effect on their limit distributions if T∕N→0. These tests allow us to make inference on the presence and number of structural changes. Simulation results show good performance of the proposed procedure. In an application to US quarterly macroeconomic data we detect two possible breaks.",http://www.sciencedirect.com/science/article/pii/S030440762030124X
Journal of Econometrics,2021,Predicting the VIX and the volatility risk premium: The role of short-run funding spreads Volatility Factors,Elena Andreou and Eric Ghysels,"This paper presents an innovative approach to extract Volatility Factors which predict the VIX, the S&P500 Realized Volatility (RV) and the Variance Risk Premium (VRP). The approach is innovative along two different dimensions, namely: (1) we extract Volatility Factors from panels of filtered volatilities — in particular large panels of univariate ARCH-type models and propose methods to estimate common Volatility Factors in the presence of estimation error and (2) we price equity volatility risk using factors which go beyond the equity class namely Volatility Factors extracted from panels of volatilities of short-run funding spreads. The role of these Volatility Factors is compared with the corresponding factors extracted from the panels of the above spreads as well as related factors proposed in the literature. Our monthly short-run funding spreads Volatility Factors provide both in- and out-of-sample predictive gains for forecasting the monthly VIX, RV as well as the equity premium, while the corresponding daily volatility factors via Mixed Data Sampling (MIDAS) models provide further improvements.",http://www.sciencedirect.com/science/article/pii/S0304407620301251
Journal of Econometrics,2021,Estimation of heterogeneous panels with systematic slope variations,Jörg Breitung and Nazarii Salish,"We analyse estimation procedures for the panel data models with heterogeneous slopes. Specifically we take into account a possible dependence between regressors and heterogeneous slope coefficients, which is referred to as systematic variation. It is shown that under relevant forms of systematic slope variations (i) the pooled OLS estimator is severely biased, (ii) Swamy’s GLS estimator is inconsistent if the number of time periods T is fixed, whereas (iii) the mean-group estimator always provides consistent estimators at the risk of high variances. Following Mundlak (1978) we propose an augmentated regression which results in a simple and robust version of the pooled estimator. The latter approach avoids the risk of large standard errors of the mean-group estimator, whenever T is small. We also propose two test statistics for systematic slope variation using the Lagrange multiplier and Hausman principles. We derive their asymptotic properties and provide a local power analysis of both test statistics. Monte Carlo experiments corroborate our theoretical findings and show that for all combinations of N and T the Mundlak-type GLS estimator outperform all other estimators.",http://www.sciencedirect.com/science/article/pii/S0304407620301263
Journal of Econometrics,2021,Instrumental variable estimation of dynamic linear panel data models with defactored regressors and a multifactor error structure,"Milda Norkutė, Vasilis Sarafidis, Takashi Yamagata and Guowei Cui","This paper develops two instrumental variable (IV) estimators for dynamic panel data models with exogenous covariates and a multifactor error structure when both the cross-sectional and time series dimensions, N and T respectively, are large. The main idea is to project out the common factors from the exogenous covariates of the model, and to construct instruments based on defactored covariates. For models with homogeneous slope coefficients, we propose a two-step IV estimator. In the first step, the model is estimated consistently by employing defactored covariates as instruments. In the second step, the entire model is defactored based on estimated factors extracted from the residuals of the first-step estimation, after which an IV regression is implemented using the same instruments as in step one. For models with heterogeneous slope coefficients, we propose a mean-group-type estimator, which involves the averaging of first-step IV estimates of cross-section-specific slopes. The proposed estimators do not need to seek for instrumental variables outside the model. Furthermore, these estimators are linear, and therefore computationally robust and inexpensive. Notably, they require no bias correction. We investigate the finite sample performances of the proposed estimators and associated statistical tests, and the results show that the estimators and the tests perform well even for small N and T.",http://www.sciencedirect.com/science/article/pii/S0304407620301275
Journal of Econometrics,2021,Heterogeneous structural breaks in panel data models,Ryo Okui and Wendun Wang,"This paper develops a new model and estimation procedure for panel data that allows us to identify heterogeneous structural breaks. We model individual heterogeneity using a grouped pattern. For each group, we allow common structural breaks in the coefficients. However, the number, timing, and size of these breaks can differ across groups. We develop a hybrid estimation procedure of the grouped fixed effects approach and adaptive group fused Lasso. We show that our method can consistently identify the latent group structure, detect structural breaks, and estimate the regression parameters. Monte Carlo results demonstrate the good performance of the proposed method in finite samples. An empirical application to the relationship between income and democracy illustrates the importance of considering heterogeneous structural breaks.",http://www.sciencedirect.com/science/article/pii/S0304407620301287
Journal of Econometrics,2021,Inferential theory for heterogeneity and cointegration in large panels,Lorenzo Trapani,"This paper provides an estimation and testing framework to assess the presence and the extent of slope heterogeneity and cointegration when the units are a mixture of spurious and/or cointegrating regressions. We propose two moment estimators for the degree of heterogeneity (measured by the dispersion of the slope coefficients around their average) and for the fraction of spurious regressions, which are found to be consistent in the whole parameter space. Based on these estimators, two tests for the null hypotheses of slope homogeneity and for cointegration are proposed. Monte Carlo simulations show that both tests have the correct size and satisfactory power.",http://www.sciencedirect.com/science/article/pii/S0304407620301299
Journal of Econometrics,2021,Estimation and inference for multi-dimensional heterogeneous panel datasets with hierarchical multi-factor error structure,"George Kapetanios, Laura Serlenga and Yongcheol Shin","Given the growing availability of large datasets and following recent research trends on multi-dimensional modelling, we develop three dimensional (3D) panel data models with hierarchical error components that allow for strong cross-section dependence through unobserved heterogeneous global and local factors. We propose consistent estimation procedures by extending the common correlated effects (CCE) estimation approach proposed by Pesaran (2006). The standard CCE approach needs to be modified in order to account for the hierarchical factor structure in 3D panels. Further, we provide asymptotic theory, including new nonparametric variance estimators. The validity of the proposed approach is confirmed by Monte Carlo simulation studies. We demonstrate the empirical usefulness of the proposed framework through an application to a 3D panel gravity model of bilateral export flows.",http://www.sciencedirect.com/science/article/pii/S0304407620301305
Journal of Econometrics,2021,An econometric approach to the estimation of multi-level models,Yimin Yang and Peter Schmidt,"In this paper we consider “multidimensional” or “hierarchical” or “multilevel” models that are popular in the educational and economics literatures. Instead of two levels (individuals over time in the standard panel data model), we now have multiple levels (e.g. students in classrooms in schools in districts). We apply standard methods of analysis for econometric panel data to multilevel models. Specifically, we generalize the results of Hausman and Taylor and the subsequent literature to these models. This is a non-trivial extension because we now have more than one kind of time-invariant effect and more than one kind of “between” regression. We discuss estimation by GMM both with and without the assumption of no conditional heteroskedasticity. We also discuss endogeneity and dynamic models, and we generalize the concept of testing the exogeneity assumptions using a variable addition test.",http://www.sciencedirect.com/science/article/pii/S0304407620301317
Journal of Econometrics,2021,Detecting granular time series in large panels,Christian Brownlees and Geert Mesters,"Large economic and financial panels can include time series that influence the entire cross-section. We name such series granular. In this paper we introduce a panel data model that allows to formalize the notion of granular time series. We then propose a methodology, which is inspired by the network literature in statistics and econometrics, to detect the set of granulars when such set is unknown. The influence of the ith series in the panel is measured by the norm of the ith column of the inverse covariance matrix. We show that a detection procedure based on the column norms allows to consistently select granular series when the cross-section and time series dimensions are large. Importantly, the methodology allows to consistently detect granulars also when the series in the panel are influenced by common factors. A simulation study shows that the proposed procedures perform satisfactorily in finite samples. Our empirical study shows the granular influence of the automobile sector in US industrial production.",http://www.sciencedirect.com/science/article/pii/S0304407620301329
Journal of Econometrics,2021,Estimation of a nonparametric model for bond prices from cross-section and time series information,"Bonsoo Koo, Davide La Vecchia and Oliver Linton","We develop a novel estimation methodology for an additive nonparametric panel model that is suitable for capturing the pricing of coupon-paying government bonds followed over many time periods. We use our model to estimate the discount function and yield curve of nominally riskless government bonds. The novelty of our approach is the combination of two different techniques: cross-sectional nonparametric methods and kernel estimation for time varying dynamics in the time series context. The resulting estimator is used for predicting individual bond prices given the full schedule of their future payments. In addition, it is able to capture the yield curve shapes and dynamics commonly observed in the fixed income markets. We establish the consistency, the rate of convergence, and the asymptotic normality of the proposed estimator. A Monte Carlo exercise illustrates the good performance of the method under different scenarios. We apply our methodology to the daily CRSP bond market dataset, and compare ours with the popular Diebold and Li (2006) method.",http://www.sciencedirect.com/science/article/pii/S0304407620301330
Journal of Econometrics,2021,"Dynamic panels with MIDAS covariates: Nonlinearity, estimation and fit","Lynda Khalaf, Maral Kichian, Charles J. Saunders and Marcel Voia","This paper introduces Mixed Data Sampling (MIDAS) into the panel data context. To address the unidentified nuisance parameter problem, we propose to invert model specification tests for inference on the MIDAS parameter along with bounds tests for model coefficients. Illustrative identification, simulation and empirical analyses are conducted in the dynamic GMM framework. Our framework allows for departures from i.i.d errors such as clustering and dynamic specifications. A simulation study and an application to a model of reserve holdings illustrate the usefulness of the proposed methods, and more broadly set a promising template for shrinkage approaches.",http://www.sciencedirect.com/science/article/pii/S0304407620301342
Journal of Econometrics,2021,Panel forecasts of country-level Covid-19 infections,"Laura Liu, Hyungsik Roger Moon and Frank Schorfheide","We use a dynamic panel data model to generate density forecasts for daily active Covid-19 infections for a panel of countries/regions. Our specification that assumes the growth rate of active infections can be represented by autoregressive fluctuations around a downward sloping deterministic trend function with a break. Our fully Bayesian approach allows us to flexibly estimate the cross-sectional distribution of slopes and then implicitly use this distribution as prior to construct Bayes forecasts for the individual time series. We find some evidence that information from locations with an early outbreak can sharpen forecast accuracy for late locations. There is generally a lot of uncertainty about the evolution of active infection, due to parameter and shock uncertainty, in particular before and around the peak of the infection path. Over a one-week horizon, the empirical coverage frequency of our interval forecasts is close to the nominal credible level. Weekly forecasts from our model are published at https://laurayuliu.com/covid19-panel-forecast/.",http://www.sciencedirect.com/science/article/pii/S030440762030347X
Journal of Econometrics,2021,"Causal impact of masks, policies, behavior on early covid-19 pandemic in the U.S","Victor Chernozhukov, Hiroyuki Kasahara and Paul Schrimpf","The paper evaluates the dynamic impact of various policies adopted by US states on the growth rates of confirmed Covid-19 cases and deaths as well as social distancing behavior measured by Google Mobility Reports, where we take into consideration people’s voluntarily behavioral response to new information of transmission risks in a causal structural model framework. Our analysis finds that both policies and information on transmission risks are important determinants of Covid-19 cases and deaths and shows that a change in policies explains a large fraction of observed changes in social distancing behavior. Our main counterfactual experiments suggest that nationally mandating face masks for employees early in the pandemic could have reduced the weekly growth rate of cases and deaths by more than 10 percentage points in late April and could have led to as much as 19 to 47 percent less deaths nationally by the end of May, which roughly translates into 19 to 47 thousand saved lives. We also find that, without stay-at-home orders, cases would have been larger by 6 to 63 percent and without business closures, cases would have been larger by 17 to 78 percent. We find considerable uncertainty over the effects of school closures due to lack of cross-sectional variation; we could not robustly rule out either large or small effects. Overall, substantial declines in growth rates are attributable to private behavioral response, but policies played an important role as well. We also carry out sensitivity analyses to find neighborhoods of the models under which the results hold robustly: the results on mask policies appear to be much more robust than the results on business closures and stay-at-home orders. Finally, we stress that our study is observational and therefore should be interpreted with great caution. From a completely agnostic point of view, our findings uncover predictive effects (association) of observed policies and behavioral changes on future health outcomes, controlling for informational and other confounding variables.",http://www.sciencedirect.com/science/article/pii/S0304407620303468
Journal of Econometrics,2021,Identification and estimation of the SEIRD epidemic model for COVID-19,Ivan Korolev,"This paper studies the SEIRD epidemic model for COVID-19. First, I show that the model is poorly identified from the observed number of deaths and confirmed cases. There are many sets of parameters that are observationally equivalent in the short run but lead to markedly different long run forecasts. Second, I show that the basic reproduction number R0 can be identified from the data, conditional on epidemiologic parameters, and propose several nonlinear SUR approaches to estimate R0. I examine the performance of these methods using Monte Carlo studies and demonstrate that they yield fairly accurate estimates of R0. Next, I apply these methods to estimate R0 for the US, California, and Japan, and document heterogeneity in the value of R0 across regions. My estimation approach accounts for possible underreporting of the number of cases. I demonstrate that if one fails to take underreporting into account and estimates R0 from the reported cases data, the resulting estimate of R0 may be biased downward and the resulting forecasts may exaggerate the long run number of deaths. Finally, I discuss how auxiliary information from random tests can be used to calibrate the initial parameters of the model and narrow down the range of possible forecasts of the future number of deaths.",http://www.sciencedirect.com/science/article/pii/S0304407620302621
Journal of Econometrics,2021,Consumer panic in the COVID-19 pandemic,Michael Keane and Timothy Neal,"We develop an econometric model of consumer panic (or panic buying) during the COVID-19 pandemic. Using Google search data on relevant keywords, we construct a daily index of consumer panic for 54 countries from January 1st to April 30th 2020. We also assemble data on government policy announcements and daily COVID-19 cases for all countries. Our panic index reveals widespread consumer panic in most countries, primarily during March, but with significant variation in the timing and severity of panic between countries. Our model implies that both domestic and world virus transmission contribute significantly to consumer panic. But government policy is also important: Internal movement restrictions – whether announced by domestic or foreign governments – generate substantial short run panic that largely vanishes in a week to ten days. Internal movement restrictions announced early in the pandemic generated more panic than those announced later. Stimulus announcements had smaller impacts, and travel restrictions do not appear to generate consumer panic.",http://www.sciencedirect.com/science/article/pii/S0304407620302840
Journal of Econometrics,2021,Estimating the fraction of unreported infections in epidemics with a known epicenter: An application to COVID-19,"Ali Hortacsu, Jiarui Liu and Timothy Schwieg","We develop an analytically tractable method to estimate the fraction of unreported infections in epidemics with a known epicenter and estimate the number of unreported COVID-19 infections in the U.S. during the first half of March 2020. Our method utilizes the covariation in initial reported infections across U.S. regions and the number of travelers to these regions from the epicenter, along with the results of an early randomized testing study in Iceland. Using our estimates of the number of unreported infections, which are substantially larger than the number of reported infections, we also provide estimates for the infection fatality rate using data on reported COVID-19 fatalities from U.S. counties.",http://www.sciencedirect.com/science/article/pii/S030440762030302X
Journal of Econometrics,2021,When will the Covid-19 pandemic peak?,Shaoran Li and Oliver Linton,"We carry out some analysis of the daily data on the number of new cases and the number of new deaths by (191) countries as reported to the European Centre for Disease Prevention and Control (ECDC). Our benchmark model is a quadratic time trend model applied to the log of new cases for each country. We use our model to predict when the peak of the epidemic will arise in terms of new cases or new deaths in each country and the peak level. We also predict how long the number of new daily cases in each country will fall by an order of magnitude. Finally, we also forecast the total number of cases and deaths for each country. We consider two models that link the joint evolution of new cases and new deaths.",http://www.sciencedirect.com/science/article/pii/S0304407620303055
Journal of Econometrics,2021,Sparse HP filter: Finding kinks in the COVID-19 contact rate,"Sokbae (Simon) Lee, Yuan Liao, Myung Hwan Seo and Youngki Shin","In this paper, we estimate the time-varying COVID-19 contact rate of a Susceptible–Infected–Recovered (SIR) model. Our measurement of the contact rate is constructed using data on actively infected, recovered and deceased cases. We propose a new trend filtering method that is a variant of the Hodrick–Prescott (HP) filter, constrained by the number of possible kinks. We term it the sparse HP filter and apply it to daily data from five countries: Canada, China, South Korea, the UK and the US. Our new method yields the kinks that are well aligned with actual events in each country. We find that the sparse HP filter provides a fewer kinks than the ℓ1 trend filter, while both methods fitting data equally well. Theoretically, we establish risk consistency of both the sparse HP and ℓ1 trend filters. Ultimately, we propose to use time-varying contact growth rates to document and monitor outbreaks of COVID-19.",http://www.sciencedirect.com/science/article/pii/S0304407620303365
Journal of Econometrics,2021,Estimating the COVID-19 infection rate: Anatomy of an inference problem,Charles Manski and Francesca Molinari,"As a consequence of missing data on tests for infection and imperfect accuracy of tests, reported rates of cumulative population infection by the SARS CoV-2 virus are lower than actual rates of infection. Hence, reported rates of severe illness conditional on infection are higher than actual rates. Understanding the time path of the COVID-19 pandemic has been hampered by the absence of bounds on infection rates that are credible and informative. This paper explains the logical problem of bounding these rates and reports illustrative findings, using data from Illinois, New York, and Italy. We combine the data with assumptions on the infection rate in the untested population and on the accuracy of the tests that appear credible in the current context. We find that the infection rate might be substantially higher than reported. We also find that, assuming accurate reporting of deaths, the infection fatality rates in Illinois, New York, and Italy are substantially lower than reported.",http://www.sciencedirect.com/science/article/pii/S0304407620301676
Journal of Econometrics,2021,Estimation of Covid-19 prevalence from serology tests: A partial identification approach,Panos Toulis,"We propose a partial identification method for estimating disease prevalence from serology studies. Our data are results from antibody tests in some population sample, where the test parameters, such as the true/false positive rates, are unknown. Our method scans the entire parameter space, and rejects parameter values using the joint data density as the test statistic. The proposed method is conservative for marginal inference, in general, but its key advantage over more standard approaches is that it is valid in finite samples even when the underlying model is not point identified. Moreover, our method requires only independence of serology test results, and does not rely on asymptotic arguments, normality assumptions, or other approximations. We use recent Covid-19 serology studies in the US, and show that the parameter confidence set is generally wide, and cannot support definite conclusions. Specifically, recent serology studies from California suggest a prevalence anywhere in the range 0%-2% (at the time of study), and are therefore inconclusive. However, this range could be narrowed down to 0.7%–1.5% if the actual false positive rate of the antibody test was indeed near its empirical estimate (∼0.5%). In another study from New York state, Covid-19 prevalence is confidently estimated in the range 13%–17% in mid-April of 2020, which also suggests significant geographic variation in Covid-19 exposure across the US. Combining all datasets yields a 5%–8% prevalence range. Our results overall suggest that serology testing on a massive scale can give crucial information for future policy design, even when such tests are imperfect and their parameters unknown.",http://www.sciencedirect.com/science/article/pii/S030440762030350X
