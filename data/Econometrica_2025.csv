journal,year,title,authors,abstract,url
Econometrica,2025,Erratum to “Robust Priors in Nonlinear Panel Data Models”,"Manuel Arellano, Stéphane Bonhomme, Sofia Borodich Suarez, Martin Schumann, Xiaoxia Shi and Gautam Tripathi",,https://doi.org/10.3982/ECTA23441
Econometrica,2025,"Fisher–Schultz Lecture: Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments, With an Application to Immunization in India","Victor Chernozhukov, Mert Demirer, Esther Duflo and Iván Fernández‐Val","We propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. These key features include best linear predictors of the effects using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high‐dimensional settings, where the effects are proxied (but not necessarily consistently estimated) by predictive and causal machine learning methods. We post‐process these proxies into estimates of the key features. Our approach is generic; it can be used in conjunction with penalized methods, neural networks, random forests, boosted trees, and ensemble methods, both predictive and causal. Estimation and inference are based on repeated data splitting to avoid overfitting and achieve validity. We use quantile aggregation of the results across many potential splits, in particular taking medians of p‐values and medians and other quantiles of confidence intervals. We show that quantile aggregation lowers estimation risks over a single split procedure, and establish its principal inferential properties. Finally, our analysis reveals ways to build provably better machine learning proxies through causal learning: we can use the objective functions that we develop to construct the best linear predictors of the effects, to obtain better machine learning proxies in the initial step. We illustrate the use of both inferential tools and causal learners with a randomized field experiment that evaluates a combination of nudges to stimulate demand for immunization in India.",https://doi.org/10.3982/ECTA19303
Econometrica,2025,"A Comment on: “Fisher–Schultz Lecture: Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments, With an Application to Immunization in India” by Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández‐Val",Kosuke Imai and Michael Lingzhi Li,"We examine the split‐sample robust inference (SSRI) methodology introduced by Chernozhukov, Demirer, Duflo, and Fernandez‐Val for quantifying uncertainty in heterogeneous treatment effect estimates produced by machine learning (ML) models. Although SSRI properly accounts for the additional variability due to sample splitting, its computational cost becomes prohibitive with complex ML models. We propose an alternative approach based on randomization inference (RI) that preserves the broad applicability of SSRI while eliminating the need for repeated sample splitting. Leveraging cross‐fitting and design‐based inference, the RI procedure yields valid confidence intervals with substantially reduced computational burden. Simulation studies demonstrate that the RI method preserves the statistical efficiency of SSRI while scaling to much larger applications and more complex settings.",https://doi.org/10.3982/ECTA22261
Econometrica,2025,"A Comment on: “Fisher–Schultz Lecture: Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments, With an Application to Immunization in India” by Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández‐Val",Stefan Wager,"We use the martingale construction of Luedtke and van der Laan (2016) to develop tests for the presence of treatment heterogeneity. The resulting sequential validation approach can be instantiated using various validation metrics, such as BLPs, GATES, QINI curves, etc., and provides an alternative to cross‐validation‐like cross‐fold application of these metrics. This note was prepared as a comment on the Fisher–Schultz paper by Chernozhukov, Demirer, Duflo, and Fernández‐Val, forthcoming in Econometrica.",https://doi.org/10.3982/ECTA23293
Econometrica,2025,"Reply to: Comments on “Fisher–Schultz Lecture: Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments, With an Application to Immunization in India”","Victor Chernozhukov, Mert Demirer, Esther Duflo and Iván Fernández‐Val",,https://doi.org/10.3982/ECTA23706
Econometrica,2025,Selecting the Most Effective Nudge: Evidence From a Large‐Scale Experiment on Immunization,"Abhijit Banerjee, Arun G. Chandrasekhar, Suresh Dalpath, Esther Duflo, John Floretta, Matthew O. Jackson, Harini Kannan, Francine Loza, Anirudh Sankar, Anna Schrimpf and Maheshwor Shrestha","Policymakers often choose a policy bundle that is a combination of different interventions in different dosages. We develop a new technique—treatment variant aggregation (TVA)—to select a policy from a large factorial design. TVA pools together policy variants that are not meaningfully different and prunes those deemed ineffective. This allows us to restrict attention to aggregated policy variants, consistently estimate their effects on the outcome, and estimate the best policy effect adjusting for the winner's curse. We apply TVA to a large randomized controlled trial that tests interventions to stimulate demand for immunization in Haryana, India. The policies under consideration include reminders, incentives, and local ambassadors for community mobilization. Cross‐randomizing these interventions, with different dosages or types of each intervention, yields 75 combinations. The policy with the largest impact (which combines incentives, ambassadors who are information hubs, and reminders) increases the number of immunizations by 44% relative to the status quo. The most cost‐effective policy (information hubs, ambassadors, and SMS reminders, but no incentives) increases the number of immunizations per dollar by 9.1% relative to the status quo.",https://doi.org/10.3982/ECTA19739
Econometrica,2025,Producing Health: Measuring Value Added of Nursing Homes,"Liran Einav, Amy Finkelstein and Neale Mahoney","We develop a stylized model that allows us to estimate a value‐added measure for nursing homes (“SNFs”) which accounts for patient selection both into and out of a SNF. We use the model, together with detailed data on the physical and mental health of about 6 million Medicare SNF patients between 2011 and 2016, to estimate the value added for about 14,000 distinct SNFs. We document substantial heterogeneity in value added. Nationwide, compared to a 10th percentile SNF, a 90th percentile SNF is able to discharge a patient at the same health level almost a week sooner, or one quarter of the median length of stay. Heterogeneity in value added within a market is almost as large as it is nationwide. Our results point to the potential for substantial gains through policies that encourage reallocation of patients to higher‐quality SNFs within their market.",https://doi.org/10.3982/ECTA21016
Econometrica,2025,Competitive Capture of Public Opinion,Ricardo Alonso and Gerard Padró i Miquel,"Two opposed interested parties (IPs) compete to influence citizens with heterogeneous priors which receive news items produced by a variety of sources. The IPs fight to capture the coverage conveyed in these items. We characterize the equilibrium level of capture of item as well as the equilibrium level of information transmission. Capture increases the prevalence of the ex ante most informative messages and can explain the empirical distribution of slant at the news‐item level. Opposite capturing efforts do not cancel each other and instead undermine social learning as rational citizens discount informative messages. Citizen skepticism makes efforts to capture the news strategic substitutes. Because of strategic substitution, competition for influence is compatible with horizontal differentiation between successful media. In equilibrium, rational citizens choose to consume messages from aligned sources despite knowledge of the bias in a manner consistent with recent empirical evidence.",https://doi.org/10.3982/ECTA22072
Econometrica,2025,You Can Lead a Horse to Water: Spatial Learning and Path Dependence in Consumer Search,Charles Hodgson and Gregory Lewis,"We develop and estimate a model of consumer search with spatial learning. Consumers make inferences from previously searched objects to unsearched objects that are nearby in attribute space, generating path dependence in search sequences. The estimated model rationalizes patterns in data on online consumer search paths: search tends to converge to the chosen product in attribute space, and consumers take larger steps away from rarely purchased products. Eliminating spatial learning reduces consumer welfare by 12%: cross‐product inferences allow consumers to locate better products in a shorter time. Spatial learning has important implications for product recommendations on retail platforms. We show that consumer welfare can be reduced by unrepresentative product recommendations and that consumer‐optimal product recommendations depend on both consumer learning and competition between platforms.",https://doi.org/10.3982/ECTA19576
Econometrica,2025,Dynamic Concern for Misspecification,Giacomo Lanzani,"I consider an agent who posits a set of probabilistic models for the payoff‐relevant outcomes. The agent has a prior over this set but fears the actual model is omitted and hedges against this possibility. The concern for misspecification is endogenous: If a model explains the previous observations well, the concern attenuates. I show that different static preferences under uncertainty (subjective expected utility, maxmin, robust control) arise in the long run, depending on how quickly the agent becomes unsatisfied with unexplained evidence. The misspecification concern's endogeneity naturally induces behavior cycles, and I characterize the limit action frequency. I apply the model to monetary policy cycles and choices in the face of complex tax schedules.",https://doi.org/10.3982/ECTA22139
Econometrica,2025,Private Information and Price Regulation in the US Credit Card Market,Scott T. Nelson,"The 2009 CARD Act limited credit card lenders' ability to raise borrowers' interest rates on the basis of new information. Pricing became less responsive to public and private signals of borrowers' risk and demand characteristics, and price dispersion fell by one‐third. I estimate the efficiency and distributional effects of this shift toward more pooled pricing. Prices fell for high‐risk and price‐inelastic consumers, but prices rose elsewhere in the market and newly exceeded willingness to pay for over 30% of the safest subprime borrowers. On net, average traded prices fell and consumer surplus rose at all credit scores. Higher consumer surplus was partly driven by a fall in lender profits, and partly by the Act's insurance value to borrowers who could retain favorable pricing after adverse changes to their default risk. The relatively high level of pre‐CARD‐Act markups was crucial for realizing these surplus gains.",https://doi.org/10.3982/ECTA18063
Econometrica,2025,Contract Labor and Establishment Growth in India,"Marianne Bertrand, Chang‐Tai Hsieh and Nick Tsivanidis","India's Industrial Disputes Act (IDA) requires large manufacturing plants to pay substantial costs if they wish to shrink their workforce. Since the early 2000s, these large plants have dramatically increased their use of contract workers who are not subject to these regulatory constraints. Between 2000 and 2015, the contract labor share in non‐managerial employment nearly doubled at establishments with more than 100 workers (from 21 to 40 percentage points), while it only increased from 14 to 17 percentage points at establishments with less than 50 workers. Over the same period, the thickness of the right tail of the establishment size distribution in formal Indian manufacturing plants increased, the average product of labor at large plants declined, the job creation rate for large plants increased, and the probability that large plants introduced new products rose. We argue that these changes were caused by the increased adoption of contract labor. In a model of establishment growth subject to firing costs, we show that easing access to contract labor increased TFP in Indian manufacturing by 7.3% since the early 2000s, occurring all through a one‐time reduction in misallocation between large and small plants with negligible change in the long‐run growth rate.",https://doi.org/10.3982/ECTA20046
Econometrica,2025,Fiduciary Duty and the Market for Financial Advice,"Vivek Bhattacharya, Gastón Illanes and Manisha Padi","Fiduciary duty aims to solve principal‐agent problems, and the United States is in the middle of a protracted debate surrounding the merits of extending it to all financial advisers. Leveraging a transaction‐level data set of deferred annuities and state‐level variation in common law fiduciary duty, we find that it raises risk‐adjusted returns by 25 bp and leads to a 16% decline in the entry of affected firms. Through the lens of a model of entry and advice provision, we show that this effect can be due to both an increase in fixed costs and an increase in the cost of providing low‐quality advice. We show how to disentangle these channels and find that both are empirically relevant. Counterfactual simulations show that further increases in the stringency of fiduciary duty monotonically improve advice quality.",https://doi.org/10.3982/ECTA18492
Econometrica,2025,A Comment on: “Monotone Comparative Statics”,Rabah Amir and David Rietzke,"Milgrom and Shannon (1994) provide necessary and sufficient conditions on parameterized optimization problems for their solution sets to be globally monotone in the parameter. We establish that their conditions may be significantly relaxed when focusing on discrete, binary comparisons between solution sets. Such binary comparisons are ubiquitous in economics and may involve comparing the same decision maker across two distinct regimes or two distinct decision makers with related objectives (e.g., a monopolist firm versus a social planner). While the single‐crossing property remains prominent in the theory, quasisupermodularity of the objective functions of interest is not needed. Our approach relies upon a novel method of embedding a new optimization problem with a quasisupermodular objective function “between” the two original problems of interest. In smooth problems, sufficient conditions for our new assumptions may be verified by elementary differential comparisons, making them well suited for applied work. We illustrate the relevance of this novel approach with several economic applications.",https://doi.org/10.3982/ECTA23292
Econometrica,2025,Corrigendum: Financial Frictions and the Wealth Distribution,"Jesús Fernández‐Villaverde, Samuel Hurtado and Galo Nuño",,https://doi.org/10.3982/ECTA22259
Econometrica,2025,Making Subsidies Work: Rules versus Discretion,"Federico Cingano, Filippo Palomba, Paolo Pinotti and Enrico Rettore","We estimate the employment effects of a large program of public investment subsidies to private firms that ranked applicants on a score reflecting both objective rules and local politicians' discretion. Leveraging the rationing of funds as an ideal Regression Discontinuity Design, we characterize the heterogeneity of treatment effects and cost‐per‐new‐job across inframarginal firms and estimate the cost‐effectiveness of subsidies under factual and counterfactual allocations. Firms ranking high on objective rules and firms preferred by local politicians generated larger employment growth on average, but the latter did so at a higher cost per job. We estimate that relying only on objective criteria would reduce the cost per job by 11%, while relying only on political discretion would increase such cost by 42%.",https://doi.org/10.3982/ECTA21319
Econometrica,2025,The Cost of Consumer Collateral: Evidence From Bunching,"Benjamin L. Collier, Cameron M. Ellis and Benjamin J. Keys","How do collateral requirements impact consumer borrowing behavior? Using administrative loan application and performance data from the U.S. Federal Disaster Loan Program, we exploit a loan amount threshold above which households must post their residence as collateral. Our bunching estimates suggest that the median borrower is willing to give up 40% of their loan amount to avoid posting collateral. Exploiting time variation in the threshold, we estimate collateral causally reduces default rates by 36%. Finally, we structurally estimate households' attachment to their homes, net of any equity, and find a median value of $11,000. Attachment creates a wedge between lender and borrower valuation of collateral of 15%. Our results explain high perceived default costs in the mortgage market, and document the importance of collateral for reducing moral hazard in consumer credit markets.",https://doi.org/10.3982/ECTA22303
Econometrica,2025,Insurance and Inequality With Persistent Private Information,"Alexander W. Bloedel, R. Vijay Krishna and Oksana Leukhina","We study the implications of optimal insurance provision for long‐run welfare and inequality in economies with persistent private information. A principal insures an agent whose private type follows an ergodic, finite‐state Markov chain. The optimal contract always induces immiseration: the agent's consumption and utility decrease without bound. Under positive serial correlation, it also backloads high‐powered incentives: the sensitivity of the agent's utility with respect to his reports increases without bound. These results extend—and help elucidate the limits of—the hallmark immiseration results for economies with i.i.d. private information. Numerically, we find that persistence yields faster immiseration, higher inequality, and novel short‐run distortions. Our analysis uses recursive methods for contracting with persistent types and allows for binding global incentive constraints.",https://doi.org/10.3982/ECTA20404
Econometrica,2025,Auctioning Control and Cash‐Flow Rights Separately,Tingjun Liu and Dan Bernhardt,"We consider a classical auction setting in which an asset/project is sold to buyers who privately receive signals about expected payoffs, and payoffs are more sensitive to a bidder's signal if he runs the project than if another bidder does. We show that a seller can increase revenues by sometimes allocating cash‐flow rights and control to different bidders, for example, with the highest bidder receiving cash flows and the second‐highest receiving control. Separation reduces a bidder's information rent, which depends on the importance of his private information for the value of his awarded cash flows. As project payoffs are most sensitive to a bidder's information if he controls the project, allocating cash flow to another bidder lowers bidders' informational advantage. As a result, when signals are close, the seller can increase revenues by splitting rights between the top two bidders.",https://doi.org/10.3982/ECTA21343
Econometrica,2025,"Soaking up the Sun: Battery Investment, Renewable Energy, and Market Equilibrium","R. Andrew Butters, Jackson Dorsey and Gautam Gowrisankaran","Renewable energy and battery storage are seen as complementary technologies that can together facilitate reductions in carbon emissions. We develop and estimate a framework to calculate the equilibrium effects of large‐scale battery storage. Using data from California, we find that the first storage unit breaks even by 2024 without subsidies when the renewable energy share reaches 50%. Equilibrium effects are important: the first 5000 MWh of storage capacity would reduce wholesale electricity prices by 5.6%, but an increase from 25,000 to 50,000 MWh would only reduce these prices by 2.6%. Large‐scale batteries will reduce revenues to both dispatchable generators and renewable energy sources. The equilibrium effects lead battery adoption to be virtually non‐existent until 2030, without a storage mandate or subsidy. A 30% capital cost subsidy—such as the one in the U.S. Inflation Reduction Act—achieves 5000 MWh of battery capacity by 2024, similar to the level required under California's storage mandate.",https://doi.org/10.3982/ECTA20411
Econometrica,2025,Personalized Pricing and the Value of Time: Evidence From Auctioned Cab Rides,"Nicholas Buchholz, Laura Doval, Jakub Kastl, Filip Matejka and Tobias Salz","We recover valuations of time using detailed data from a large ride‐hail platform, where drivers bid on trips and consumers choose between a set of rides with different prices and wait times. Leveraging a consumer panel, we estimate demand as a function of both prices and wait times and use the resulting estimates to recover heterogeneity in the value of time across consumers. We study the welfare implications of personalized pricing and its effect on the platform, drivers, and consumers. Taking into account drivers' optimal reaction to the platform's pricing policy, personalized pricing lowers consumer surplus by 2.5% and increases overall surplus by 5.2%. Like the platform, drivers benefit from personalized pricing. By conditioning prices on drivers' wait times and not on consumers' data, the platform can capture a significant portion of the profits garnered from personalized pricing, and simultaneously benefit consumers.",https://doi.org/10.3982/ECTA18838
Econometrica,2025,Quality Disclosure and Regulation: Scoring Design in Medicare Advantage,Benjamin Vatter,"Policymakers and market intermediaries often use quality scores to alleviate asymmetric information about product quality. Scores affect the demand for quality and, in equilibrium, its supply. Equilibrium effects break the rule whereby more information is always better, and the optimal design of scores must account for them. In the context of Medicare Advantage, I find that consumers' information is limited, and quality is inefficiently low. A simple design alleviates these issues and increases total welfare by 3.7 monthly premiums. More than half of the gains stem from scores' effect on quality rather than information. Scores can outperform full‐information outcomes by regulating inefficient oligopolistic quality provision, and a binary certification of quality attains 98% of this welfare. Scores are informative even when coarse; firms' incentives are to produce quality at the scoring threshold, which consumers know. The primary design challenge of scores is to dictate thresholds and thus regulate quality.",https://doi.org/10.3982/ECTA21182
Econometrica,2025,Risk and Optimal Policies in Bandit Experiments,Karun Adusumilli,"We provide a decision‐theoretic analysis of bandit experiments under local asymptotics. Working within the framework of diffusion processes, we define suitable notions of asymptotic Bayes and minimax risk for these experiments. For normally distributed rewards, the minimal Bayes risk can be characterized as the solution to a second‐order partial differential equation (PDE). Using a limit of experiments approach, we show that this PDE characterization also holds asymptotically under both parametric and non‐parametric distributions of the rewards. The approach further describes the state variables it is asymptotically sufficient to restrict attention to, and thereby suggests a practical strategy for dimension reduction. The PDEs characterizing minimal Bayes risk can be solved efficiently using sparse matrix routines or Monte Carlo methods. We derive the optimal Bayes and minimax policies from their numerical solutions. These optimal policies substantially dominate existing methods such as Thompson sampling; the risk of the latter is often twice as high.",https://doi.org/10.3982/ECTA21075
Econometrica,2025,Location Sorting and Endogenous Amenities: Evidence From Amsterdam,Milena Almagro and Tomás Domínguez‐Iino,"This paper shows the endogeneity of amenities plays a crucial role in determining the welfare distribution of a city's residents. We quantify this mechanism by building a dynamic model of residential choice with heterogeneous households, where consumption amenities are the equilibrium outcome of a market for non‐tradables. We estimate our model using Dutch microdata and leveraging variation in Amsterdam's spatial distribution of tourists as a demand shifter, finding significant heterogeneity in residents' preferences over amenities and in the supply responses of amenities to changes in demand composition. This two‐way heterogeneity dictates the degree of horizontal differentiation across neighborhoods, residential sorting, and inequality. Finally, we show the distributional effects of mass tourism depend on this heterogeneity: following rent increases due to growing tourist demand for housing, younger residents—whose amenity preferences are closest to tourists—are compensated by amenities tilting in their favor, while the losses of older residents are amplified.",https://doi.org/10.3982/ECTA21394
Econometrica,2025,Adaptive Maximization of Social Welfare,"Nicolò Cesa‐Bianchi, Roberto Colomboni and Maximilian Kasy","We consider the problem of repeatedly choosing policies to maximize social welfare. Welfare is a weighted sum of private utility and public revenue. Earlier outcomes inform later policies. Utility is not observed, but indirectly inferred. Response functions are learned through experimentation. We derive a lower bound on regret, and a matching adversarial upper bound for a variant of the Exp3 algorithm. Cumulative regret grows at a rate of T2/3. This implies that (i) welfare maximization is harder than the multiarmed bandit problem (with a rate of T1/2 for finite policy sets), and (ii) our algorithm achieves the optimal rate. For the stochastic setting, if social welfare is concave, we can achieve a rate of T1/2 (for continuous policy sets), using a dyadic search algorithm. We analyze an extension to nonlinear income taxation, and sketch an extension to commodity taxation. We compare our setting to monopoly pricing (which is easier), and price setting for bilateral trade (which is harder).",https://doi.org/10.3982/ECTA22351
Econometrica,2025,Cap‐and‐Trade and Carbon Tax Meet Arrow–Debreu,Robert M. Anderson and Haosui Duanmu,"We propose two general equilibrium models, quota equilibrium, and emission tax equilibrium. Government specifies quotas or taxes on emissions, and then refrains from further action. All results remain valid regardless of how government chooses its emissions target. Quota equilibrium exists; the allocation of emission property rights impacts the distribution of welfare. If the only externality arises from total net emissions, quota equilibrium is Pareto optimal among all feasible outcomes with the same total net emissions. For certain tax rates, emission tax equilibrium may not exist. Every quota equilibrium can be realized as an emission tax equilibrium and vice versa. However, different quota prices may arise in equilibrium from a single quota, and different emission levels may arise in equilibrium from a single tax rate. This leads to inequivalence between quota and emission tax equilibria.",https://doi.org/10.3982/ECTA22923
Econometrica,2025,Choices and Outcomes in Assignment Mechanisms: The Allocation of Deceased Donor Kidneys,"Nikhil Agarwal, Charles Hodgson and Paulo Somaini","While the mechanism design paradigm emphasizes notions of efficiency based on agent preferences, policymakers often focus on alternative objectives. School districts emphasize educational achievement, and transplantation communities focus on patient survival. It is unclear whether choice‐based mechanisms perform well when assessed based on these outcomes. This paper evaluates the assignment mechanism for allocating deceased donor kidneys on the basis of patient life‐years from transplantation (LYFT). We examine the role of choice in increasing LYFT and compare realized assignments to benchmarks that remove choice. Our model combines choices and outcomes in order to study how selection affects LYFT. We show how to identify and estimate the model using instruments derived from the mechanism. The estimates suggest that the design in use selects patients with better post‐transplant survival prospects and matches them well, resulting in an average LYFT of 9.29, which is 1.75 years more than a random assignment. However, the maximum aggregate LYFT is 14.08. Realizing the majority of the gains requires transplanting relatively healthy patients, who would have longer life expectancies even without a transplant. Therefore, a policymaker faces a dilemma between transplanting patients who are sicker and those for whom life will be extended the longest.",https://doi.org/10.3982/ECTA20203
Econometrica,2025,People Are More Moral in Uncertain Environments,Yiting Chen and Songfa Zhong,We conduct a series of experiments and document a robust behavioral pattern whereby people behave more morally in uncertain environments than degenerate deterministic ones. We show that this pattern is weakened when the moral implication of behavior is diminished or when uncertainty pertains to others rather than oneself. These findings are incompatible with standard models that respect dominance. We propose a mechanism based on the anxiety aspect of uncertain environments whereby people act morally as if their moral behavior can help deliver a better outcome. We further delve into the complexity aspect of uncertainty to arrive at a more comprehensive understanding of these findings.,https://doi.org/10.3982/ECTA20574
Econometrica,2025,Estimating Candidate Valence,Kei Kawai and Takeaki Sunada,"We estimate valence measures of candidates running in U.S. House elections from data on vote shares. Our identification and estimation strategy builds on ideas developed for estimating production functions, allowing us to control for possible endogeneity of campaign spending and sample selection of candidates due to endogenous entry. We find that incumbents have substantially higher valence measures than challengers running against them, resulting in about 3.5 percentage‐point differences in the vote share, on average. Eliminating differences in the valence of challengers and incumbents results in an increase in the winning probability of a challenger from 6.5% to 12.1%. Our measure of candidate valence can be used to study various substantive questions of political economy. We illustrate its usefulness by studying the source of incumbency advantage in U.S. House elections.",https://doi.org/10.3982/ECTA20496
Econometrica,2025,"The Impact of Incarceration on Employment, Earnings, and Tax Filing","Andrew Garin, Dmitri Koustas, Carl McPherson, Samuel Norris, Matthew Pecenco, Evan K. Rose, Yotam Shem‐Tov and Jeffrey Weaver","We study the effect of incarceration on wages, self‐employment, and taxes and transfers in North Carolina and Ohio using two quasi‐experimental research designs: discontinuities in sentencing guidelines and random assignment to judges. Across both states, incarceration generates short‐term drops in economic activity while individuals remain in prison. As a result, a year‐long sentence decreases cumulative earnings over five years by 13%. Beyond five years, however, there is no evidence of lower employment, wage earnings, or self‐employment in either state, as well as among defendants with no prior incarceration history. These results suggest that upstream factors, such as other types of criminal justice interactions or pre‐existing labor market detachment, are more likely to be the cause of low earnings among the previously incarcerated, who we estimate would earn just $5000 per year on average if spared a prison sentence.",https://doi.org/10.3982/ECTA22028
Econometrica,2025,Double Robust Bayesian Inference on Average Treatment Effects,"Christoph Breunig, Ruixuan Liu and Zhengfei Yu","We propose a double robust Bayesian inference procedure on the average treatment effect (ATE) under unconfoundedness. For our new Bayesian approach, we first adjust the prior distributions of the conditional mean functions, and then correct the posterior distribution of the resulting ATE. Both adjustments make use of pilot estimators motivated by the semiparametric influence function for ATE estimation. We prove asymptotic equivalence of our Bayesian procedure and efficient frequentist ATE estimators by establishing a new semiparametric Bernstein–von Mises theorem under double robustness; that is, the lack of smoothness of conditional mean functions can be compensated by high regularity of the propensity score and vice versa. Consequently, the resulting Bayesian credible sets form confidence intervals with asymptotically exact coverage probability. In simulations, our method provides precise point estimates of the ATE through the posterior mean and delivers credible intervals that closely align with the nominal coverage probability. Furthermore, our approach achieves a shorter interval length in comparison to existing methods. We illustrate our method in an application to the National Supported Work Demonstration following LaLonde (1986) and Dehejia and Wahba (1999).",https://doi.org/10.3982/ECTA21442
Econometrica,2025,On (Constrained) Efficiency of Strategy‐Proof Random Assignment,Christian Basteck and Lars Ehlers,"We study random assignment of indivisible objects among a set of agents, when each agent is to receive one object and has strict preferences over the objects. Random Serial Dictatorship (RSD) satisfies equal treatment of equals, ex post efficiency, and strategy‐proofness. Answering a longstanding open question, we show that RSD is not characterized by those properties—there are other mechanisms satisfying equal treatment of equals, ex post efficiency, and strategy‐proofness which are not welfare‐equivalent to RSD. On the other hand, we show that RSD is not Pareto dominated by any mechanism that is (i) strategy‐proof and (ii) boundedly invariant. Moreover, the same holds for all mechanisms that are ex post efficient, strategy‐proof, and boundedly invariant: no such mechanism is dominated by any other mechanism that is strategy‐proof and boundedly invariant.",https://doi.org/10.3982/ECTA22762
Econometrica,2025,Feedback Design in Dynamic Moral Hazard,"Jeffrey C. Ely, George Georgiadis and Luis Rayo","We study the joint design of dynamic incentives and performance feedback for an environment with a coarse (all‐or‐nothing) measure of performance, and show that hiding information from the agent can be an optimal way to motivate effort. Using a novel approach to incentive compatibility, we derive a two‐phase solution that begins with a “silent phase” where the agent is given no feedback and is asked to work non‐stop, and ends with a “full‐transparency phase” where the agent stops working as soon as a performance threshold is met. Hiding information leads to greater effort, but an ignorant agent is also more expensive to motivate. The two‐phase solution—where the agent's ignorance is fully frontloaded—stems from a “backward compounding effect” that raises the cost of hiding information as time passes.",https://doi.org/10.3982/ECTA21871
Econometrica,2025,A Quest for Knowledge,Christoph Carnehl and Johannes Schneider,"Is more novel research always desirable? We develop a model in which knowledge shapes society's policies and guides the search for discoveries. Researchers select a question and how intensely to study it. The novelty of a question determines both the value and difficulty of discovering its answer. We show that the benefits of discoveries are nonmonotone in novelty. Knowledge expands endogenously step‐by‐step over time. Through a dynamic externality, moonshots—research on questions more novel than what is myopically optimal—can improve the evolution of knowledge. Moonshots induce research cycles in which subsequent researchers connect the moonshot to previous knowledge.",https://doi.org/10.3982/ECTA22144
Econometrica,2025,Comparative Statics With Adjustment Costs and the Le Chatelier Principle,"Eddie Dekel, John K.‐H. Quah and Ludvig Sinander","We develop a theory of monotone comparative statics for models with adjustment costs. We show that comparative‐statics conclusions may be drawn under the usual ordinal complementarity assumptions on the objective function, assuming very little about costs: only a mild monotonicity condition is required. We use this insight to prove a general Le Chatelier principle: under the ordinal complementarity assumptions, if short‐run adjustment is subject to a monotone cost, then the long‐run response to a shock is greater than the short‐run response. We extend these results to a fully dynamic model of adjustment over time: the Le Chatelier principle remains valid, and under slightly stronger assumptions, optimal adjustment follows a monotone path. We apply our results to models of saving, production, pricing, labor supply, and investment.",https://doi.org/10.3982/ECTA22841
Econometrica,2025,Uniform Priors for Impulse Responses,"Jonas E. Arias, Juan F. Rubio‐Ramírez and Daniel F. Waggoner","There has been a call for caution regarding the standard procedure for Bayesian inference in set‐identified structural vector autoregressions on the grounds that the common practice of using a uniform prior over the set of orthogonal matrices induces a non‐uniform prior for individual impulse responses or other quantities of interest. This paper challenges this call by formally showing that when the focus is on joint inference, the uniform prior over the set of orthogonal matrices is not only sufficient but also necessary for inference based on a uniform joint prior distribution over the identified set for the vector of impulse responses. In addition, we show how to conduct inference based on a uniform joint prior distribution for the vector of impulse responses.",https://doi.org/10.3982/ECTA21101
Econometrica,2025,A Comment on: “Autoregressive Conditional Duration: A New Model for Irregularly Spaced Transaction Data”,"Giuseppe Cavaliere, Thomas Mikosch, Anders Rahbek and Frederik Vilandt","Based on the GARCH literature, Engle and Russell (1998) established consistency and asymptotic normality of the QMLE for the autoregressive conditional duration (ACD) model, assuming strict stationarity and ergodicity of the durations. Using novel arguments based on renewal process theory, we show that their results hold under the stronger requirement that durations have finite expectation. However, we demonstrate that this is not always the case under the assumption of stationary and ergodic durations. Specifically, we provide a counterexample where the MLE is asymptotically mixed normal and converges at a rate significantly slower than usual. The main difference between ACD and GARCH asymptotics is that the former must account for the number of durations in a given time span being random. As a by‐product, we present a new lemma which can be applied to analyze asymptotic properties of extremum estimators when the number of observations is random.",https://doi.org/10.3982/ECTA21896
Econometrica,2025,Mussa Puzzle Redux,Oleg Itskhoki and Dmitry Mukhin,"The Mussa (1986) puzzle is the observation of a sharp and simultaneous increase in the volatility of both nominal and real exchange rates following the end of the Bretton Woods System of pegged exchange rates in 1973. It is commonly viewed as a central piece of evidence in favor of monetary non‐neutrality because it is an instance in which a change in the monetary regime caused a dramatic change in the equilibrium behavior of a real variable—the real exchange rate—and is often further interpreted as direct evidence in favor of models with nominal rigidities in price setting. This paper shows that the data do not support this latter conclusion because there was no simultaneous change in the properties of the other macro variables, nominal or real; an extended set of Mussa facts falsifies both conventional flexible‐price RBC models and sticky‐price New Keynesian models. We present a resolution to the broader Mussa puzzle based on a model of segmented financial market, in which the bulk of the nominal exchange rate risk is held by financial intermediaries and is not shared smoothly throughout the economy, emphasizing the importance of monetary transmission via the risk premium channel.",https://doi.org/10.3982/ECTA20849
Econometrica,2025,The Political Economy of Zero‐Sum Thinking,"S. Nageeb Ali, Maximilian Mihm and Lucas Siga",This paper offers a strategic rationale for zero‐sum thinking in elections. We show that asymmetric information and distributional considerations together make voters wary of policies supported by others. This force impels a majority of voters to support policies contrary to their preferences and information. Our analysis identifies and interprets a form of “adverse correlation” that is necessary and sufficient for zero‐sum thinking to prevail in equilibrium.,https://doi.org/10.3982/ECTA22474
Econometrica,2025,Seeding a Simple Contagion,Evan Sadler,"I propose a method for selecting seeds to maximize contagion. First, fit a random graph model using a coarse categorization of individuals. Next, compute a seed multiplier for each category—this is the average number of new infections a seed generates. Finally, seed the category with the highest multiplier. Relative to the most common methods, my approach requires far less granular data, and it consumes less computing power—the problem scales with the number of categories, not the number of individuals. I validate the methodology through simulations using real network data.",https://doi.org/10.3982/ECTA22448
Econometrica,2025,History's Masters The Effect of European Monarchs on State Performance,Sebastian Ottinger and Nico Voigtländer,"We create a novel reign‐level data set for European monarchs, covering all major European states between the 10th and 18th centuries. We first document a strong positive relationship between rulers' cognitive ability and state performance. To address endogeneity issues, we exploit the facts that (i) rulers were appointed according to hereditary succession, independent of their ability, and (ii) the widespread inbreeding among the ruling dynasties of Europe led over centuries to quasirandom variation in ruler ability. We code the degree of blood relationship between the parents of rulers, which also reflects “hidden” layers of inbreeding from previous generations. The coefficient of inbreeding is a strong predictor of ruler ability, and the corresponding instrumental variable results imply that ruler ability had a sizeable effect on the performance of states and their borders. This supports the view that “leaders made history,” shaping the European map until its consolidation into nation states. We also show that rulers mattered only where their power was largely unconstrained. In reigns where parliaments checked the power of monarchs, ruler ability no longer affected their state's performance.",https://doi.org/10.3982/ECTA20830
Econometrica,2025,The Margins of Trade,Ana Cecília Fieler and Jonathan Eaton,"Welfare depends on the quantity, quality, and range of goods consumed. We use trade data, which report the quantities and prices of the individual goods that countries exchange, to learn about how the gains from trade and growth break down into these different margins. Our general equilibrium model, in which both quality and quantity contribute to consumption and to production, captures (i) how prices increase with importer and exporter per capita income, (ii) how the range of goods traded rises with importer and exporter size, and (iii) how products traveling longer distances have higher prices. Our framework can deliver a standard gravity formulation for total trade flows and for the gains from trade. We find that growth in the extensive margin contributes to about half of overall gains. Quality plays a larger role in the welfare gains from international trade than from economic growth due to selection.",https://doi.org/10.3982/ECTA17510
Econometrica,2025,How Well Does Bargaining Work in Consumer Markets? A Robust Bounds Approach,Joachim Freyberger and Bradley Larsen,"This study provides a structural analysis of detailed, alternating‐offer bargaining data from eBay, deriving bounds on buyers and sellers private value distributions and the gains from trade using a range of assumptions on behavior and the informational environment. These assumptions range from weak (assuming only that acceptance and rejection decisions are rational) to less weak (e.g., assuming that bargaining offers are weakly increasing in players' private values). We estimate the bounds and show what they imply for consumer negotiation behavior and inefficient breakdown. For the median product, bargaining ends in impasse in 37% of negotiations even when the buyer values the good more than the seller.",https://doi.org/10.3982/ECTA20125
Econometrica,2025,Persuasion Meets Delegation,Anton Kolotilin and Andriy Zapechelnyuk,"A principal can restrict an agent's information (the persuasion problem) or discretion (the delegation problem). We study these two problems under standard single‐crossing assumptions on the agent's marginal utility. We show that these problems are equivalent on the set of monotone stochastic mechanisms, implying, in particular, the equivalence of deterministic delegation and monotone partitional persuasion. We also show that the monotonicity restriction is superfluous for linear persuasion and linear delegation, implying their equivalence on the set of all stochastic mechanisms. Finally, using tools from the persuasion literature, we characterize optimal delegation mechanisms, thereby generalizing and extending existing results in the delegation literature.",https://doi.org/10.3982/ECTA17051
Econometrica,2025,Tell Me Something I Don't Already Know: Learning in Low‐ and High‐Inflation Settings,"Michael Weber, Bernardo Candia, Hassan Afrouzi, Tiziano Ropele, Rodrigo Lluberas, Serafin Frache, Brent Meyer, Saten Kumar, Yuriy Gorodnichenko, Dimitris Georgarakos, Olivier Coibion, Geoff Kenny and Jorge Ponce","Using randomized control trials (RCTs) applied over time in different countries, we study whether the economic environment affects how agents learn from new information. We show that as inflation rose in advanced economies, both households and firms became more attentive and informed about publicly available news about inflation, leading them to respond less to exogenously provided information about inflation and monetary policy. We also study the effects of RCTs in countries where inflation has been consistently high (Uruguay) and low (New Zealand) as well as what happens when the same agents are repeatedly provided information in both low‐ and high‐inflation environments (Italy). Our results broadly support models in which inattention is an endogenous outcome that depends on the economic environment.",https://doi.org/10.3982/ECTA22764
Econometrica,2025,"Minimum Wages, Efficiency, and Welfare","David Berger, Kyle Herkenhoff and Simon Mongey","Many argue that minimum wages can prevent efficiency losses from monopsony power. We assess this argument in a general equilibrium model of oligopsonistic labor markets with heterogeneous workers and firms. We decompose welfare gains into an efficiency component that captures reductions in monopsony power and a redistributive component that captures the way minimum wages shift resources across people. The minimum wage that maximizes the efficiency component of welfare lies below $8.00 and yields gains worth less than 0.2% of lifetime consumption. When we add back in Utilitarian redistributive motives, the optimal minimum wage is $11 and redistribution accounts for 102.5% of the resulting welfare gains, implying offsetting efficiency losses of −2.5%. The reason a minimum wage struggles to deliver efficiency gains is that with realistic firm productivity dispersion, a minimum wage that eliminates monopsony power at one firm causes severe rationing at another. These results hold under an EITC and progressive labor income taxes calibrated to the U.S. economy.",https://doi.org/10.3982/ECTA21466
